1
00:00:00,480 --> 00:00:08,640
Hey, this is Andrew Brown, and I'm bringing you another certification course, and this time it's the Azure AI Fundamentals, also known as the AI 900.

2
00:00:08,880 --> 00:00:15,600
And if you're looking to pass a certification, we have everything that you need here, such as labs, lectures, and a free practice exam.

3
00:00:15,840 --> 00:00:23,280
So you can go ace that exam, get that certification, put it on your resume and LinkedIn to go get that job you've been looking for.

4
00:00:24,080 --> 00:00:33,840
If you want to support more free courses like this one, the best way is to purchase the additional paid materials where you can get access to more practice exams and other resources.

5
00:00:34,000 --> 00:00:43,120
If you don't know me, I've taught a bit of everything here on the cloud that's been with AWS, Azure, GCP, DevOps, Terraform, Kubernetes, you name it.

6
00:00:43,120 --> 00:00:43,760
I've taught it.

7
00:00:44,160 --> 00:00:46,880
But you know the drill here.

8
00:00:46,880 --> 00:00:50,960
Let's get into it and learn more about the Azure AI fundamentals.

9
00:00:54,640 --> 00:01:03,360
Hey, this is Andrew Brown from ExamPro, and we are at the start of our journey here learning about the AI900 asking the most important question, which is what is the AI900?

10
00:01:03,680 --> 00:01:09,840
So the Azure AI Fundamental Certification is for those seeking an ML role such as AI engineer or data scientist.

11
00:01:10,160 --> 00:01:18,720
The certification will demonstrate if a person can define and understand Azure AI services such as Cognitive Services and Azure Applied AI Services.

12
00:01:19,200 --> 00:01:34,960
AI concepts, knowledge mining, responsible AI, basics of ML pipelines, classical ML models, AutoML, generative AI workloads, which is newly added content, and Azure AI Studio, so you don't need to know super complicated ML knowledge here, but it definitely helps to get you through there.

13
00:01:35,280 --> 00:01:44,720
So this certification is generally referred to by its course code, the AI900, and it's the natural path for the Azure AI Engineer or Azure Data Scientist certification.

14
00:01:44,960 --> 00:01:48,840
This generally is an easy course to pass, and it's great for those new to cloud or ML.

15
00:01:48,920 --> 00:01:50,080
related technology.

16
00:01:50,560 --> 00:01:55,520
Looking at our roadmap, you might be asking, okay, well, what are the paths and what should I learn first?

17
00:01:55,520 --> 00:01:57,200
So here are a few suggested routes.

18
00:01:57,680 --> 00:02:02,480
If you already have your AZ-900, that's a great starting point before you take your AI-900.

19
00:02:02,960 --> 00:02:11,520
If you don't have your AZ-900, you can jump right into the AI-900, but I strongly recommend you go get that AZ-900 because it gives you general foundational knowledge.

20
00:02:11,520 --> 00:02:16,720
It's just another thing that you should not have to worry about, which is just how to use Azure at a fundamental level.

21
00:02:17,320 --> 00:02:20,160
Do you need the DP-900 to take the AI-900?

22
00:02:20,400 --> 00:02:29,680
No, but a lot of people seem to like to go this route where they want to have that data foundation before they move on to the AI-900, because they know that the broad knowledge is going to be useful there.

23
00:02:29,920 --> 00:02:34,880
So it's a pairing that you see a lot of people getting the AI-900 and the DP-900 together.

24
00:02:35,200 --> 00:02:38,080
For the AI-900, the path is a little bit more clear.

25
00:02:38,080 --> 00:02:40,960
It's either going to be data scientists or AI engineer.

26
00:02:41,360 --> 00:02:45,120
So for the AI engineer, you have to know how to use the AI services in and out.

27
00:02:45,120 --> 00:02:47,240
For data scientists, it's more focused on

28
00:02:47,320 --> 00:02:50,880
setting up actual pipelines and things like that within Azure Machine Learning.

29
00:02:50,880 --> 00:02:53,040
So you just have to decide which path is for you.

30
00:02:53,440 --> 00:02:56,640
The data scientist is definitely harder than the AI engineer.

31
00:02:56,640 --> 00:03:02,160
So if you aren't ready for the data science, some people like taking the AI engineer 1st and then doing the data scientist.

32
00:03:02,160 --> 00:03:03,920
So this is kind of like a warm-up.

33
00:03:04,400 --> 00:03:08,960
Again, it's not 100% necessary, but it's just based on your personal learning style.

34
00:03:08,960 --> 00:03:14,480
And a lot of times people like to take the data engineer after the data scientist just to round out their complete knowledge.

35
00:03:15,000 --> 00:03:22,800
Now, if you already have the AZ-900 and the administrator associate, you can safely go to the data scientist if you want to risk it, because this one is really hard.

36
00:03:22,880 --> 00:03:29,760
So if you've passed the AZ-104, you know you're going to probably have a lot more confidence learning up about all the concepts at this level here.

37
00:03:30,160 --> 00:03:39,680
But of course, it's always recommended to go grab these foundational certs, because sometimes course materials just do not cover the information, and so the obvious stuff is going to get left out, okay?

38
00:03:40,400 --> 00:03:44,160
So moving forward here, how long should you study to pass for the AI-900?

39
00:03:44,560 --> 00:03:51,840
If you're entirely new to ML, AI, and cloud providers such as Azure, you should anticipate dedicating around 15 hours to grasp the basics.

40
00:03:52,000 --> 00:03:55,360
This estimate can vary based on your familiarity with these concepts.

41
00:03:55,440 --> 00:03:59,360
For complete beginners, the time commitment might extend to 20 to 30 hours.

42
00:03:59,840 --> 00:04:06,720
For the intermediate level, so people that have passed the AZ-900 or DP-900, you're looking at around 8 to 10 hours.

43
00:04:07,360 --> 00:04:15,360
If you have one or more years of experience with Azure or another cloud service provider like a WS or GCP, you're looking at about 5 hours or less.

44
00:04:15,840 --> 00:04:18,000
The average study time is about 8 hours.

45
00:04:18,000 --> 00:04:23,680
This is where you should be committing 50% of the time to the lecture and labs and 50% for the practice exams.

46
00:04:24,160 --> 00:04:28,240
The recommended study time is 30 minutes to an hour a day for 14 days.

47
00:04:28,320 --> 00:04:32,080
This should get you through it, but just don't overstudy and just don't spend too little time.

48
00:04:32,720 --> 00:04:34,480
What does it take to pass the exam?

49
00:04:35,040 --> 00:04:41,280
you got to watch the lectures and memorize key information, do hands-on labs, and follow along with your own Azure account.

50
00:04:41,360 --> 00:04:49,360
I'd say that you could probably get away with just watching all the videos in this one without having to do the labs, but again, it really does reinforce that information.

51
00:04:49,360 --> 00:04:53,920
If you do take the time, there is some stuff that is in Azure AI Studio or Machine Learning.

52
00:04:54,560 --> 00:05:02,960
You might be wary of launching instances, because we do have to run instances and they will cost money, unless you delete the instances after use, resulting in very small costs.

53
00:05:03,120 --> 00:05:12,720
So, if you feel that you're not comfortable with that by just watching the videos, you should be okay, but when you get into the associate tier, you absolutely have to expect to pay something to learn and take that risk.

54
00:05:13,320 --> 00:05:16,800
You want to do paid online practice exams that simulate the real exam?

55
00:05:16,880 --> 00:05:27,040
As I've mentioned before, I do provide a free practice exam and have paid practice exams that accompany this course that are on my platform, Exam Pro, and that's how you can help support more of these free courses.

56
00:05:27,560 --> 00:05:30,960
So, can you pass this certification without taking a practice exam?

57
00:05:31,120 --> 00:05:32,720
Well, Azure's a little bit harder.

58
00:05:32,720 --> 00:05:40,960
If this isn't a WS exam, I would say yes, but for Azure exams like AI-900, DP-900, and SC-900, probably not.

59
00:05:40,960 --> 00:05:42,080
It's kind of risky.

60
00:05:42,400 --> 00:05:46,000
I think you should do at least one practice exam or go through the sample one.

61
00:05:46,000 --> 00:05:48,960
There's a sample one probably laying around on the Azure website.

62
00:05:49,560 --> 00:05:56,320
Let's take a look at the exam guide breakdown here, and then in the following video, we'll look at it in more detail, so it's broken down into the following domain.

63
00:05:56,640 --> 00:06:03,760
So, the exam has five domains of questions, and each domain has its own weighting, which determines how many questions in a domain that will show up.

64
00:06:04,080 --> 00:06:08,080
So, 15 to 20% will be described AI workloads and considerations.

65
00:06:08,640 --> 00:06:13,360
20 to 25% will consist of described fundamental principles of machine learning on Azure.

66
00:06:13,600 --> 00:06:18,320
15 to 20% will consist of described features of computer vision workloads on Azure.

67
00:06:18,560 --> 00:06:23,440
15 to 20% will be described features of natural language processing workloads on Azure.

68
00:06:23,680 --> 00:06:28,080
And 15 to 20% will be described features of generative AI workloads on Azure.

69
00:06:28,320 --> 00:06:30,800
I want you to notice it says describe these domains.

70
00:06:30,800 --> 00:06:33,600
This is good because that tells you it's not going to be super hard.

71
00:06:33,760 --> 00:06:38,440
If you start seeing things that say beyond describe and identify, then you know it's going to be a bit harder.

72
00:06:39,040 --> 00:06:40,720
So, where do you take this exam?

73
00:06:41,120 --> 00:06:45,600
Well, you can take it in person at a test center or online from the convenience of your own home.

74
00:06:46,000 --> 00:06:50,160
So, there's two popular test centers: there's Certiport and there's Pearson VUE.

75
00:06:50,240 --> 00:06:53,840
You can also take it at a local test center if there are nearby locations.

76
00:06:54,360 --> 00:06:58,880
The term proctored means a supervisor or person that is monitoring you while you're taking the exam.

77
00:06:59,040 --> 00:07:06,080
If I had the option between in-person or online, I would always choose the in-person because it's a controlled environment and it's way less stressful.

78
00:07:06,160 --> 00:07:10,800
Online, there are many things that can go wrong, but it's up to your personal preference and your situation.

79
00:07:11,520 --> 00:07:16,200
The passing grade here is 700 out of 1000, so that's around 70%.

80
00:07:16,200 --> 00:07:22,240
I would say around because you could possibly fail with 70% because these things work on scaled scoring for response types.

81
00:07:22,760 --> 00:07:28,000
There's about 37 to 47 questions, and you can afford to get about 10 to 13 questions wrong.

82
00:07:28,320 --> 00:07:30,640
So some questions are worth more than one point.

83
00:07:30,960 --> 00:07:32,640
Some questions cannot be skipped.

84
00:07:32,960 --> 00:07:38,080
And the format of questions can be multiple choice, multiple answer, drag and drop, and hot area.

85
00:07:38,160 --> 00:07:41,280
There shouldn't be any case studies for foundational level exams.

86
00:07:41,600 --> 00:07:43,760
And there's no penalty for wrong questions.

87
00:07:44,160 --> 00:07:48,000
So for the duration, you get one hour that means about one minute per question.

88
00:07:48,280 --> 00:07:50,320
The time for this exam is 60 minutes.

89
00:07:50,560 --> 00:07:52,240
Your seat time is 90 minutes.

90
00:07:52,480 --> 00:07:56,240
Seat time refers to the amount of time that you should take to allocate for that exam.

91
00:07:56,480 --> 00:08:02,640
So this includes time to review the instructions, read and accept the NDA, complete the exam, and provide feedback at the end.

92
00:08:02,880 --> 00:08:06,480
This certification is going to be valid forever and it does not expire.

93
00:08:06,560 --> 00:08:14,560
Microsoft fundamental certifications such as the AZ-900 or MS-900 do not expire as long as the technology is still available or relevant.

94
00:08:14,880 --> 00:08:17,280
So we'll proceed to the full exam guide now.

95
00:08:21,760 --> 00:08:27,840
Hey, this is Andrew Brown from Exam Pro, and what we've pulled up here is the official exam outline on the Microsoft website.

96
00:08:28,160 --> 00:08:32,640
If you want to find this yourself, you just have to type in AI900 Azure or Microsoft.

97
00:08:32,960 --> 00:08:34,720
You should be able to easily find it.

98
00:08:34,720 --> 00:08:35,840
The page looks like this.

99
00:08:36,040 --> 00:08:46,320
What I want you to do is scroll on down because we're looking for the AI900 study guide, and from there we're going to scroll on down to the skills measured section, and you might want to bump up the text.

100
00:08:46,720 --> 00:08:55,760
Azure loves updating their courses with minor updates that don't generally affect the outcome of the study here, but it does get a lot of people worried because they always say, well, is your course out of date?

101
00:08:56,240 --> 00:09:00,320
So no, they're just making minor changes because they'll do this like 5 * a year.

102
00:09:00,720 --> 00:09:03,920
And so if there was a major revision, what would happen is they would change it.

103
00:09:03,920 --> 00:09:15,360
So instead of being the AI-900, it'd be like the AI-901 or 902, similar to how the AI-102 was previously AI-100, but now it's the AI-102, so just watch out for those.

104
00:09:15,360 --> 00:09:16,600
And if it's a major revision,

105
00:09:16,720 --> 00:09:19,120
then yes, it would probably need a completely new course.

106
00:09:19,520 --> 00:09:27,920
So there aren't any major changes with the new update, other than the update for the generative AI workloads on Azure section, a couple of name changes, and a few things being removed.

107
00:09:28,080 --> 00:09:33,920
Everything else remains relatively the same, with very minor changes, so the concepts and such are still up to date.

108
00:09:34,080 --> 00:09:36,800
Overall, I think the exam is easier than before.

109
00:09:37,120 --> 00:09:40,400
So let's go through some of the topics and work our way through here.

110
00:09:40,720 --> 00:09:43,120
So describe AI workloads and considerations.

111
00:09:43,120 --> 00:09:46,000
So here we're just kind of describing the generalities of AI.

112
00:09:46,680 --> 00:09:54,880
So, content moderation workloads involve filtering out inappropriate or harmful content from user-generated inputs, ensuring a safe and positive user experience.

113
00:09:55,000 --> 00:10:02,480
Personalization workloads analyze user behavior and preferences to tailor content, recommendations, or experiences to individual users.

114
00:10:02,880 --> 00:10:09,680
Computer vision workloads involve the analysis of images and videos to recognize patterns, objects, faces, and actions.

115
00:10:10,320 --> 00:10:16,640
Identify natural language processing, knowledge mining, document intelligence, and features of generative AI workloads.

116
00:10:17,120 --> 00:10:18,880
Note that these are all just concepts.

117
00:10:18,880 --> 00:10:21,440
You don't need to know how to use the services at a high level.

118
00:10:22,320 --> 00:10:24,400
Then you have the responsible AI section.

119
00:10:24,400 --> 00:10:29,680
So Microsoft has these six principles that they really want you to know, and they push it throughout all their AI services.

120
00:10:29,680 --> 00:10:32,640
So those are the six you'll need to know, and they're not that hard to learn.

121
00:10:33,760 --> 00:10:37,760
Moving on, we have described fundamental principles of machine learning on Azure.

122
00:10:38,880 --> 00:10:43,920
So here it's just describing regression, classification, clustering, and features of deep learning.

123
00:10:44,240 --> 00:10:49,440
We have a lot of practical experience with these in the course, so you will understand at the end what these are used for.

124
00:10:49,760 --> 00:10:52,080
Next, we have core machine learning concepts.

125
00:10:52,080 --> 00:10:56,480
We could identify features and labels in a data set, so that's the data labeling service.

126
00:10:56,560 --> 00:11:01,200
Describe how training validation data sets are used in machine learning, so we'll touch on that.

127
00:11:01,840 --> 00:11:04,560
Describe capabilities of automated machine learning.

128
00:11:05,240 --> 00:11:11,360
AutoML simplifies building and picking the best models, while data and compute services provide the power you need for training.

129
00:11:11,440 --> 00:11:18,000
With Azure Machine Learning, it helps with managing and deploying your models, letting you put your machine learning projects into action smoothly.

130
00:11:18,640 --> 00:11:27,280
Under Computer Vision Workloads, we have Image Classification, Object Detection, Optical Character Recognition, Facial Detection, and Facial Analysis Solutions.

131
00:11:28,160 --> 00:11:32,960
Next, we have Azure AI Vision, Azure AI Face Detection, and Azure AI Video Indexer.

132
00:11:33,360 --> 00:11:39,360
The Azure AI Services encompass a wide range of tools designed to facilitate the development of intelligent applications.

133
00:11:39,440 --> 00:11:50,400
These services used to be called Computer Vision, Custom Vision, Face Service, and Form Recognizer, but have evolved or been grouped under broader service categories to streamline their application and integration into projects.

134
00:11:52,280 --> 00:12:04,240
For NLP, we have key phrase extraction, entity recognition, sentiment analysis, language modeling, speech recognition, synthesis, this one doesn't really appear much, it's kind of a concept, not so much something we have to do.

135
00:12:04,320 --> 00:12:05,680
And then there's translation.

136
00:12:06,800 --> 00:12:10,080
So now we have Azure tools and services for NLP workloads.

137
00:12:10,160 --> 00:12:15,600
These include the Azure AI Language Service, Azure AI Speech Service, and Azure AI Translator Service.

138
00:12:15,680 --> 00:12:25,600
These used to be separate services, I believe, like the Text Analytics Service, LUIS Speech Service, and Translator Text Service, but they have been added to the Azure AI umbrella of AI services.

139
00:12:26,240 --> 00:12:29,360
And now we'll be moving on to the Generative AI workloads on Azure.

140
00:12:30,040 --> 00:12:46,160
We'll be covering features of generative AI models, common scenarios for generative AI, and responsible AI considerations for generative AI, and also some of the cool features that Azure OpenAI Service has to offer, such as natural language generation, code generation, and image generation.

141
00:12:46,800 --> 00:12:50,400
So, that's about a general breakdown of the AI 900 Exam Guide.

142
00:12:55,640 --> 00:12:59,960
Hey, this is Andrew Brown from Exam Pro, and we are looking at the layers of machine learning.

143
00:12:59,960 --> 00:13:02,640
So here I have this thing that looks like kind of an onion.

144
00:13:02,800 --> 00:13:08,960
And what it is, it's just describing the relationship between these ML terms related to AI.

145
00:13:08,960 --> 00:13:10,960
And we'll just work our way through here, starting at the top.

146
00:13:10,960 --> 00:13:16,800
So artificial intelligence, also known as AI, is when machines that perform jobs that mimic human behavior.

147
00:13:16,800 --> 00:13:21,680
So it doesn't describe how it does that, but it's just the fact that that's what AI is.

148
00:13:22,320 --> 00:13:24,440
One layer underneath, we have machine learning.

149
00:13:24,440 --> 00:13:27,440
So machines that get better at a task without explicit programming.

150
00:13:28,080 --> 00:13:29,360
Then we have deep learning.

151
00:13:29,440 --> 00:13:34,560
So these are machines that have an artificial neural network inspired by the human brain to solve complex problems.

152
00:13:34,880 --> 00:13:41,720
And if you're talking about someone that actually assembles either ML or deep learning models or algorithms, that's a data scientist.

153
00:13:41,720 --> 00:13:47,840
So a person with multidisciplinary skills in math, statistics, predictive modeling, machine learning to make future predictions.

154
00:13:48,080 --> 00:13:51,880
So what you need to understand is that AI is just the outcome, right?

155
00:13:51,880 --> 00:13:52,160
And so

156
00:13:52,320 --> 00:13:58,640
AI could be using ML underneath, or deep learning, or a combination of both, or just if-else statements, okay?

157
00:14:04,440 --> 00:14:06,480
All right, so let's take a look here at the key elements of AI.

158
00:14:06,480 --> 00:14:15,280
So AI is the software that imitates human behaviors and capabilities, and there are key elements according to Azure or Microsoft as to what makes up AI.

159
00:14:15,520 --> 00:14:17,200
So let's go through this list quickly here.

160
00:14:17,200 --> 00:14:22,320
So we have machine learning, which is the foundation of an AI system that can learn and predict like a human.

161
00:14:22,480 --> 00:14:26,720
You have anomaly detection, so detect outliers or things out of place like a human.

162
00:14:26,960 --> 00:14:29,760
Computer vision, be able to see like a human.

163
00:14:29,920 --> 00:14:34,360
Natural language processing, also known as NLP, be able to process human languages.

164
00:14:34,600 --> 00:14:41,040
and refer a context, like a human, conversational AI be able to hold a conversation with a human.

165
00:14:41,040 --> 00:14:57,440
So, I wrote here, according to Microsoft and Azure, because the global definition is a bit different, but I just wanted to put this here because I've definitely seen this as an exam question, and so we're going to have to go with Azure's definition here, okay?

166
00:15:02,360 --> 00:15:03,920
Let's define what is a data set.

167
00:15:03,920 --> 00:15:10,280
So a data set is a logical grouping of units of data that are closely related to or share the same data structure.

168
00:15:10,280 --> 00:15:16,880
And there are publicly available data sets that are used in learning of statistics, data analytics, and machine learning.

169
00:15:17,200 --> 00:15:18,800
I just want to cover a couple here.

170
00:15:18,800 --> 00:15:21,160
So the 1st is the MNIST database.

171
00:15:21,160 --> 00:15:27,600
So images of handwritten digits used to test, classify, cluster image processing algorithms, commonly used when learning

172
00:15:28,240 --> 00:15:34,120
how to build computer vision ML models to translate handwriting into digital text.

173
00:15:34,120 --> 00:15:38,320
So it's just a bunch of handwritten numbers and letters.

174
00:15:38,640 --> 00:15:43,280
And then another very popular dataset is the Common Objects in Context COCO dataset.

175
00:15:43,520 --> 00:15:50,720
So this is a dataset which contains many common images using a JSON file, COCO format, that identify objects or segments within an image.

176
00:15:51,320 --> 00:15:57,840
And so this data set has a lot of stuff in it, so object segmentations, recognition in it context, super pixel stuff segmentation.

177
00:15:57,840 --> 00:16:02,880
They have a lot of images and a lot of objects, so there's a lot of stuff in there.

178
00:16:02,880 --> 00:16:06,400
So why am I talking about this, and in particular Cocoa data sets?

179
00:16:06,400 --> 00:16:11,760
Well, when you use Azure Machine Learning Studio, it has a data labeling service.

180
00:16:12,160 --> 00:16:19,680
And the thing is that it can actually export out into Cocoa format, so that's why I wanted you to get exposure to what Cocoa was.

181
00:16:20,040 --> 00:16:31,640
And the other thing is that when you're building out Azure Machine Learning pipelines, they actually have open data sets, which you'll see later in the course, that shows you that you can just use very common ones.

182
00:16:31,640 --> 00:16:35,520
And so you might see MNIST and the other one there.

183
00:16:35,760 --> 00:16:37,600
So I just wanted to get you some exposure, okay?

184
00:16:42,240 --> 00:16:43,760
Let's talk about data labeling.

185
00:16:43,760 --> 00:16:54,080
So this is the process of identifying raw data, so images, text files, videos, and adding one or more meaningful and informative labels to provide context so a machine learning model can learn.

186
00:16:54,080 --> 00:17:01,360
So with supervised machine learning, labeling is a prerequisite to produce training data, and each piece of data will generally be labeled by a human.

187
00:17:01,520 --> 00:17:09,440
The reason why I say generally here is because with Azure's data labeling service, they can actually do ML-assisted labeling.

188
00:17:10,000 --> 00:17:15,760
So with unsupervised machine learning, labels will be produced by the machine and may not be human readable.

189
00:17:16,320 --> 00:17:19,040
And then one other thing I want to touch on is the term called ground truth.

190
00:17:19,040 --> 00:17:26,800
So this is a properly labeled data set that you can use as the objective standard to train and assess a given model.

191
00:17:26,960 --> 00:17:28,240
It's often called ground truth.

192
00:17:28,480 --> 00:17:32,000
The accuracy of your trained model will depend on the accuracy of your ground truth.

193
00:17:32,240 --> 00:17:35,920
Now, using Azure's tools, I never see them use the word ground truth.

194
00:17:36,000 --> 00:17:37,360
I see that a lot in AWS.

195
00:17:37,560 --> 00:17:39,800
And even this graphic here is from AWS.

196
00:17:40,160 --> 00:17:43,360
But I just want to make sure you are familiar with all that stuff, okay?

197
00:17:47,920 --> 00:17:50,960
Let's compare supervised, unsupervised, and reinforcement learning.

198
00:17:50,960 --> 00:17:52,880
Starting at the top, we got supervised learning.

199
00:17:52,880 --> 00:18:00,240
This is where the data has been labeled for training, and it's considered task-driven because you are trying to make a prediction, get a value back.

200
00:18:00,240 --> 00:18:08,960
So when the labels are known and you want a precise outcome, when you need a specific value returned, and so you're going to be using classification and regression in these cases.

201
00:18:09,120 --> 00:18:09,800
For unsupervised

202
00:18:10,000 --> 00:18:10,320
learning.

203
00:18:10,320 --> 00:18:12,160
This is where data that has not been labeled.

204
00:18:12,480 --> 00:18:14,480
The ML model needs to do its own labeling.

205
00:18:14,640 --> 00:18:16,080
This is considered data-driven.

206
00:18:16,080 --> 00:18:18,720
It's trying to recognize a structure or a pattern.

207
00:18:18,920 --> 00:18:24,880
And so this is when the labels are not known and the outcome does not need to be precise when you're trying to make sense of data.

208
00:18:24,880 --> 00:18:29,040
So you have clustering, dimensionality, reduction, and association.

209
00:18:29,040 --> 00:18:34,560
If you've never heard this term before, the idea is it's trying to reduce the amount of dimensions to make it easier to work with the data.

210
00:18:34,800 --> 00:18:36,640
So make sense of the data, right?

211
00:18:37,360 --> 00:18:38,480
We have reinforcement learning.

212
00:18:38,480 --> 00:18:40,000
So this is where there is no data.

213
00:18:40,000 --> 00:18:45,520
There's an environment and an ML model generates data and makes many attempts to reach a goal.

214
00:18:45,520 --> 00:18:47,840
So this is considered decisions driven.

215
00:18:48,040 --> 00:18:51,400
And so this is for game AI, learning tasks, robot navigation.

216
00:18:51,400 --> 00:18:55,680
When you've seen someone code a video game that can play itself, that's what this is.

217
00:18:55,920 --> 00:18:58,720
If you're wondering, this is not all the types of machine learning.

218
00:18:58,920 --> 00:19:07,240
And these are in specific unsupervised and supervised is considered classical machine learning because they heavily rely on statistics and math to

219
00:19:07,320 --> 00:19:09,360
to reduce the outcome, but there you go.

220
00:19:14,160 --> 00:19:15,760
So what is a neural network?

221
00:19:15,760 --> 00:19:17,840
Well, it's often described as mimicking the brain.

222
00:19:17,840 --> 00:19:20,000
It's a neuron or node that represents an algorithm.

223
00:19:20,000 --> 00:19:25,680
So data is inputted into a neuron and based on the output, the data will be passed to one of many connected neurons.

224
00:19:25,920 --> 00:19:28,320
The connections between neurons is weighted.

225
00:19:28,320 --> 00:19:29,520
I really should have highlighted that one.

226
00:19:29,520 --> 00:19:30,400
That's very important.

227
00:19:30,880 --> 00:19:32,960
The network is organized into layers.

228
00:19:33,120 --> 00:19:37,120
There will be an input layer, one to many hidden layers and an output layer.

229
00:19:37,320 --> 00:19:39,840
So here's an example of a very simple neural network.

230
00:19:40,080 --> 00:19:41,120
Notice the NN.

231
00:19:41,120 --> 00:19:44,880
A lot of times you'll see this in ML as an abbreviation for neural networks.

232
00:19:45,200 --> 00:19:47,720
And sometimes neural networks are just called neural nets.

233
00:19:47,720 --> 00:19:49,920
So just understand that's the same term here.

234
00:19:50,160 --> 00:19:51,000
What is deep learning?

235
00:19:51,000 --> 00:19:53,200
This is a neural network that has three or more hidden layers.

236
00:19:53,200 --> 00:19:59,920
It's considered deep learning because at this point, it's not human readable to understand what's going on within those layers.

237
00:20:01,160 --> 00:20:02,240
What is forward feed?

238
00:20:02,240 --> 00:20:07,000
So neural networks where they have connections between nodes that do not form a cycle, they always move forward.

239
00:20:07,000 --> 00:20:11,280
So that just describes a forward pass through the network.

240
00:20:11,520 --> 00:20:14,560
You'll see FNN, which stands for Forward Feed Neural Network.

241
00:20:14,600 --> 00:20:16,320
I just described that type of network.

242
00:20:17,040 --> 00:20:20,960
Then there's backpropagation, which are in forward feed networks.

243
00:20:21,200 --> 00:20:25,200
This is where we move backwards through the neural net, adjusting the weights to improve the outcome on next iteration.

244
00:20:25,200 --> 00:20:26,800
This is how a neural net learns.

245
00:20:27,040 --> 00:20:36,160
The way the backpropagation knows to do this is that there's a loss function, so a function that compares the ground truth to the prediction to determine the error rate, how bad the network performs.

246
00:20:36,160 --> 00:20:42,480
So when it gets to the end, it's going to perform that calculation, and then it's going to do its backpropagation and adjust the weights.

247
00:20:43,600 --> 00:20:45,360
Then you have activation functions.

248
00:20:45,360 --> 00:20:47,120
I'm just going to clear this up here.

249
00:20:47,840 --> 00:20:55,440
So activation functions, they're an algorithm applied to a hidden layer node that affects connected output.

250
00:20:55,440 --> 00:20:59,200
So for this entire hidden layer, they'll all have the same one here.

251
00:20:59,200 --> 00:21:01,000
And it just kind of affects how.

252
00:21:01,080 --> 00:21:03,320
how it learns and like how the weighting works.

253
00:21:03,320 --> 00:21:06,560
So it's part of back propagation and just the learning process.

254
00:21:06,800 --> 00:21:07,800
There's a concept of dense.

255
00:21:07,800 --> 00:21:24,880
So when the next layer increases the amount of nodes and you have sparse, so when the next layer decreases the amount of nodes, anytime you see something going from a dense layer to a sparse layer, that's usually called dimensionality reduction because you're reducing the amount of dimensions because the amount of nodes in your network determines the dimensions you have.

256
00:21:25,040 --> 00:21:25,280
Okay.

257
00:21:30,040 --> 00:21:30,960
What is a GPU?

258
00:21:30,960 --> 00:21:37,280
Well, it's a general processing unit that is specially designed to quickly render high-resolution images and videos concurrently.

259
00:21:37,440 --> 00:21:45,760
GPUs can perform parallel operations on multiple sets of data, so they are commonly used for non-graphical tasks such as machine learning and scientific computation.

260
00:21:45,760 --> 00:21:49,040
So A CPU has an average of 4 to 16 processor cores.

261
00:21:49,320 --> 00:21:51,680
A GPU can have thousands of processor cores.

262
00:21:51,680 --> 00:21:55,280
So something that has 48 GPUs could have as many as 40,000 cores.

263
00:21:55,520 --> 00:21:58,160
Here's an image I grabbed right off the NVIDIA website.

264
00:21:58,400 --> 00:21:59,920
And so it really illustrates

265
00:22:00,040 --> 00:22:08,160
very well, like how this would be really good for machine learning or neural networks, because neural networks have a bunch of nodes.

266
00:22:08,160 --> 00:22:09,520
They're very repetitive tasks.

267
00:22:09,520 --> 00:22:12,800
If you can spread them across a lot of cores, that's going to work out really great.

268
00:22:13,040 --> 00:22:21,520
So GPUs are suited for repetitive and highly parallel computing tasks, such as rendering graphics, cryptocurrency mining, deep learning, and machine learning.

269
00:22:26,160 --> 00:22:27,080
We're talking about CUDA.

270
00:22:27,080 --> 00:22:29,120
Before we can, let's talk about what NVIDIA is.

271
00:22:29,120 --> 00:22:34,400
So NVIDIA is a company that manufactures graphical processing units for gaming and professional markets.

272
00:22:34,400 --> 00:22:36,320
If you play video games, you've heard of NVIDIA.

273
00:22:36,320 --> 00:22:37,040
So what is CUDA?

274
00:22:37,040 --> 00:22:40,160
It is the Compute Unified Device Architecture.

275
00:22:40,400 --> 00:22:49,920
It is a parallel computing platform and API by NVIDIA that allows developers to use CUDA-enabled GPUs for general-purpose computing on GPUs, so GPGUs.

276
00:22:50,640 --> 00:22:53,360
All major deep learning frameworks are integrated with NVIDIA Deep

277
00:22:53,680 --> 00:22:54,640
learning SDK.

278
00:22:54,880 --> 00:22:59,440
The NVIDIA Deep Learning SDK is a collection of NVIDIA libraries for deep learning.

279
00:22:59,680 --> 00:23:04,400
One of those libraries is the CUDA Deep Neural Network Library, so CUDNN.

280
00:23:04,560 --> 00:23:11,880
So CUDNN provides highly tuned implementations for standard routines such as forward and back convolution.

281
00:23:11,880 --> 00:23:19,200
Convolution is really great for computer vision, pooling, normalization, activation layers.

282
00:23:19,600 --> 00:23:29,840
So, in the Azure certification for the AI 900, they're not going to be talking about CUDA, but if you understand these two things, you'll understand why GPUs really matter, okay?

283
00:23:35,280 --> 00:23:39,480
All right, let's get an easy introduction into machine learning pipelines.

284
00:23:39,480 --> 00:23:43,680
So this one is definitely not an exhaustive one, and we're definitely going to see more complex ones.

285
00:23:44,040 --> 00:23:46,400
throughout this course, but let's get to it here.

286
00:23:46,400 --> 00:23:49,600
So starting on the left-hand side, we might start with data labeling.

287
00:23:49,840 --> 00:23:56,880
This is very important when you're doing supervised learning because you need to label your data so that the ML model can learn by example during training.

288
00:23:57,600 --> 00:24:06,240
This stage and the feature engineering stage is considered pre-processing because we are preparing our data to be trained for the model.

289
00:24:06,760 --> 00:24:14,200
When we want to feature engineering, the idea here is that ML models can only work with numerical data, so you'll need to translate it into a format that it can understand.

290
00:24:14,200 --> 00:24:19,520
So extract out the important data that the ML model needs to focus on.

291
00:24:19,920 --> 00:24:20,400
Okay.

292
00:24:21,120 --> 00:24:22,320
Then there's the training step.

293
00:24:22,320 --> 00:24:24,560
So your model needs to learn how to become smarter.

294
00:24:24,560 --> 00:24:27,920
It will perform multiple iterations, getting smarter with each iteration.

295
00:24:28,560 --> 00:24:32,400
You might also have a hyperparameter tuning step here.

296
00:24:32,560 --> 00:24:34,400
It says tuning, but should say tuning.

297
00:24:35,480 --> 00:24:37,480
But the ML model can have different parameters.

298
00:24:37,480 --> 00:24:41,600
So you can use ML to try out many different parameters to optimize the outcome.

299
00:24:41,840 --> 00:24:46,200
When you get to deep learning, it's impossible to tweak the parameters by hand.

300
00:24:46,200 --> 00:24:49,120
So you have to use hyperparameter tuning.

301
00:24:49,120 --> 00:24:51,440
Then you have serving, sometimes known as deploying.

302
00:24:52,080 --> 00:24:57,120
But when we say deploy, we talk about the entire pipeline, not necessarily just the ML model step.

303
00:24:57,120 --> 00:24:59,600
So we need to make an ML model accessible.

304
00:24:59,600 --> 00:25:03,120
So we serve it by hosting it in a virtual machine or container.

305
00:25:03,640 --> 00:25:10,000
When we're talking about Azure Machine Learning, it's either going to be an Azure Kubernetes Service or Azure Container Instance.

306
00:25:10,320 --> 00:25:11,960
And you have inference.

307
00:25:11,960 --> 00:25:16,960
So inference is the act of requesting to make a prediction.

308
00:25:17,200 --> 00:25:22,480
So you send your payload with either CSV or whatever, and you get back the results.

309
00:25:22,640 --> 00:25:24,960
You have a real-time endpoint and batch processing.

310
00:25:24,960 --> 00:25:29,280
So real-time is just, batch can be real-time as well, but generally it's slower.

311
00:25:29,520 --> 00:25:33,560
But the idea is that, am I making a single item prediction or am I giving you a

312
00:25:33,680 --> 00:25:34,840
bunch of data at once.

313
00:25:34,840 --> 00:25:37,480
And again, this is a very simplified ML pipeline.

314
00:25:37,480 --> 00:25:40,320
I'm sure we'll revisit an ML pipeline later in this course.

315
00:25:44,760 --> 00:25:48,720
So let's compare the terms forecasting and prediction.

316
00:25:48,720 --> 00:25:51,360
So forecasting, you make a prediction with relevant data.

317
00:25:51,680 --> 00:25:55,280
It's great for analysis of trends, and it's not guessing.

318
00:25:55,680 --> 00:25:58,880
And when you're talking about prediction, this is where you make a prediction without relevant data.

319
00:25:58,880 --> 00:26:00,960
You use statistics to predict future outcomes.

320
00:26:00,960 --> 00:26:03,920
It's more of guessing, and it uses decision theory.

321
00:26:04,080 --> 00:26:11,200
So imagine you have a bunch of data, and the idea is you're going to infer from that data, okay, maybe it's A, maybe it's B, maybe it's C.

322
00:26:11,440 --> 00:26:14,680
And for prediction, you don't have really much data, so you're

323
00:26:14,760 --> 00:26:19,520
Going to have to kind of invent it, and the idea is that you'll figure out what the outcome is there.

324
00:26:19,600 --> 00:26:24,640
These are extremely broad terms, but just so you have a high-level view of these two things.

325
00:26:24,640 --> 00:26:31,680
Okay, so what are performance or evaluation metrics?

326
00:26:31,680 --> 00:26:34,640
Well, they are used to evaluate different machine learning algorithms.

327
00:26:34,640 --> 00:26:35,600
The idea is...

328
00:26:36,120 --> 00:26:43,600
when your machine learning makes a prediction, these are the metrics you're using to evaluate to determine, is your ML model working as you intended?

329
00:26:43,840 --> 00:26:46,560
So, for different types of problems, different metrics matter.

330
00:26:46,560 --> 00:26:48,560
This is absolutely not an exhaustive list.

331
00:26:48,880 --> 00:26:56,000
I just want you to get your exposure to these words and things, so that when you see them, you go, Okay, I'll come back here and refer to this.

332
00:26:56,560 --> 00:26:59,120
But lots of these, it's not necessarily to remember.

333
00:26:59,120 --> 00:27:00,880
But classification metrics, you should know.

334
00:27:01,120 --> 00:27:06,160
So classification, we have accuracy, precision, recall, F1 score, ROC and AUC.

335
00:27:06,160 --> 00:27:09,920
For regression metrics, we have MSC, RMSCE, MAE.

336
00:27:10,240 --> 00:27:13,320
Ranking metrics, we have MMR, DCG, NDCG.

337
00:27:13,320 --> 00:27:15,360
Statistical metrics, we have correlation.

338
00:27:15,600 --> 00:27:19,520
Computer vision metrics, we have PSNR, SSIM, IOU.

339
00:27:19,640 --> 00:27:22,240
NLP metrics, we have perplexity, blue, meteor, rogue.

340
00:27:22,480 --> 00:27:24,960
Deep learning related metrics, we have inception score.

341
00:27:25,200 --> 00:27:26,280
I cannot say this

342
00:27:26,360 --> 00:27:31,600
person's name, or I'm assuming it's a person, but this inception distance.

343
00:27:31,880 --> 00:27:34,000
And there are two categories of evaluation metrics.

344
00:27:34,000 --> 00:27:40,960
We have internal evaluation, so metrics used to evaluate the internals of an ML model, so accuracy, F1 score, precision, recall.

345
00:27:41,200 --> 00:27:50,720
I call them the famous 4, used in all kinds of models, and external evaluation metrics used to evaluate the final prediction of an ML model.

346
00:27:50,960 --> 00:27:54,360
So yeah, don't get too worked up here.

347
00:27:54,360 --> 00:27:55,280
I know that's a lot of stuff

348
00:27:55,880 --> 00:27:58,160
The ones that matter, we will see again, okay?

349
00:28:03,120 --> 00:28:04,840
Let's take a look at Jupyter Notebooks.

350
00:28:04,840 --> 00:28:11,120
So these are web-based applications for authoring documents that combine live code, narrative text, equations, visualizations.

351
00:28:11,680 --> 00:28:16,160
So if you're doing data science or you're building ML models, you absolutely are going to be working with Jupyter Notebooks.

352
00:28:16,160 --> 00:28:20,720
They're always integrated into cloud service providers' ML tools.

353
00:28:22,000 --> 00:28:24,560
So Jupyter Notebook actually came about from IPython.

354
00:28:24,560 --> 00:28:27,280
So IPython is the precursor of it, and they extracted that feature out.

355
00:28:27,280 --> 00:28:28,400
It became Jupyter Notebook.

356
00:28:28,720 --> 00:28:32,720
IPython is now a kernel to run Python.

357
00:28:32,720 --> 00:28:37,840
So when you execute out Python code here, it's using IPython, which is just a version of Python.

358
00:28:38,320 --> 00:28:44,080
Jupyter Notebooks were overhauled and better integrated into an IDE called Jupyter Labs, which we'll talk about here in a moment.

359
00:28:44,280 --> 00:28:49,840
And you generally want to open Notebooks and Labs, the legacy web-based interfaces known as Jupyter Classic Notebooks.

360
00:28:50,000 --> 00:28:51,440
So this is what the old one looks like.

361
00:28:51,440 --> 00:28:51,800
You can still

362
00:28:51,880 --> 00:28:54,280
Open them up, but everyone uses JupyterLabs now.

363
00:28:54,280 --> 00:28:55,920
Okay, so let's talk about JupyterLabs.

364
00:28:56,160 --> 00:28:58,880
JupyterLabs is the next generation web-based user interface.

365
00:28:58,960 --> 00:29:04,080
All familiar features of the classic Jupyter Notebook is in a flexible, powerful user interface.

366
00:29:04,400 --> 00:29:08,640
It has notebooks, a terminal, a text editor, a file browser, rich outputs.

367
00:29:08,960 --> 00:29:12,600
JupyterLabs will eventually replace the classic Jupyter Notebooks.

368
00:29:12,600 --> 00:29:13,280
So there you go.

369
00:29:18,040 --> 00:29:22,720
We keep mentioning regression, but let's talk about it in more detail here so we kind of understand the concept.

370
00:29:22,720 --> 00:29:27,400
So regression is the process of finding a function to record a labeled data set.

371
00:29:27,400 --> 00:29:28,440
Notice it says labeled.

372
00:29:28,440 --> 00:29:32,560
That means it's going to be for supervised learning into a continuous variable number.

373
00:29:32,560 --> 00:29:35,600
So another way to say it is predict this variable in the future.

374
00:29:35,600 --> 00:29:38,320
So the future just means like that continuous variable.

375
00:29:38,320 --> 00:29:42,480
It doesn't have to be time, but that's just a good example of regression.

376
00:29:43,080 --> 00:29:45,600
So what will the temperature be next week?

377
00:29:45,600 --> 00:29:47,440
So will it be 20 Celsius?

378
00:29:47,440 --> 00:29:48,640
How would we determine that?

379
00:29:48,640 --> 00:29:53,920
Well, we would have vectors, so dots, that are plotted on a graph that has multiple dimensions.

380
00:29:54,160 --> 00:29:56,360
The dimensions could be greater than just X&Y.

381
00:29:56,360 --> 00:29:57,440
You could have many.

382
00:29:58,240 --> 00:29:59,600
And then you have a regression line.

383
00:29:59,600 --> 00:30:00,000
This is the line.

384
00:30:00,160 --> 00:30:07,360
that's going through our data set, and that's going to help us figure out how to predict the value.

385
00:30:07,360 --> 00:30:08,240
So how would we do that?

386
00:30:08,240 --> 00:30:12,960
Well, we would need to calculate the distance of a vector from the regression line, which is called an error.

387
00:30:13,320 --> 00:30:17,760
And so different regression algorithms use the error to predict different variable, future variables.

388
00:30:17,760 --> 00:30:25,400
So just to look at this graphic here, so here is our regression line, and here is a dot, like a vector, a piece of information.

389
00:30:25,400 --> 00:30:38,080
And this distance from the line, the actual distance is what we're going to use in our ML model to figure out if we were to plot another line up here, right, you know, we would compare this line to all the other lines, okay?

390
00:30:38,080 --> 00:30:39,840
And that's how we'd find similarity.

391
00:30:40,240 --> 00:30:46,320
And what we'll commonly see for this is mean squared error, root mean squared error, mean absolute error.

392
00:30:46,320 --> 00:30:49,200
So MSE, MRSE, and MAE, okay?

393
00:30:54,560 --> 00:30:57,600
Let's take a closer look at the concepts of classification.

394
00:30:57,600 --> 00:31:01,840
So classification is the process of finding a function to divide a labeled data set.

395
00:31:01,840 --> 00:31:06,640
So again, this is supervised learning into classes or categories.

396
00:31:06,640 --> 00:31:09,520
So predict a category to apply to the inputted data.

397
00:31:09,520 --> 00:31:11,440
So will it rain next Saturday?

398
00:31:11,440 --> 00:31:12,560
Will it be sunny or rainy?

399
00:31:12,560 --> 00:31:18,480
So we have our data set and the idea is we're drawing through this a classification line to divide the data set.

400
00:31:18,720 --> 00:31:22,880
So regression, we're measuring the line to or the vectors to the line.

401
00:31:23,080 --> 00:31:24,440
And this one is just what size

402
00:31:24,520 --> 00:31:25,360
Of the line is it on?

403
00:31:25,360 --> 00:31:26,840
If it's on this side, then it's sunny.

404
00:31:26,840 --> 00:31:28,720
If it's on this side, it's rainy.

405
00:31:29,080 --> 00:31:43,280
For classification algorithms, we got logistic regression, decision trees, random forests, neural networks, naive Bayes, K-nearest neighbor, also known as KNN, and support vector machines (SVMs).

406
00:31:48,360 --> 00:31:50,080
Let's take a closer look at clustering.

407
00:31:50,080 --> 00:31:53,040
So clustering is the process of grouping unlabeled data.

408
00:31:53,040 --> 00:31:58,200
So unlabeled data means it's unsupervised learning based on similarities and differences.

409
00:31:58,200 --> 00:32:01,840
So the outcome could be grouped data based on similarities or differences.

410
00:32:01,960 --> 00:32:03,600
I guess it's the same description up here.

411
00:32:04,240 --> 00:32:09,440
But imagine we have a graph and we have data, and the idea is we draw boundaries around that to see

412
00:32:09,840 --> 00:32:15,800
Similar groups, so maybe we're recommending purchases to Windows computers, or recommending purchases to Mac computers.

413
00:32:15,800 --> 00:32:22,400
Now, remember, this is unlabeled data, so the label is being inferred, or they're just saying these things are similar, right?

414
00:32:22,960 --> 00:32:28,720
So, clustering algorithms, we've got K-means, K-medoids, a density-based hierarchical, okay?

415
00:32:33,800 --> 00:32:46,800
Hey, this is Andrew Brown from Exam Pro, and we're looking at the confusing matrix, and this is a table to visualize the model predictions, the predicted versus the ground truth labels, the actual, also known as an error matrix, and they are useful for classification problems to determine if...

416
00:32:48,240 --> 00:32:51,320
if our classification is working as we think it is.

417
00:32:51,320 --> 00:32:56,320
So imagine we have a question, how many bananas did this person eat or these people eat?

418
00:32:56,600 --> 00:33:01,000
And so we have this kind of box here where we have predicted versus actual.

419
00:33:01,000 --> 00:33:05,680
And it's really comparing the ground truth and what the model predicted, right?

420
00:33:06,520 --> 00:33:14,720
And so on the exam, they'll ask you questions like, okay, well, imagine that, and they might not even say yes or no, maybe like zero and one.

421
00:33:15,160 --> 00:33:21,360
And so what they're saying is, imagine you want to tell us the true positives, right?

422
00:33:21,360 --> 00:33:29,920
And so the idea is they won't show you the labels here, but you know one and one would be a true positive, and zero and zero would be a false negative, okay?

423
00:33:30,200 --> 00:33:35,680
Another thing they'll ask you about these confusion matrixes is the size of them.

424
00:33:35,680 --> 00:33:40,160
So the idea is that we're looking right now at a, oops,

425
00:33:40,920 --> 00:33:41,720
Just going to erase that there.

426
00:33:41,720 --> 00:33:47,920
But we're looking at a binary classifier because we have one label and just two labels, right?

427
00:33:47,920 --> 00:33:48,800
One and two.

428
00:33:49,280 --> 00:33:49,600
Okay?

429
00:33:49,600 --> 00:33:51,520
But you could have three, say one, two, and three.

430
00:33:51,520 --> 00:33:52,640
So how would you calculate that?

431
00:33:52,640 --> 00:33:54,800
Well, there would just be a third cell over here.

432
00:33:55,680 --> 00:34:00,320
You know, and it's just going to be actual and predicted because we're only going to have ground truth versus prediction.

433
00:34:00,520 --> 00:34:02,480
And so that's how you'll know it will be 6.

434
00:34:02,480 --> 00:34:03,440
The size will be 6.

435
00:34:03,440 --> 00:34:05,280
Might not say cells, but it'll just say 6.

436
00:34:05,280 --> 00:34:05,680
Okay?

437
00:34:11,040 --> 00:34:14,880
So to understand anomaly detection, let's define quickly what is an anomaly.

438
00:34:14,880 --> 00:34:19,440
So an abnormal thing that is marked by deviation from the norm or standard.

439
00:34:19,440 --> 00:34:24,400
So anomaly detection is the process of finding outliers within a data set called anomaly.

440
00:34:24,400 --> 00:34:30,080
So detecting when a piece of data or access patterns appear suspicious or malicious.

441
00:34:30,320 --> 00:34:38,760
So use cases for anomaly detection can be data cleaning, intrusion detection, fraud detection, system health monitoring, event detection, and sensory

442
00:34:38,840 --> 00:34:44,480
or sensor networks, ecosystem disturbances, detection of critical and cascading flaws.

443
00:34:44,920 --> 00:34:58,880
Anomaly detections by hand is a very tedious process, so using ML for anomaly detection is more efficient and accurate, and Azure has a service called Anomaly Detector, detects anomalies in data to quickly identify and troubleshoot issues.

444
00:35:03,480 --> 00:35:10,000
So computer vision is when we use machine learning neural networks to gain high-level understanding of digital images or videos.

445
00:35:10,000 --> 00:35:14,960
So for computer vision deep learning algorithms, we have convolutional neural networks.

446
00:35:15,200 --> 00:35:17,280
These are for image and video recognition.

447
00:35:17,280 --> 00:35:22,640
They're inspired after how the human eye actually processes information and sends it back to the brain to be processed.

448
00:35:22,880 --> 00:35:28,440
You have recurrent neural networks, RNNs, which are generally used for handwriting recognition or speech recognition.

449
00:35:28,440 --> 00:35:32,960
Of course, these algorithms have other applications, but these are the most common use cases for them.

450
00:35:33,840 --> 00:35:40,560
For types of computer vision, we have image classification, so look at an image or video and classify its place in a category.

451
00:35:40,560 --> 00:35:45,520
Object detection, so identify objects within an image or video and apply labels and location boundaries.

452
00:35:45,920 --> 00:35:52,160
Semantic segmentation, so identify segments or objects by drawing pixel masks around them, so great for objects and movement.

453
00:35:52,600 --> 00:35:59,440
Image analysis, so analyze an image or video to apply descriptive context labels.

454
00:35:59,600 --> 00:36:04,560
So maybe an employee is sitting at a desk in Tokyo would be something that image analysis would do.

455
00:36:04,880 --> 00:36:12,480
Optical character recognition or OCR, find text in images or videos and extract them into digital text for editing.

456
00:36:12,480 --> 00:36:19,360
Facial detection, so detect faces in a photo or video and draw a location boundary and label their expression.

457
00:36:19,360 --> 00:36:22,400
So for computer vision, to some things around Azure

458
00:36:22,600 --> 00:36:23,320
Microsoft services.

459
00:36:23,320 --> 00:36:24,880
There's one called Seeing AI.

460
00:36:25,040 --> 00:36:27,760
It's an AI app developed by Microsoft for iOS.

461
00:36:28,400 --> 00:36:35,440
So you use your device camera to identify people and objects, and the app audibly describes those objects for people with visual impairments.

462
00:36:35,440 --> 00:36:36,800
It's totally free if you have an iOS app.

463
00:36:37,120 --> 00:36:40,800
I have an Android phone, so I cannot use it, but I hear it's great.

464
00:36:40,800 --> 00:36:43,840
Some of the Azure Computer Vision Service offerings is computer vision.

465
00:36:43,840 --> 00:36:48,120
So analyze images and videos, extract descriptions, tags, objects, and text.

466
00:36:48,520 --> 00:36:53,840
Custom vision, so custom image classification, object detection models using your own images.

467
00:36:54,160 --> 00:36:57,920
Face, so detect and identify people and emotions and images.

468
00:36:58,240 --> 00:37:04,560
Form, recognizer, so translate, scan documents into key value or tabular editable data.

469
00:37:09,040 --> 00:37:17,320
So natural language processing, also known as NLP, is machine learning that can understand the context of a corpus, corpus being a body of related text.

470
00:37:17,600 --> 00:37:24,160
So NLPs enable you to analyze and interpret text within documents and e-mail messages, interpret or contextualize spoken tokens.

471
00:37:24,400 --> 00:37:39,680
So for example, maybe customer sentiment analysis, whether a customer's happy or sad, synthesize speech, so a voice assistant talking to you, automatically translates spoken or written phrases and sentences between languages, interprets spoken or written commands and determine appropriate actions.

472
00:37:39,880 --> 00:37:46,080
A very famous example for a voice assistant specifically or virtual assistant for Microsoft is Cortana.

473
00:37:46,680 --> 00:37:51,360
It uses the Bing search engine to perform tasks such as setting reminders and answering questions for the user.

474
00:37:52,000 --> 00:37:56,000
And if you're on a Windows 10 machine, it's very easy to activate Cortana by accident.

475
00:37:56,400 --> 00:38:00,440
When we were talking about Azure's MLP offering, we have text and analytics.

476
00:38:00,440 --> 00:38:02,720
So sentiment analysis to find out what customers think.

477
00:38:03,040 --> 00:38:06,600
Find topic-relevant phrases using key phrase extraction.

478
00:38:06,600 --> 00:38:09,280
Identify the language of the text with language detection.

479
00:38:09,560 --> 00:38:13,280
Detect and categorize entities in your text with named entity recognition.

480
00:38:13,280 --> 00:38:16,480
For translator, we have real-time text translation and multi-language support.

481
00:38:17,120 --> 00:38:22,000
For speech service, we have transcribe audible speech into readable searchable text.

482
00:38:22,280 --> 00:38:26,560
And then we have language understanding, also known as LUIS.

483
00:38:27,360 --> 00:38:35,600
Natural language processing service that enables you to understand human language in your own application, website, chatbots, IoT device, and more.

484
00:38:35,600 --> 00:38:40,000
When we talk about conversational AI, it usually generally uses NLP.

485
00:38:40,000 --> 00:38:41,920
So that's where you'll see that overlap next, okay?

486
00:38:46,560 --> 00:38:51,520
Let's take a look here at conversational AI, which is technology that can participate in conversations with humans.

487
00:38:51,520 --> 00:38:59,800
So we have chat bots, voice assistants, and interactive voice recognition systems, which is like the second version to interactive voice response systems.

488
00:38:59,800 --> 00:39:06,640
So you know when you call in and they say press these numbers, that is a response system and a recognition system is when they can actually take human

489
00:39:06,960 --> 00:39:09,280
speech and translate that into action.

490
00:39:09,280 --> 00:39:18,320
So the use cases here would be online customer support, replaces human agents for replying about customer FAQs, maybe shipping questions, anything about customer support.

491
00:39:18,680 --> 00:39:22,400
Accessibility, so voice operate UI for those who are visually impaired.

492
00:39:22,920 --> 00:39:26,400
HR processes, so employee training, onboarding, updating employee information.

493
00:39:26,960 --> 00:39:29,440
I've never seen it used like that, but that's what they say is a use case.

494
00:39:29,440 --> 00:39:31,360
Healthcare, accessible, affordable healthcare.

495
00:39:31,600 --> 00:39:33,120
So maybe you're doing a claim process.

496
00:39:33,480 --> 00:39:38,720
I've never seen this, but maybe in the US where you do more of your claims and everything is privatized, it makes more sense.

497
00:39:38,960 --> 00:39:48,080
Internet of things, so IoT devices, so Amazon Alexa, Apple Siri, Google Home, and I suppose Cortana, but it doesn't really have a particular device, so that's why I didn't list it there.

498
00:39:48,320 --> 00:39:51,360
Computer software, so autocomplete search on phone or desktop.

499
00:39:51,360 --> 00:39:53,600
So that would be Cortana, something it could do.

500
00:39:54,400 --> 00:40:03,040
For the two services that are around conversational AI, for Azure, we have Q&A Maker, so create a conversational question and answer bot from your existing content.

501
00:40:03,480 --> 00:40:11,080
also known as a knowledge base, and Azure Bot Service, intelligent serverless bot service that scales on demand, used for creating, publishing, managing bots.

502
00:40:11,080 --> 00:40:15,120
So the idea is you make your bot here, and then you deploy it with this.

503
00:40:15,120 --> 00:40:15,440
Okay?

504
00:40:20,400 --> 00:40:25,920
Let's take a look here at Responsible AI, which focuses on ethical, transparent, and accountable uses of AI technology.

505
00:40:25,920 --> 00:40:30,000
Microsoft puts into practice Responsible AI via its six Microsoft AI principles.

506
00:40:30,440 --> 00:40:32,880
This whole thing is invented by Microsoft.

507
00:40:33,240 --> 00:40:39,400
And so, it's not necessarily a standard, but it's something that Microsoft is pushing hard to have people adopt.

508
00:40:39,400 --> 00:40:39,600
Okay?

509
00:40:40,000 --> 00:40:41,840
So the first thing we have is fairness.

510
00:40:41,840 --> 00:40:45,120
So this is an AI system which should treat all people fairly.

511
00:40:45,280 --> 00:40:49,280
We have reliability and safety, and AI systems should perform reliably and safely.

512
00:40:49,600 --> 00:40:53,120
Privacy and security, AI systems should be secure and respect privacy.

513
00:40:53,120 --> 00:40:56,720
Inclusiveness, AI systems should empower everyone and engage people.

514
00:40:56,720 --> 00:40:59,480
Transparency, AI systems should be understandable.

515
00:40:59,480 --> 00:41:00,240
Accountability,

516
00:41:00,480 --> 00:41:06,080
People should be accountable for AI systems, and we need to know these in greater detail.

517
00:41:06,080 --> 00:41:08,960
So we're going to have a short little video on each of these, okay?

518
00:41:13,360 --> 00:41:14,760
The first on our list is fairness.

519
00:41:14,760 --> 00:41:17,360
So AI systems should treat all people fairly.

520
00:41:17,360 --> 00:41:19,600
So an AI system can reinforce existing social...

521
00:41:20,120 --> 00:41:27,040
Societal stereotypical bias can be introduced during the development of a pipeline.

522
00:41:27,080 --> 00:41:37,040
So an AS system that are used to allocate or withhold opportunities, resources, or information in domains such as criminal justice, employment and hiring, finance, and credit.

523
00:41:37,280 --> 00:41:46,240
So an example here would be an ML model designed to select a final applicant for a hiring pipeline without incorporating any bias based on gender, ethnicity, or may result in an unfair advantage.

524
00:41:46,480 --> 00:41:50,040
So Azure ML can tell you how each feature can influence a model's prediction.

525
00:41:50,320 --> 00:41:58,320
For bias, one thing that could be of use is Fairlearn, so it's an open source Python project to help data scientists to improve fairness in the AI systems.

526
00:41:58,760 --> 00:42:08,000
At the time that I made this course, a lot of their stuff is still in preview, so the fairness component is not 100% there, but it's great to see that they're getting that along.

527
00:42:12,440 --> 00:42:18,720
So we are on to our second AI principle for Microsoft, and this one is AI systems should perform reliably and safely.

528
00:42:18,960 --> 00:42:24,160
So AI software must be rigorously tested to ensure they work as expected before release to the end user.

529
00:42:24,400 --> 00:42:32,640
If there are scenarios where AI is making mistakes, it is important to release a report quantified risks and harms to end users so they are informed of the shortcomings of an AI solution.

530
00:42:32,880 --> 00:42:34,480
Something you should really remember for the exam.

531
00:42:34,560 --> 00:42:35,600
They'll definitely ask that.

532
00:42:36,160 --> 00:42:37,520
AI, where concern

533
00:42:38,000 --> 00:42:40,120
for reliability and safety for humans is critically important.

534
00:42:40,400 --> 00:42:46,160
Autonomous vehicles, health diagnosis, suggestions, prescriptions, and autonomous weapon systems.

535
00:42:46,400 --> 00:42:47,960
They didn't mention this in their content.

536
00:42:47,960 --> 00:42:50,440
And I was just like doing some additional research.

537
00:42:50,440 --> 00:42:56,240
I'm like, yeah, you really don't want mistakes when you have automated weapons or ethically you shouldn't have them at all.

538
00:42:56,240 --> 00:42:58,640
But hey, that's just how the world works.

539
00:42:58,640 --> 00:43:00,080
But yeah, this is this category here.

540
00:43:05,080 --> 00:43:07,360
We're on to our third Microsoft AI principle.

541
00:43:07,440 --> 00:43:10,160
AI systems should be secure and respect privacy.

542
00:43:10,160 --> 00:43:14,320
So AI can require vast amounts of data to train deep machine ML models.

543
00:43:14,320 --> 00:43:19,520
The nature of an ML model may require personally identifiable information, so PIIs.

544
00:43:20,320 --> 00:43:24,760
It is important that we ensure protection of user data, that it is not leaked or disclosed.

545
00:43:24,760 --> 00:43:28,000
In some cases, ML models can be run locally on a user's device, so they're

546
00:43:28,720 --> 00:43:32,640
PIIs remain on their device, avoiding the vulnerability.

547
00:43:32,800 --> 00:43:35,600
This is like edge computing, so that's the concept there.

548
00:43:35,880 --> 00:43:44,880
AI security principles to check malicious actors, so data origin and lineage, data use internal versus external, data corruption considerations, anomaly detection.

549
00:43:44,880 --> 00:43:45,520
So there you go.

550
00:43:50,040 --> 00:43:52,320
We're on to the 4th Microsoft AI principle.

551
00:43:52,320 --> 00:43:54,640
So AI systems should empower everyone and engage people.

552
00:43:54,880 --> 00:43:59,240
If we can design AI solutions for the minority of users, they can design AI solutions for the majority of users.

553
00:43:59,240 --> 00:44:04,720
So when we're talking about minority groups, we're talking about physical ability, gender, sexual orientation, ethnicity, other factors.

554
00:44:04,880 --> 00:44:06,080
This one's really simple.

555
00:44:06,480 --> 00:44:10,480
In terms of practicality, it doesn't 100% make sense, because if you've worked with...

556
00:44:11,720 --> 00:44:14,520
groups that are deaf and blind developing technology for them.

557
00:44:14,520 --> 00:44:24,320
A lot of times they need specialized solutions, but the approach here is that if we can design for the minority, we can design for all, that is the principle there, so that's what we need to know, okay?

558
00:44:28,920 --> 00:44:30,320
Let's take a look here at transparency.

559
00:44:30,320 --> 00:44:32,240
So AI systems should be understandable.

560
00:44:32,240 --> 00:44:37,440
So interpretability and intelligibility is when the end user can understand the behavior of UI.

561
00:44:37,440 --> 00:44:44,720
So transparency of AI systems can result in mitigating unfairness, help developers debug their AI systems, gaining more trust from our users.

562
00:44:44,960 --> 00:44:52,240
Those who build AI systems should be open about why they're using AI, open about the limitations of the AI systems.

563
00:44:52,560 --> 00:44:58,840
Adopting an open source AI framework can provide transparency, at least from a technical perspective on the internal working

564
00:44:59,440 --> 00:45:00,800
of an AI system.

565
00:45:04,880 --> 00:45:07,680
We are on to the last Microsoft AI principle here.

566
00:45:07,680 --> 00:45:09,800
People should be accountable for AI systems.

567
00:45:09,800 --> 00:45:14,240
So the structure put in place to consistently enacting AI principles and taking them into account.

568
00:45:14,320 --> 00:45:20,400
AI systems should work within frameworks of governments, organizational principles, ethical and legal standards that are clearly defined.

569
00:45:21,200 --> 00:45:26,320
Principles guide Microsoft on how they develop, sell and advocate when working with third parties and this push

570
00:45:27,000 --> 00:45:32,640
Towards regulation towards a principle, so this is Microsoft saying, Hey, everybody adopt our model.

571
00:45:33,200 --> 00:45:36,720
There aren't many other models, so I guess it's great that Microsoft is taking the charge there.

572
00:45:36,720 --> 00:45:45,200
I just feel that it needs to be a bit more well-developed, but what we'll do is look at some more practical examples so we can better understand how to apply their principles.

573
00:45:49,560 --> 00:45:56,400
So if we really want to understand how to apply the Microsoft AI principles, they've created this nice little tool via a free web app for practical scenarios.

574
00:45:56,400 --> 00:45:58,560
So they have these cards, you can read through these cards.

575
00:45:58,800 --> 00:46:00,880
They're color-coded for different scenarios.

576
00:46:01,040 --> 00:46:01,920
And there's a website.

577
00:46:01,920 --> 00:46:04,560
So let's go take a look at that and see what we can learn, okay?

578
00:46:09,000 --> 00:46:16,960
All right, so we're here on the guidelines for human-AI interaction so we can better understand how to put into practice the Microsoft AI principles.

579
00:46:17,200 --> 00:46:21,280
They have 18 cards, and let's work our way through here and see the examples.

580
00:46:21,280 --> 00:46:23,840
The first one on our list, make clear what the system can do.

581
00:46:23,840 --> 00:46:26,640
Help the users understand what the AI system is capable of doing.

582
00:46:26,960 --> 00:46:32,560
So here, PowerPoint Quick Start builds an online outline to help you get started researching a subject.

583
00:46:32,720 --> 00:46:37,120
It displays suggested topics that help you understand the feature's capability.

584
00:46:37,640 --> 00:46:41,840
Then we have the Bing app shows examples of types of things you can search for.

585
00:46:42,960 --> 00:46:46,400
Apple Watch displays all metrics it tracks and explains how.

586
00:46:46,400 --> 00:46:50,880
Going on the second card, we have make clear how well the system can do what it can do.

587
00:46:51,520 --> 00:47:01,040
So here we have Office new companion experience ideas dock alongside your work and offers one-click assistance with grammar, design, data insights, richer images, and more.

588
00:47:01,200 --> 00:47:06,880
The unassuming term ideas coupled with label previews help set expectations and presented suggestions.

589
00:47:07,480 --> 00:47:13,600
The recommender in Apple Music uses language such as we will think you'll like to communicate uncertainty.

590
00:47:15,360 --> 00:47:29,760
The help page for Outlook Webmail explains the filtering into focused and other and we'll start working right away, but we'll get better with use, making clear the mistakes will happen and you teach the product and set overrides onto our red cards here.

591
00:47:30,480 --> 00:47:36,800
We have time services based on context, time when to act or interrupt based on the user's current task and environment.

592
00:47:37,320 --> 00:47:47,760
When it's time to leave for appointments, Outlook sends a time to leave notification with directions for both driving and public transit, taking into account current location, event location, real-time traffic information.

593
00:47:49,360 --> 00:47:55,200
And then we have after using Apple Maps routing, it remembers when you're parked your car, when you open the app.

594
00:47:55,200 --> 00:47:59,040
After a little while, it suggests routing to the location of the parked car.

595
00:47:59,280 --> 00:48:03,040
All these Apple examples make me think that Microsoft has some kind of partnership with Apple.

596
00:48:04,400 --> 00:48:09,680
I guess Microsoft or Bill Gates did own Apple shares, so maybe they're closer than we think.

597
00:48:10,480 --> 00:48:15,680
Show contextually relevant information, time when to act or interrupt based on user's current task and environment.

598
00:48:16,080 --> 00:48:24,400
Powered by machine learning, acronyms in Word helps you understand shorthand employed in your own work environment relative to current open document.

599
00:48:26,000 --> 00:48:32,400
On Walmart.com, when the user is looking at a product such as gaming console, it recommends accessories and games that would go with it.

600
00:48:33,240 --> 00:48:39,920
When a user searches for movies, Google shows results, including showtimes near the user's location for the current data.

601
00:48:40,240 --> 00:48:44,880
Onto our fifth card here, match-based, we didn't miss this one, right?

602
00:48:45,880 --> 00:48:46,320
Yeah, we did.

603
00:48:46,560 --> 00:48:48,160
Okay, so we're on the fifth one here.

604
00:48:48,160 --> 00:48:49,680
Match relevant social norms.

605
00:48:49,800 --> 00:48:55,000
Ensure experience is delivered in a way the users would expect, given the social cultural context.

606
00:48:55,000 --> 00:49:00,960
When editor identifies ways to improve writing style, prince optionals politely consider using.

607
00:49:01,560 --> 00:49:03,040
That's the Canadian way, being polite.

608
00:49:03,760 --> 00:49:12,560
Google Photos is able to recognize pets and use the wording, important cats and dogs, recognizing that for many, pets are an important part of one's family.

609
00:49:12,880 --> 00:49:13,760
And you know what?

610
00:49:13,880 --> 00:49:18,000
When I started renting my new house, I said, you know, is there a problem with dogs?

611
00:49:18,000 --> 00:49:21,720
And my landlord said, well, of course, pets are part of the family.

612
00:49:21,720 --> 00:49:22,960
And that was something I like to hear.

613
00:49:23,520 --> 00:49:31,440
Cortana uses semi-formal tone apologizing when unable to find a contact which is polite and socially appropriate.

614
00:49:31,440 --> 00:49:32,080
I like that.

615
00:49:33,440 --> 00:49:35,360
Okay, mitigate social biases.

616
00:49:35,360 --> 00:49:40,720
Ensure AI system, languages, and behaviors do not reinforce undesirable, unfair stereotypes and biases.

617
00:49:41,280 --> 00:49:45,920
My analytics summarizes how you spend your time at work, then suggests ways to work smarter.

618
00:49:45,920 --> 00:49:50,240
One way is to mitigate biases by using gender-neutral icons to represent important people.

619
00:49:50,240 --> 00:49:50,960
Sounds good to me.

620
00:49:51,480 --> 00:49:57,600
A Bing search for CEO or doctor shows images of diverse people in terms of gender and ethnicity.

621
00:49:57,600 --> 00:49:58,400
Sounds good to me.

622
00:49:59,120 --> 00:50:05,760
The predictive keyboard for Android suggests both genders when typing a pronoun starting with the letter H.

623
00:50:06,440 --> 00:50:13,600
We're on to our yellow cards to support efficient invocation, so make it easy to invoke or request AI system services when needed.

624
00:50:13,600 --> 00:50:21,440
So Flash Fill is a helpful time saver in Excel that can be easily invoked with on-canvas interactions that keep you in flow.

625
00:50:22,080 --> 00:50:24,640
On Amazon.com, oh hey, there you got Amazon.

626
00:50:24,800 --> 00:50:32,480
In addition to the system giving recommendations as you browse, you can manually invoke additional recommendations from the recommender for your menu.

627
00:50:33,080 --> 00:50:39,680
Design ideas in Microsoft PowerPoint can be invoked with the press of a button if needed.

628
00:50:39,760 --> 00:50:41,600
I cannot stand it when that pops up.

629
00:50:41,680 --> 00:50:43,600
I always have to tell it to leave me alone.

630
00:50:44,160 --> 00:50:49,360
Okay, support efficient dismissal.

631
00:50:51,040 --> 00:50:53,120
Oh, support efficient dismissal.

632
00:50:53,280 --> 00:50:53,600
Okay.

633
00:50:53,920 --> 00:50:58,000
Make it easy to dismiss or ignore undesired AI system services.

634
00:50:58,440 --> 00:50:59,360
Okay, this sounds good to me.

635
00:50:59,600 --> 00:51:03,600
Microsoft Forms allows you to create custom surveys, quizzes, polls, questionnaires, and forms.

636
00:51:03,600 --> 00:51:08,960
Some choices, questions trigger suggested options, position beneath the relevant question.

637
00:51:09,200 --> 00:51:11,360
The suggestion can be easily ignored and dismissed.

638
00:51:12,400 --> 00:51:19,600
Instagram allows the users to easily hide or report ads that have been suggested by AI by tapping the ellipses at the top of the right of the ad.

639
00:51:20,560 --> 00:51:25,520
Siri can be easily dismissed by saying, never mind.

640
00:51:27,440 --> 00:51:29,360
Always telling my Alexa, Never mind.

641
00:51:30,080 --> 00:51:37,280
Support efficient correction, make it easy to edit, refine, or recover the AI system when the AI system is wrong.

642
00:51:37,280 --> 00:51:43,000
So, Alt Auto Alt Text automatically generates alt text for photographs by using intelligent services in the cloud.

643
00:51:43,000 --> 00:51:46,080
Descriptions can be easily modified by clicking the Alt Text button.

644
00:51:46,360 --> 00:51:47,120
in the ribbon.

645
00:51:47,120 --> 00:51:52,080
Once you set a reminder with Siri, the UI displays a tap to edit link.

646
00:51:52,440 --> 00:52:02,400
When Bing automatically corrects spelling errors in search queries, it provides the option to revert to the query as originally typed with one click onto card number 10.

647
00:52:03,520 --> 00:52:07,400
Scope services when in doubt, so engage in disambiguous.

648
00:52:09,960 --> 00:52:15,600
disambiguation or gracefully degrade the AI system service when uncertain about a user's goal.

649
00:52:15,760 --> 00:52:23,600
So when auto-replacement word is uncertain of a correction, it engages in disambiguation by displaying multiple options you can select from.

650
00:52:24,160 --> 00:52:29,520
Siri will let you know it has trouble hearing if you don't respond or speak too softly.

651
00:52:29,840 --> 00:52:32,400
Bing Maps will provide multiple routing options when...

652
00:52:33,080 --> 00:52:35,040
when unable to recommend best one.

653
00:52:35,040 --> 00:52:36,480
We're on to card number 11.

654
00:52:36,720 --> 00:52:38,920
Make clear why the system did what it did.

655
00:52:38,920 --> 00:52:43,520
Enable users to access an explanation of why the AI system behaved as it did.

656
00:52:43,920 --> 00:52:48,560
Office Online recommends documents based on history and activity.

657
00:52:48,560 --> 00:52:52,880
Descriptive text above each document makes it clear why the recommendation is shown.

658
00:52:53,680 --> 00:53:01,920
Product recommendations on Amazon.com include why recommended link that shows what products in the user's shopping history and forms.

659
00:53:02,440 --> 00:53:03,520
the recommendations.

660
00:53:03,680 --> 00:53:09,760
Facebook enables you to access an explanation about why you are seeing each ad in the news feed.

661
00:53:11,680 --> 00:53:12,800
Onto our green cards.

662
00:53:12,800 --> 00:53:14,600
So remember recent interactions.

663
00:53:14,600 --> 00:53:18,960
So maintain short-term memory and allow the user to make efficient references to that memory.

664
00:53:19,240 --> 00:53:24,560
When attaching a file, Outlook offers a list of recent files, including recently copied file links.

665
00:53:24,960 --> 00:53:31,360
Outlook also remembers people you have interacted with recently and displays them when addressing a new e-mail.

666
00:53:32,800 --> 00:53:37,280
Bing search remembers some recent queries and search can be continued conversationally.

667
00:53:37,280 --> 00:53:40,480
How old is he after a search for Keanu Reeves?

668
00:53:41,280 --> 00:53:44,360
Siri carries over the context from one interaction to the next.

669
00:53:44,360 --> 00:53:48,160
A text message is created from the person you told Siri to message to.

670
00:53:48,160 --> 00:53:51,200
On to card number 13, lucky number 13.

671
00:53:51,360 --> 00:53:52,560
Learn from user behavior.

672
00:53:52,560 --> 00:53:56,240
Personalize user experience by learning from their actions over time.

673
00:53:56,560 --> 00:53:59,440
Tap on a search bar in Office, Applications, and Search lists

674
00:54:00,000 --> 00:54:11,440
The top three commands on your screen that you're most likely to need to personalize, the technology called Zero Query doesn't even need to type in the search bar to provide a personalized predictive answer.

675
00:54:12,160 --> 00:54:16,880
Amazon.com gives personalized product recommendations based on previous purchases.

676
00:54:16,880 --> 00:54:21,040
Onto Card 14, update and adapt cautiously.

677
00:54:21,600 --> 00:54:26,240
Limit disruptive changes when updating adapting the AI system's behaviors.

678
00:54:26,240 --> 00:54:33,280
So PowerPoint Designer improves slides for Office 65 subscribers by automatically generating design ideas to choose from.

679
00:54:33,640 --> 00:54:41,840
Designer has integrated new capabilities such as smart graphics, icon suggestions, and an existing user experience, ensuring the updates are not disruptive.

680
00:54:42,720 --> 00:54:47,200
Office Tell Me feature shows dynamically recommended items.

681
00:54:47,560 --> 00:55:01,200
And it doesn't need a try area to minimize disruptive changes onto card number 15, encourage granular feedback, enable the users to provide feedback indicating their preferences during regular interactions with the AI system.

682
00:55:01,200 --> 00:55:06,320
So ideas in Excel empowers you to understand your data through high-level visual summaries, trends, and patterns.

683
00:55:06,320 --> 00:55:09,840
It encourages feedback on each suggestion by asking, is this helpful?

684
00:55:10,440 --> 00:55:16,960
Not only does Instagram provide the option to hide specific ads, but it also solicits feedback to understand why the ad is not relevant.

685
00:55:17,240 --> 00:55:21,440
And Apple's music app, Love Dislike buttons are prominent, easily accessible.

686
00:55:23,040 --> 00:55:25,560
Number 16, convey the consequences of user actions.

687
00:55:25,560 --> 00:55:30,160
Immediately update or convey how user actions will impact future behaviors of the AI system.

688
00:55:30,560 --> 00:55:33,560
You can get stock in geographic data types in Excel.

689
00:55:33,560 --> 00:55:37,760
It is easy as typing text into a cell and converting it to stock data.

690
00:55:38,360 --> 00:55:40,960
type or geography data type.

691
00:55:40,960 --> 00:55:45,040
When you perform the conversion action, an icon immediately appears in the converted cells.

692
00:55:45,680 --> 00:55:55,280
Upon tapping the like/dislike button for each recommendation in Apple Music, a pop-up informs the user that they'll receive more or fewer similar recommendations.

693
00:55:55,280 --> 00:55:57,960
Onto card number 17, we're almost near the end.

694
00:55:57,960 --> 00:55:59,520
Provide global controls.

695
00:55:59,520 --> 00:56:05,080
Allow the user to globally customize the AI system monitors and how it behaves.

696
00:56:05,080 --> 00:56:07,840
So editor expands on spelling and grammar.

697
00:56:08,400 --> 00:56:14,000
checking capabilities of Word to include more advanced proofing and editing designed to ensure document is readable.

698
00:56:14,360 --> 00:56:18,160
Editor can flag a range of critique types and allow to customize.

699
00:56:18,240 --> 00:56:21,920
The thing is that in Word, it's so awful spell checking.

700
00:56:21,920 --> 00:56:25,600
I don't understand, like it's been years and the spell checking ever gets better.

701
00:56:25,600 --> 00:56:28,320
So they're going to implore better spell checking AI, I think.

702
00:56:28,560 --> 00:56:33,520
Bing search provides settings that impact the types of results the engine will return.

703
00:56:33,760 --> 00:56:35,680
For example, safe search.

704
00:56:37,280 --> 00:56:42,160
Then we have Google Photos, allows users to turn location history on and off for future photos.

705
00:56:42,360 --> 00:56:51,920
It's kind of funny seeing like Bing in there about like using AI because at one point it's almost pretty certain that Bing was copying just Google search indexes to learn how to index.

706
00:56:52,640 --> 00:56:54,000
I don't know, that's Microsoft for you.

707
00:56:54,720 --> 00:56:55,880
We're on to card 18.

708
00:56:55,880 --> 00:57:00,640
Notify users about changes, inform the user when AI system adds or updates its capabilities.

709
00:57:01,240 --> 00:57:08,800
The What's New dialogue in Office informs you about changes by giving an overview of the latest features and updates, including updates to AI features.

710
00:57:09,200 --> 00:57:14,280
In Outlook Web, the Help tab includes a What's New section that covers updates.

711
00:57:14,280 --> 00:57:16,880
So, there we go, we made it to the end of the list.

712
00:57:17,480 --> 00:57:24,800
I hope that was a fun listen for you, and there I hope that we could kind of match up the responsible AI.

713
00:57:24,960 --> 00:57:32,400
I kind of wish what they would have done is actually mapped it out here and say where it matched, but I guess it's kind of an isolate service that kind of ties in, so I guess there we go.

714
00:57:32,400 --> 00:57:32,880
Okay.

715
00:57:38,040 --> 00:57:42,120
Hey, this is Andrew Brown from Exam Pro, and we are looking at Azure Cognitive Services.

716
00:57:42,120 --> 00:57:47,480
And this is a comprehensive family of AI services and cognitive APIs to help you build intelligent apps.

717
00:57:47,480 --> 00:57:51,840
So create customizable pre-trained models built with breakthrough AI researches.

718
00:57:51,840 --> 00:57:53,120
I put that in quotations.

719
00:57:53,120 --> 00:57:58,400
I'm kind of throwing some shade at Microsoft or Azure just because it's their marketing material, right?

720
00:57:58,960 --> 00:58:03,280
Deploy cognitive services anywhere from cloud to the edge with containers.

721
00:58:03,280 --> 00:58:04,320
Get started quickly.

722
00:58:04,320 --> 00:58:07,960
No machine learning expertise required, but I think it helps to have

723
00:58:08,040 --> 00:58:09,280
a bit of background knowledge.

724
00:58:09,600 --> 00:58:11,520
Developed with strict ethical standards.

725
00:58:12,320 --> 00:58:16,880
Microsoft loves talking about the responsible AI stuff.

726
00:58:17,080 --> 00:58:20,600
Empowering responsible use with industry-leading tools and guidelines.

727
00:58:20,600 --> 00:58:24,720
So let's do a quick breakdown of the types of services in this family.

728
00:58:24,720 --> 00:58:28,880
So for decision, we have anomaly detector, identify potential problems early on.

729
00:58:29,040 --> 00:58:32,560
Content moderator, detect potentially offensive or unwanted content.

730
00:58:32,800 --> 00:58:35,920
Personalizer, create rich personalized experiences for every user.

731
00:58:36,080 --> 00:58:37,960
For languages, we have language understanding.

732
00:58:38,080 --> 00:58:40,600
also known as L-U-I-S, Lewis.

733
00:58:40,600 --> 00:58:43,360
I don't know why I didn't put the initials in there, but don't worry, we'll see it again.

734
00:58:43,600 --> 00:58:47,520
Build natural language understanding into app spots and IoT devices.

735
00:58:47,520 --> 00:58:51,600
Q&A maker, create a conversational question and answer layer over your data.

736
00:58:51,760 --> 00:58:54,160
Text analytics, detect sentiment.

737
00:58:54,160 --> 00:58:57,520
So sentiment is like whether customers are happy, sad, glad.

738
00:58:58,160 --> 00:59:00,640
Keep phrases and named entities.

739
00:59:00,640 --> 00:59:03,600
Translator, detect and translate more than 90 supported languages.

740
00:59:03,840 --> 00:59:06,640
For speech, we have speech-to-text, so transcribe audible.

741
00:59:07,520 --> 00:59:09,160
Speech into readable search text.

742
00:59:09,160 --> 00:59:13,120
Text-to-speech, convert text to lifelike speech for natural interfaces.

743
00:59:13,520 --> 00:59:17,600
Speech translation, so integrate real-time speech translation into your apps.

744
00:59:18,320 --> 00:59:24,400
Speaker recognition, identify and verify the people speaking based on audio for vision.

745
00:59:25,040 --> 00:59:28,480
We have computer vision, so analyze content in images and videos.

746
00:59:28,640 --> 00:59:35,280
Custom vision, so analyze, or sorry, customize image recognition to fit your business needs.

747
00:59:36,000 --> 00:59:36,960
Face detect

748
00:59:37,440 --> 00:59:40,560
And identify people and emotions in images.

749
00:59:40,720 --> 00:59:41,520
So, there you go.

750
00:59:46,080 --> 00:59:54,800
So, Azure Cognitive Services is an umbrella AI service that enables customers to access multiple AI services with an AI key and API endpoint.

751
00:59:54,960 --> 00:59:59,960
So, what you do is you go create a new Cognitive Service, and once you're there, it's going to generate...

752
01:00:00,040 --> 01:00:08,960
Two keys and an endpoint, and that is what you're using generally for authentication with the various AI services pragmatically, and that is something that is key to the service that you need to know.

753
01:00:13,440 --> 01:00:24,320
So, knowledge mining is a discipline in AI that uses a combination of intelligent services to quickly learn from vast amounts of information, so it allows organizations to deeply understand and easily explore information.

754
01:00:24,680 --> 01:00:27,760
uncover hidden insights, and find relationships and patterns at scale.

755
01:00:27,760 --> 01:00:30,400
So we have ingest, enrich, and explore.

756
01:00:31,040 --> 01:00:31,880
Those are three steps.

757
01:00:31,880 --> 01:00:37,000
So for ingest content from a range of sources using connectors to 1st and third-party data stores.

758
01:00:37,000 --> 01:00:40,160
So we might have structured data such as databases, CSVs.

759
01:00:41,440 --> 01:00:45,280
The CSVs would more be semi-structured, but we're not going to get into that level of detail.

760
01:00:45,280 --> 01:00:54,880
Unstructured data, so PDFs, videos, images, and audio, for enrich the content with AI capabilities that let you extract information, find patterns, and deepen understanding.

761
01:00:55,120 --> 01:01:11,320
So cognitive services like vision, language, speech, decision, and search, and explore the newly indexed data via search bots, existing businesses, applications, and data visualizations, enriched structured data, customer relationship management, wrap systems, power

762
01:01:12,000 --> 01:01:21,560
This whole knowledge mining thing is a thing, but I believe that the whole model around this is so that Azure shows you how you can use the cognitive services to solve the problem.

763
01:01:21,680 --> 01:01:23,760
things without having to invent new solutions.

764
01:01:23,760 --> 01:01:29,520
So let's look at a bunch of use cases that Azure has and see where we can find some useful use.

765
01:01:29,680 --> 01:01:31,440
So the first one here is for content research.

766
01:01:31,440 --> 01:01:39,200
So when organizations task employees to review and research of technical data, it can be tedious to read page after page of dense text.

767
01:01:39,520 --> 01:01:43,000
Knowledge mining helps employees quickly review these dense materials.

768
01:01:43,000 --> 01:01:50,960
So you have a document, and in the enrichment step, you could be doing printed text recognition, key phrase extraction, sharpen,

769
01:01:51,400 --> 01:01:56,400
skills, technical keyword sanitation, format, definition, miner, large-scale vocabulary matcher.

770
01:01:56,640 --> 01:02:02,480
You put it through a search service, and now you have search reference libraries, so it makes things a lot easier to work with.

771
01:02:03,520 --> 01:02:14,680
Now we have audit risk compliance management, so developers could use knowledge mining to help attorneys quickly identify entities of importance from discovery documents and flag important ideas across documents.

772
01:02:14,680 --> 01:02:25,120
So we have documents, so clause extraction, clause classification, GDPR risk, identity extraction, key phrase extraction, language detection, automate translation.

773
01:02:25,920 --> 01:02:31,120
Then you put it back into a search index, and now you can use it in a management platform or a Word plug-in.

774
01:02:32,120 --> 01:02:44,520
And so we have business process management in industries where bidding competition is fierce or when the diagnosis of a problem must be quick or in near real-time companies use knowledge mining to avoid costly mistakes.

775
01:02:44,520 --> 01:02:54,080
So the client drilling and completion reports, document processor, AI services and custom models, queue for human validation, intelligent automation.

776
01:02:54,240 --> 01:02:59,920
You send it to a back-end system or a data lake, and/or a data lake, and then you do your analytics dashboard.

777
01:03:00,320 --> 01:03:02,040
Then we have customer support and feedback

778
01:03:02,640 --> 01:03:03,360
analysis.

779
01:03:03,520 --> 01:03:07,040
So for many companies, customer support is costly and efficient.

780
01:03:07,360 --> 01:03:15,120
Knowledge mining can help customer support teams quickly find the right answers for a customer inquiry or assess customer sentiment at scale.

781
01:03:15,120 --> 01:03:19,120
So you have your source data, you do your document cracking, use cognitive skills.

782
01:03:19,120 --> 01:03:20,720
So pre-trained services are custom.

783
01:03:21,280 --> 01:03:22,640
You have enriched documents.

784
01:03:22,800 --> 01:03:25,520
From here, you're going to do your projections and have a knowledge store.

785
01:03:25,520 --> 01:03:29,440
You're going to have a search index and then do your analytics, something like Power BI.

786
01:03:30,000 --> 01:03:31,760
We have digital assessment management.

787
01:03:31,760 --> 01:03:35,600
I know there's a lot of these, but it really helps you understand how cognitive services are going to be useful.

788
01:03:36,160 --> 01:03:42,640
Given the amount of unstructured data created daily, many companies are struggling to make use of or find information within their files.

789
01:03:43,040 --> 01:03:48,640
Knowledge mining through a search index makes it easy for end customers and employees to locate what they're looking for faster.

790
01:03:48,880 --> 01:03:51,760
So you ingest like art metadata and the actual images themselves.

791
01:03:51,920 --> 01:03:55,400
For the top layer, we're doing geo point extractor, biographical enricher.

792
01:03:55,400 --> 01:03:59,440
Then down below, we're tagging, we're custom object detector, similar image tagger.

793
01:03:59,520 --> 01:03:59,880
We put it in

794
01:03:59,960 --> 01:04:00,800
in a search index.

795
01:04:00,800 --> 01:04:03,840
They love those search indexes, and now you have an art explorer.

796
01:04:05,360 --> 01:04:07,400
We have contract management.

797
01:04:07,400 --> 01:04:08,560
This is the last one here.

798
01:04:08,560 --> 01:04:15,600
Many companies create products for multiple sectors, hence the business opportunities with different vendors and buyers increase exponentially.

799
01:04:15,840 --> 01:04:21,200
Knowledge mining can help organizations to scour thousands of pages of sources to create accurate bids.

800
01:04:21,360 --> 01:04:23,120
So here we have RFP documents.

801
01:04:23,960 --> 01:04:35,200
This will actually probably come back later in the original set, but we'll do risk extraction, print text recognition, key phrase extraction, organizational extraction, engineering standards.

802
01:04:35,200 --> 01:04:36,880
We'll create a search index and put it here.

803
01:04:37,120 --> 01:04:38,800
This will bring back data.

804
01:04:39,040 --> 01:04:42,920
Also, metadata extraction will come back here, and then this is just like a continuous pipeline, okay?

805
01:04:47,480 --> 01:05:07,640
Hey, this is Andrew Brown from Exam Pro, and we are looking at Face Service, and Azure Face Service provides an AI algorithm that can detect, recognize, and analyze human faces and images, such as a face in an image, face with specific attributes, face landmarks, similar faces, and the same face as a specific identity across a gallery of images.

806
01:05:07,640 --> 01:05:09,520
So, here's an example of an image.

807
01:05:10,080 --> 01:05:12,240
that I ran that will do in the follow along.

808
01:05:12,320 --> 01:05:15,600
And what it's done is it's drawn a bounding box around the image.

809
01:05:15,920 --> 01:05:17,240
And there's this ID.

810
01:05:17,240 --> 01:05:20,960
And this is a unique identifier string for each detected face in an image.

811
01:05:21,080 --> 01:05:24,080
And these can be unique across the gallery, which is really useful as well.

812
01:05:24,320 --> 01:05:27,680
Another cool thing you can do is face landmarks.

813
01:05:27,920 --> 01:05:32,400
So the idea is that you have a face and it can identify very particular components of it.

814
01:05:32,720 --> 01:05:37,600
And up to 27 predefined landmarks is what is provided with this face service.

815
01:05:38,480 --> 01:05:58,240
Another interesting thing is face attributes, so you can check whether they're wearing accessories, so think like earrings or lip rings, determine its age, the blurriness of the image, what kind of emotion is being experienced, the exposure of the image, you know, the contrast, facial hair, gender, glasses,

816
01:05:59,280 --> 01:06:02,800
your hair in general, the head pose, there's a lot of information around that.

817
01:06:02,800 --> 01:06:12,800
Makeup, which seems to be limited, like when we ran it here in the lab, all we got back was eye makeup and lip makeup, but hey, we got some information whether they're wearing a mask.

818
01:06:13,440 --> 01:06:27,360
Noise, so whether there's artifacts like visual artifacts or occlusion, so whether an object is blocking the parts of the face, and then they simply have a Boolean value for whether the person's smiling or not, which I assume is a very common component.

819
01:06:27,360 --> 01:06:30,560
So that's pretty much all we really need to know about the face service, and there you go.

820
01:06:35,320 --> 01:06:39,560
Hey, this is Andrew Brown from ExamPre, and we're looking at the Speech and Translate service.

821
01:06:39,560 --> 01:06:46,000
So Azure's Translate service is a translation service, as the name implies, and it can translate 90 languages and dialects.

822
01:06:46,000 --> 01:06:49,680
And I was even surprised to find out that it can translate into Klingon.

823
01:06:50,480 --> 01:06:57,280
And it uses Neural Machine Translation, NMT, replacing its legacy statistical machine translation.

824
01:06:57,680 --> 01:06:58,320
SMT.

825
01:06:58,560 --> 01:07:09,360
So what my guess here is that statistical, meaning that it used classical machine learning back in 2010, and then they decided to switch it over to neural networks, which of course would be a lot more accurate.

826
01:07:09,920 --> 01:07:17,480
Azure's translate service can support a custom translator, so it allows you to extend the service for translation based on your business domain use cases.

827
01:07:17,480 --> 01:07:23,120
So if you use a lot of technical words and things like that, then you can fine-tune that or particular phrases.

828
01:07:23,560 --> 01:07:30,400
Then there's the other service, Azure Speech Service, and this is a speech synthesis service.

829
01:07:30,640 --> 01:07:34,080
So what it can do is speech-to-text, text-to-speech, and speech translation.

830
01:07:34,080 --> 01:07:36,720
So it's synthesizing, creating new voices.

831
01:07:37,520 --> 01:07:46,800
So we have speech-to-text, so real-time speech-to-text, batching, multi-device conversation, conversation transcription, and you can create custom speech models.

832
01:07:46,800 --> 01:07:48,080
Then you have text-to-speech.

833
01:07:48,440 --> 01:07:54,800
So this utilizes a speech synthesis markup language, so it's just a way of formatting it, and it can create custom voices.

834
01:07:55,920 --> 01:08:03,600
Then you have the voice assistant, so it integrates with the Bot Framework SDK and speech recognition, so speaker verification and identification.

835
01:08:03,600 --> 01:08:04,400
So there you go.

836
01:08:08,920 --> 01:08:12,800
Hey, this is Andrew Brown from Exam Pro, and we are looking at Text Analytics.

837
01:08:12,800 --> 01:08:18,600
And this is a service for NLP, so natural language processing, for text mining and text analysis.

838
01:08:18,600 --> 01:08:23,840
So text analytics can perform sentiment analysis, so find out what people think about your brand or topic.

839
01:08:23,840 --> 01:08:28,080
So features provide sentiment labels, such as negative, neutral, positive.

840
01:08:28,320 --> 01:08:32,640
Then you have opinion mining, which is an aspect-based sentiment analysis.

841
01:08:32,880 --> 01:08:36,160
It's for granular information about the opinions related to aspects.

842
01:08:36,520 --> 01:08:40,800
Then you have key phrase extraction, so quickly identify the main concepts in text.

843
01:08:41,120 --> 01:08:45,680
You have language detection, so detect the language of an input of text that it's written in.

844
01:08:46,120 --> 01:08:53,920
And you have name entity recognition, so NER, so identify and categorize entities in your text as people, places, objects, and quantities.

845
01:08:54,400 --> 01:08:58,960
and subset of NER is personally identifiable information.

846
01:08:58,960 --> 01:09:02,480
So PIIs, let's just look at a few of these more in detail.

847
01:09:02,880 --> 01:09:05,440
Some of them are very obvious, but some of these would help to have an example.

848
01:09:05,440 --> 01:09:07,600
So the first we're looking at is key phrase extraction.

849
01:09:07,600 --> 01:09:10,160
So quickly identify the main concepts in text.

850
01:09:10,160 --> 01:09:14,320
So key phrase extraction works best when you give it bigger amounts of text to work on.

851
01:09:14,720 --> 01:09:18,960
This is the opposite of sentiment analysis, which performs better on smaller amounts of text.

852
01:09:19,680 --> 01:09:23,520
So document sizes can be 5,000 or fewer characters per document.

853
01:09:24,280 --> 01:09:27,040
And you can have up to 1000 items per collection.

854
01:09:27,040 --> 01:09:32,240
So imagine you have a movie review with a lot of text in here and you want to extract out the key phrases.

855
01:09:32,240 --> 01:09:37,200
So here it identified Borg ship, enterprise, surface, travels, things like that.

856
01:09:37,680 --> 01:09:39,920
Then you have named entity recognition.

857
01:09:39,920 --> 01:09:45,920
So this detects words and phrases mentioned in unstructured data that can be associated with one or more semantic types.

858
01:09:46,280 --> 01:09:48,000
And so here's an example.

859
01:09:48,000 --> 01:09:49,240
I think this is medicine-based.

860
01:09:49,240 --> 01:09:51,760
And so the idea is that it's identifying

861
01:09:52,440 --> 01:09:58,080
It's identifying these words or phrases, and then it's applying a semantic type.

862
01:09:58,080 --> 01:10:02,080
So it's saying, like, this is a diagnosis, this is a medication class, and stuff like that.

863
01:10:02,640 --> 01:10:08,560
Semantic type could be more broad, so there's location, events, location twice here, person, diagnosis, age.

864
01:10:08,760 --> 01:10:11,280
And there is a predefined set, I believe, that isn't.

865
01:10:11,600 --> 01:10:16,320
Azure that you should expect, but they have a generic one, and then there's one that's for health.

866
01:10:16,640 --> 01:10:18,240
We're looking at sentiment analysis.

867
01:10:18,240 --> 01:10:23,680
This graphic makes it make a lot more sense when we're splitting between sentiment and opinion mining.

868
01:10:23,960 --> 01:10:31,520
But the idea here is that sentiment analysis will apply labels and confidence scores to text at the sentence and document level.

869
01:10:31,520 --> 01:10:37,840
And so labels can include negative, positive, mixed, or neutral, and it'll have a confidence score ranging from zero to 1.

870
01:10:38,280 --> 01:10:41,280
And so over here we have a sentiment analysis of this

871
01:10:41,600 --> 01:10:47,120
And it's saying that this was a negative sentiment, but look, there's something that's positive and there's something that's negative.

872
01:10:47,120 --> 01:10:48,440
So was it really negative?

873
01:10:48,440 --> 01:10:56,000
And that's where opinion mining gets really useful because it has more granular data where we have a subject and we have an opinion, right?

874
01:10:56,000 --> 01:10:59,680
And so here we can see the room was great, but the staff was unfriendly negative.

875
01:10:59,680 --> 01:11:01,600
So we have a bit of a split there, okay?

876
01:11:07,320 --> 01:11:13,120
Hey, this is Andrew Brown from Exam Pro, and we are looking at optical character recognition, also known as OCR.

877
01:11:13,120 --> 01:11:18,320
And this is the process of extracting printed or handwritten text into a digital and editable format.

878
01:11:18,320 --> 01:11:26,440
So OCR can be applied to photos of street signs, products, documents, invoices, bills, financial reports, articles, and more.

879
01:11:26,440 --> 01:11:33,600
And so here's an example of us extracting out nutritional data or nutritional facts off the back of a food product.

880
01:11:34,160 --> 01:11:38,320
So Azure has two different kinds of APIs that can perform OCR.

881
01:11:38,320 --> 01:11:41,120
They have the OCR API and the Read API.

882
01:11:41,520 --> 01:11:44,640
So the OCR API uses an older recognition model.

883
01:11:44,880 --> 01:11:46,400
It supports only images.

884
01:11:46,560 --> 01:11:49,040
It executes synchronously.

885
01:11:49,680 --> 01:11:52,800
returning immediately when it detects text.

886
01:11:52,960 --> 01:11:54,680
It's suited for less text.

887
01:11:54,680 --> 01:11:56,160
It supports more languages.

888
01:11:56,160 --> 01:11:57,320
It's easier to implement.

889
01:11:57,320 --> 01:12:00,080
And on the other side, we have the read API.

890
01:12:00,080 --> 01:12:16,160
So this is an updated recognition model, supports images and PDFs, executes asynchronously, paralyzes tasks per line for faster results, suited for lots of text, supports fewer languages, and it's a bit more difficult to implement.

891
01:12:16,160 --> 01:12:19,560
And so when we want to use this service, we're going to be using

892
01:12:19,640 --> 01:12:22,240
Using Computer Vision SDK, okay?

893
01:12:26,880 --> 01:12:31,520
Hey, this is Andrew Brown from Exam Pro, and we're taking a look here at Form Recognizer Service.

894
01:12:31,520 --> 01:12:37,040
This is a specialized OCR service that translates printed text into digital and editable content.

895
01:12:37,280 --> 01:12:40,960
It preserves the structure and relationships of the form-like data.

896
01:12:41,200 --> 01:12:42,480
That's what makes it so special.

897
01:12:42,720 --> 01:12:48,560
So, Form Recognizer is used to automate data entry in your applications and enrich your document search capabilities.

898
01:12:48,800 --> 01:12:49,560
It can identify key.

899
01:12:49,640 --> 01:12:52,000
value pairs, selection marks, table structures.

900
01:12:52,640 --> 01:13:06,880
It can produce output structures such as original file relationships, bounding boxes, confidence score, and Form Recognizer is composed of custom document processing models, pre-built models for invoices, receipts, IDs, business cards, the model layouts.

901
01:13:06,880 --> 01:13:08,320
Let's talk about the layout here.

902
01:13:08,320 --> 01:13:13,040
So extract text, selection marks, table structures, along with bounding box coordinates from documents.

903
01:13:13,280 --> 01:13:19,560
Form Recognizer can extract text, selection marks, and table structures, the row and column numbers associated with the text.

904
01:13:19,640 --> 01:13:23,200
text using high-definition optical character enhancement models.

905
01:13:24,720 --> 01:13:26,720
That is totally useless.text.

906
01:14:02,800 --> 01:14:07,040
Hey, this is Andrew Brown from Exam Pro, and we are looking at Form Recognizer service.

907
01:14:07,040 --> 01:14:12,640
And this is a specialized service for OCR that translates printed text into digital editable content.

908
01:14:12,640 --> 01:14:16,560
But the magic here is that preserves the structure and relationship of form-like data.

909
01:14:16,560 --> 01:14:22,160
So there's an invoice, you see those magenta lines that's saying, identify that form-like data.

910
01:14:22,160 --> 01:14:28,160
So Form Recognizer is used to automate data entry in your applications and enrich your document search capabilities.

911
01:14:28,360 --> 01:14:31,680
And it can identify key value pairs, selection marks, table structures,

912
01:14:32,000 --> 01:14:37,280
And it can output structures such as original file relationships, bounding boxes, confidence scores.

913
01:14:37,600 --> 01:14:45,360
It's composed of a custom document processing model, pre-built models for invoices, receipts, IDs, and business cards.

914
01:14:45,520 --> 01:14:48,400
It's based on this layout model, and there you go.

915
01:14:53,520 --> 01:14:55,480
So let's touch upon custom models.

916
01:14:55,480 --> 01:15:00,760
So custom models allow you to extract text, key value pairs, selection marks, and tabular data from your forms.

917
01:15:00,760 --> 01:15:03,800
These models are trained with your data, so they're tailored to your forms.

918
01:15:03,800 --> 01:15:05,520
You only need 5 samples.

919
01:15:05,920 --> 01:15:07,280
sample input forms to start.

920
01:15:07,520 --> 01:15:12,560
The trained document processing model can output structured data that includes the relationship in the original form document.

921
01:15:12,880 --> 01:15:18,720
After you train the model, you can test and retrain it, and eventually use it reliably, extract data from more forms according to your needs.

922
01:15:18,720 --> 01:15:20,720
You have two learning options.

923
01:15:20,720 --> 01:15:29,760
You have unsupervised learnings to understand the layout and relationships between fields entries in your forms, and you have supervised learning to extract values of interest using the labeled forms.

924
01:15:29,760 --> 01:15:33,920
So we've covered unsupervised and supervised learning, so you're going to be very familiar with these two, okay?

925
01:15:38,880 --> 01:15:45,080
So Form Recognizer Service has many pre-built models that are easy to get started with.

926
01:15:45,080 --> 01:15:49,040
And so let's go look at them and see what kind of fields it extracts out by default.

927
01:15:49,280 --> 01:15:50,720
So the first is receipts.

928
01:15:50,880 --> 01:15:55,160
So sales receipts from Australia, Canada, Great Britain, India, and United States will work great here.

929
01:15:55,160 --> 01:16:04,280
And the fields that we'll extract out is receipt type, merchant name, merchant phone number, merchant address, transaction date, transaction time, total, subtotal, tax, tip, items, name, quantity.

930
01:16:04,360 --> 01:16:05,680
entity, price, total price.

931
01:16:05,840 --> 01:16:11,920
There's information that is on a receipt that you're not getting out of these fields, and that's where you make your own custom model, right?

932
01:16:12,480 --> 01:16:25,360
For business cards, it's only available for English business cards, but we can extract out contact names, first name, last name, company names, departments, job titles, emails, websites, addresses, mobile phones, faxes, work phones, and other phone numbers.

933
01:16:25,360 --> 01:16:30,240
Not sure how many people are using business cards these days, but hey, they have it as an option.

934
01:16:30,920 --> 01:16:34,480
For invoices, extract data from invoices in various formats and return structured data.

935
01:16:34,960 --> 01:16:55,600
So we have customer name, customer ID, purchase order, invoice ID, invoice date, due date, vendor name, vendor address, vendor address receipt, customer address, customer address receipt, billing address, billing address receipt, shipping address, subtotal, total tax, invoice total, amount due, service address, remittance address, service start date and end date.

936
01:16:56,160 --> 01:16:57,560
previous unpaid balance.

937
01:16:57,560 --> 01:16:59,400
And then they even have one for line items.

938
01:16:59,400 --> 01:17:05,920
So items, amount, description, quantity, unit price, product code, unit, date, tax.

939
01:17:06,400 --> 01:17:19,600
And then for IDs, which could be worldwide passports, US driver license, things like that, you would have fields such as country, region, date of birth, date of expiration, document name, first name, last name, nationality, sex.

940
01:17:20,040 --> 01:17:22,000
Machine readable zone.

941
01:17:22,000 --> 01:17:23,520
I'm not sure what that is.

942
01:17:23,600 --> 01:17:29,760
Document type and address and region, and there are some additional features with some of these models.

943
01:17:29,760 --> 01:17:30,960
We didn't really cover them.

944
01:17:30,960 --> 01:17:33,360
It's not that important, but yeah, there we go.

945
01:17:38,120 --> 01:17:46,000
Hey, this is Andrew Brown from Exam Pro, and we are looking at Natural Understanding, or Luis or Luis, depends on how you like to say it.

946
01:17:46,160 --> 01:17:52,960
And this is a no-code ML service to build language, natural language into apps, bots, and IoT devices.

947
01:17:52,960 --> 01:17:56,800
So quickly create enterprise-ready custom models that continuously improve.

948
01:17:57,120 --> 01:18:07,680
So Luis, I'm going to just call it Luis because that's what I prefer, is accessed via its own isolate domain at Luis.ai, and it utilizes NLP and NLU.

949
01:18:08,160 --> 01:18:19,200
use the ability to perform or ability to transform a linguistic statement to a representation that enables you to understand your users naturally, and it is intended to focus on intention and extraction.

950
01:18:19,200 --> 01:18:25,280
Okay, so where the users want, or sorry, what the users want and what the users are talking about.

951
01:18:25,600 --> 01:18:33,000
So the LUIS application is composed of a schema, and the schema is auto-generated for you when you use the LUIS AI web interface.

952
01:18:33,000 --> 01:18:38,000
So you definitely aren't going to be writing this by hand, but it just helps to see what's kind of in there if you do have some

953
01:18:38,120 --> 01:18:42,240
programmatic skills, obviously you can make better use of the service than just the web interface.

954
01:18:42,600 --> 01:18:46,160
But the schema defines intentions, so what the users are asking for.

955
01:18:46,520 --> 01:18:48,680
A Lewis app always contains a none intent.

956
01:18:48,680 --> 01:18:50,240
We'll talk about why that is in a moment.

957
01:18:50,560 --> 01:18:54,640
And entities, what parts of the intent is used to determine the answer.

958
01:18:54,960 --> 01:19:04,560
Then you also have utterances, so examples of the user input that includes intent and entities to train the ML model to match predictions against the real user input.

959
01:19:04,800 --> 01:19:08,040
So an intent requires one or more example utterance for training.

960
01:19:08,320 --> 01:19:11,600
And it is recommended to have 15 to 30 example utterances.

961
01:19:11,840 --> 01:19:16,080
To explicitly train to ignore an utterance, you use the none intent.

962
01:19:16,560 --> 01:19:23,440
So intent classifies user utterances and entities extract data from utterances.

963
01:19:23,440 --> 01:19:24,800
So hopefully that understands.

964
01:19:24,800 --> 01:19:26,080
I always get this stuff mixed up.

965
01:19:26,080 --> 01:19:27,760
It always takes me a bit of time to understand.

966
01:19:27,920 --> 01:19:29,680
There is more than just these things.

967
01:19:29,680 --> 01:19:35,680
There's like features and other things, but you know, for the AI 900, we don't need to go that deep, okay?

968
01:19:36,320 --> 01:19:38,040
Just to get to visualizing this

969
01:19:38,120 --> 01:19:38,800
make it a bit easier.

970
01:19:38,800 --> 01:19:41,920
So imagine we have this utterance here.

971
01:19:42,160 --> 01:19:43,480
These would be the identities.

972
01:19:43,480 --> 01:19:44,880
So we have two in Toronto.

973
01:19:44,880 --> 01:19:46,240
This is the example utterance.

974
01:19:46,640 --> 01:19:48,400
And then the idea is that you'd have the intent.

975
01:19:48,400 --> 01:19:52,320
The intent, and if you look at this keyword here, this really helps where it says classify.

976
01:19:52,560 --> 01:19:53,120
That's what it is.

977
01:19:53,120 --> 01:19:56,080
It's a classification of this example utterance.

978
01:19:56,080 --> 01:19:58,560
And that's how the ML model is going to learn, okay?

979
01:19:58,560 --> 01:19:58,640
Hey.

980
01:20:03,560 --> 01:20:07,320
Hey, this is Andrew Brown from Exam Pro, and we are looking at QnA Maker service.

981
01:20:07,320 --> 01:20:12,640
And this is a cloud-based NLP service that allows you to create a natural conversational layer over your data.

982
01:20:12,960 --> 01:20:16,720
So QnA Maker is hosted on its own isolate domain at QnAMaker.ai.

983
01:20:16,960 --> 01:20:23,600
It will help you find the most appropriate answer from any input from your custom knowledge base of information.

984
01:20:23,600 --> 01:20:32,000
So it's commonly used to build conversation clients, which includes social apps, chatbots, speech-enabled desktop applications.

985
01:20:32,840 --> 01:20:40,080
QnA Maker doesn't store customer data all the customer data is stored in the region the customer deploys the dependent services instances within.

986
01:20:40,480 --> 01:20:42,880
Okay, so let's look at some of the use cases for this.

987
01:20:43,280 --> 01:20:46,320
So, when you have static information, you can use QnA Maker.

988
01:20:47,200 --> 01:20:48,800
in your knowledge base of answers.

989
01:20:48,800 --> 01:20:55,960
This knowledge base is custom to your needs, which you've built with documents such as PDF and URLs, where you want to provide the same answer to a repeat question command.

990
01:20:55,960 --> 01:20:59,400
When different users submit the same question, the answer is returned.

991
01:20:59,400 --> 01:21:09,320
When you want to filter stack information based on meta information, so meta tag data provides additional filtering options relevant to your client application users and information.

992
01:21:09,320 --> 01:21:15,120
Common metadata information includes chit chat, content type, format, content purpose, content freshness.

993
01:21:15,440 --> 01:21:17,040
And there's a use case when you want to

994
01:21:17,160 --> 01:21:25,200
Manage a bot conversation that includes static information, so your knowledge base takes a user conversational text or command and answers it.

995
01:21:25,200 --> 01:21:33,920
If the answer is part of a predetermined conversation flow represented in the knowledge base with multiple turnkey contexts, the bot can easily provide this flow.

996
01:21:34,560 --> 01:21:39,360
So, Q&A Maker imports your content into a knowledge base of questions and answer pairs.

997
01:21:39,840 --> 01:21:45,360
And QMA Maker can build your knowledge base from an existing document manual or website, URL docx PDF.

998
01:21:45,360 --> 01:21:46,720
I thought this was the coolest thing.

999
01:21:46,720 --> 01:21:51,440
So you can just basically have anyone write a docx as long as it has a heading and text.

1000
01:21:51,640 --> 01:21:55,680
And I think it can even extract out images and it'll just turn it into the bot.

1001
01:21:55,680 --> 01:21:56,960
It just saves you so much time.

1002
01:21:56,960 --> 01:21:57,600
It's crazy.

1003
01:21:57,920 --> 01:22:00,560
It will use ML to extract the question and answer pairs.

1004
01:22:00,800 --> 01:22:07,280
The content of the question and answer pairs include all the alternate forms of the question, metadag tags used to filter choices.

1005
01:22:07,800 --> 01:22:14,560
During the search, follow-up prompts to continue the search refinement, community maker stores answers text in markdown.

1006
01:22:15,200 --> 01:22:21,200
Once your knowledge base is imported, you can fine-tune the imported results by editing the question and answer pairs, as seen here.

1007
01:22:22,240 --> 01:22:25,640
There is the chat box, so you can converse with your bot through a chat box.

1008
01:22:25,640 --> 01:22:30,560
I wouldn't say it's particularly a feature of Q&A Maker, but I just want you to know that's how you'd interact with it.

1009
01:22:30,560 --> 01:22:37,760
So when you're using the Q&A Maker AI, the Azure Bot Service, the Bot Composer, or via channels, you'll get an embeddable one.

1010
01:22:37,920 --> 01:22:43,040
You'll see this box where you can start typing in your questions and get back the answers to test it.

1011
01:22:43,280 --> 01:22:45,920
Here, an example is a multi-turn conversation.

1012
01:22:45,920 --> 01:22:51,960
So somebody asked a question, a generic question, and then said, hey, are you talking about AWS or Azure, which is kind of like a follow-up

1013
01:22:52,040 --> 01:22:52,400
prompt.

1014
01:22:52,800 --> 01:22:56,640
And we'll talk about multi-turn here in a second, but that's something I want you to know about, okay?

1015
01:22:57,360 --> 01:23:04,080
So chit chat is a feature in Q&A Maker that allows you to easily add pre-populated sets of top chit chats into your knowledge base.

1016
01:23:04,320 --> 01:23:08,480
The data set has about 100 scenarios of chit chat in voices of multiple personas.

1017
01:23:08,480 --> 01:23:12,040
So the idea is like if someone says something random like, how are you doing?

1018
01:23:12,040 --> 01:23:13,040
What's the weather today?

1019
01:23:13,040 --> 01:23:14,960
Things that your bot wouldn't necessarily know.

1020
01:23:15,120 --> 01:23:20,720
It has like canned answers and it's going to be different based on how you want the response to be, okay?

1021
01:23:21,480 --> 01:23:22,880
There's a concept of layered ranking.

1022
01:23:22,880 --> 01:23:26,640
So Q&A Maker's system is a layered ranking approach.

1023
01:23:26,800 --> 01:23:30,960
The data is stored in Azure Search, which also serves as the first ranking layer.

1024
01:23:31,200 --> 01:23:39,680
The top result from Azure Search are then passed through Q&A Maker's NLP re-ranking model to produce the final results and confidence score.

1025
01:23:39,920 --> 01:23:49,360
Touching on multi-turn conversation is a follow-up prompt and context to manage the multiple turns, known as multi-turn, for your bot from one question to another.

1026
01:23:49,480 --> 01:23:51,400
When a question can't be answered in a single turn,

1027
01:23:51,520 --> 01:23:54,320
that is when you're using multi-turn conversation.

1028
01:23:54,480 --> 01:23:59,600
So Q&A Maker provides multi-turn prompts and active learning to help you improve your questions based on key and answer pairs.

1029
01:23:59,880 --> 01:24:02,800
And it gives you the opportunity to connect questions and answer pairs.

1030
01:24:02,800 --> 01:24:09,680
The connection allows the client application to provide a top answer and provide more questions to refine the search for a final answer.

1031
01:24:10,000 --> 01:24:18,960
After the knowledge base receives questions from users at the published endpoint, Q&A Maker applies active learning to these rule-over questions to suggest changes to your knowledge base to improve the quality.

1032
01:24:18,960 --> 01:24:19,440
All right?

1033
01:24:24,080 --> 01:24:28,040
Hey, this is Andrew Brown from Exam Pro, and we are looking at Azure Bot Service.

1034
01:24:28,040 --> 01:24:34,600
So, the Azure Bot Service is an intelligent serverless bot service that scales on-demand, used for creating, publishing, and managing bots.

1035
01:24:34,600 --> 01:24:37,440
So, you can register and publish a variety of bots from the Azure portal.

1036
01:24:37,600 --> 01:24:39,600
So, here there's a bunch of ones I've never heard of.

1037
01:24:40,120 --> 01:24:50,000
probably with third-party providers partnered with Azure, and then there's the ones that we would know, like the Azure Health Bot, the Azure Bot, or the Web App Bot, which is more of a generic one.

1038
01:24:50,000 --> 01:24:59,560
So Azure Bot Service can integrate your bot with other Azure, Microsoft, or third-party services via channels.

1039
01:24:59,560 --> 01:25:08,800
So you can have a direct line, Alexa, Office 365, Facebook, Keek, Line, Microsoft Teams, Skype,

1040
01:25:09,360 --> 01:25:10,800
Twilio, and more.

1041
01:25:10,880 --> 01:25:16,960
All right, and two things that are commonly associated with the Azure Bot Service is the Bot Framework and Bot Composer.

1042
01:25:17,280 --> 01:25:23,200
In fact, it was really hard just to make this slide here because they just weren't very descriptive on it because they wanted to push these other two things here.

1043
01:25:23,440 --> 01:25:25,360
But let's talk about the Bot Framework SDK.

1044
01:25:25,360 --> 01:25:33,760
So the Bot Framework SDK, which is now version 4, is an open source SDK that enables developers to model and build sophisticated conversations.

1045
01:25:34,080 --> 01:25:34,800
The Bot Framework...

1046
01:25:35,200 --> 01:25:44,320
along with the Azure Bot Service, provides an end-to-end workflow so we can design, build, test, publish, connect, and evaluate our bots.

1047
01:25:44,640 --> 01:25:52,080
With this framework, developers can create bots that use speech, understand natural language, handle questions, answers, and more.

1048
01:25:52,400 --> 01:25:57,920
The Bot Framework includes a module extensible SDK for building bots as well as tools, templates, and related AI services.

1049
01:25:58,320 --> 01:26:00,480
Then you have Bot Framework Composer.

1050
01:26:01,120 --> 01:26:04,000
And this is built on top of the Bot Framework SDK.

1051
01:26:04,000 --> 01:26:09,200
It's an open source IDE for developers to author, test, provision, and manage conversational experiences.

1052
01:26:09,520 --> 01:26:10,360
You can download it.

1053
01:26:10,360 --> 01:26:12,640
It's an app on Windows OS X and Linux.

1054
01:26:12,640 --> 01:26:16,000
It's probably built using like web technology.

1055
01:26:16,280 --> 01:26:18,920
And so here is the actual app there.

1056
01:26:18,920 --> 01:26:21,760
And so you can see there's kind of a bit of a flow and things you can do in there.

1057
01:26:22,080 --> 01:26:24,320
So you can either use C or Node to build your bot.

1058
01:26:24,320 --> 01:26:28,000
You can deploy the bot to the Azure Web Apps or Azure Functions.

1059
01:26:28,520 --> 01:26:34,480
You have templates to build QNA, MakerBot, Enterprise, or Personal AssistantBot, LanguageBot, Calendar, or PeopleBot.

1060
01:26:35,040 --> 01:26:39,800
You can test and debug via the Bot Framework Emulator, and it has a built-in package manager.

1061
01:26:39,800 --> 01:26:43,840
There's a lot more to these things, but again, at the AI 900, this is all we need to know.

1062
01:26:44,480 --> 01:26:45,280
But yeah, there you go.

1063
01:26:49,880 --> 01:26:54,160
Hey, this is Andrew Brown from Exam Pro, and we are looking at Azure Machine Learning Service.

1064
01:26:54,160 --> 01:26:56,640
I want you to know there's a classic version of the service.

1065
01:26:56,640 --> 01:26:58,320
It's still accessible in the portal.

1066
01:26:58,800 --> 01:26:59,920
This is not an exam.

1067
01:26:59,920 --> 01:27:01,360
We are going to 100% avoid it.

1068
01:27:01,920 --> 01:27:03,200
has severe limitations.

1069
01:27:03,200 --> 01:27:06,880
We cannot transfer anything over from the classic to the new one.

1070
01:27:07,400 --> 01:27:10,000
So the one we're going to focus on is the Azure Machine Learning Service.

1071
01:27:10,160 --> 01:27:11,600
You do create studios within it.

1072
01:27:11,600 --> 01:27:14,560
So you'll hear me say Azure Machine Learning Studio, and I'm referring to the new one.

1073
01:27:15,080 --> 01:27:24,880
A service that simplifies running AIML related workloads, allowing you to build flexible automated ML pipelines, use Python or R, run deep learning workloads such as TensorFlow.

1074
01:27:25,200 --> 01:27:37,040
We can make Jupyter Notebooks in here, so build and document your machine learning models as you build them, share and collaborate Azure Machine Learning SDK for Python, so an SDK designed specifically to interact with the Azure Machine Learning Services.

1075
01:27:37,400 --> 01:27:45,680
It does ML ops, machine learning operations, so end-to-end automation of ML model pipelines, CI/CD, training inference, Azure Machine Learning Designer.

1076
01:27:46,320 --> 01:27:53,960
So this is a drag-and-drop interface to visually build, test, deploy machine learning models, technically pipelines, I guess, as a data labeling service.

1077
01:27:53,960 --> 01:28:02,480
So assemble a team of humans to label your training data, responsible machine learning, so model fairness through disparity metrics and mitigate unfairness.

1078
01:28:02,480 --> 01:28:07,280
At the time of the service, this is not very good, but it's supposed to tie in with the responsible AI that

1079
01:28:07,440 --> 01:28:08,960
Microsoft is always promoting.

1080
01:28:14,080 --> 01:28:20,960
So once we launch our own studio with an Azure Machine Learning Service, you're going to get this nice big bar or navigation left-hand side.

1081
01:28:20,960 --> 01:28:24,480
It shows you there's a lot of stuff that's in here, so let's just break it down on what all these things are.

1082
01:28:24,720 --> 01:28:26,000
So for authoring, we've got notebooks.

1083
01:28:26,000 --> 01:28:29,400
These are Jupyter notebooks and IDE to write Python code to build ML models.

1084
01:28:29,440 --> 01:28:35,600
They kind of have their own preview, which I don't really like, but there's a way to bridge it over to Jupyter Notebooks or to Visual Studio Code.

1085
01:28:35,840 --> 01:28:37,320
We have AutoML, completely automated.

1086
01:28:37,400 --> 01:28:42,960
An automated process to build and train ML models, so they're limited to only three types of models, but still that's great.

1087
01:28:43,200 --> 01:28:48,200
We have the designer, so visual drag-and-drop designer to construct end-to-end ML pipelines for assets.

1088
01:28:48,200 --> 01:28:51,040
We have datasets, so data that you can upload, which will be used.

1089
01:28:51,560 --> 01:28:53,200
which will be used for training, experiments.

1090
01:28:53,200 --> 01:28:56,000
When you run a training job, they are detailed here.

1091
01:28:56,400 --> 01:29:00,720
Pipelines, ML workflows, you have built or have used in the designer.

1092
01:29:01,040 --> 01:29:04,720
Models, so a model registry containing trained models that can be deployed.

1093
01:29:04,960 --> 01:29:12,960
Endpoints, so when you deploy a model, it's hosted on accessible endpoint, so you're going to be able to access it via a REST API or maybe the SDK.

1094
01:29:13,680 --> 01:29:16,640
For manage, we've got compute, the underlying computing instances used

1095
01:29:17,120 --> 01:29:38,960
For notebooks, training and inference environments, a reproducible Python environment for machine learning experiments, data stores, a data repository where your data resides, data labeling, so you have a human with ML-assisted labeling to label your data for supervised learning, Lync services, external service you can connect to the workspace such as Azure Synapse Analytics.

1096
01:29:43,440 --> 01:29:48,240
Let's take a look at the types of compute that is available in our Azure Machine Learning Studio.

1097
01:29:48,240 --> 01:29:49,920
We got 4 categories.

1098
01:29:50,400 --> 01:29:59,960
We have compute instances, development workstations that data scientists can use to work with data and models, compute clusters, the scalable clusters of VMs for on-demand processing.

1099
01:30:00,040 --> 01:30:13,200
experimentation code, deployment targets for predictive services that use your trained models, and attach compute links to existing Azure compute resources such as Azure VMs and Azure Databrick clusters.

1100
01:30:13,200 --> 01:30:28,480
Now, what's interesting here is like with this compute, you can see that you can open it in Jupyter Labs, Jupyter, VS Code, RStudio, and Terminal, but you can work with your compute instances, your development workstations directly in the studio, which that's the way I do it.

1101
01:30:29,640 --> 01:30:36,560
What's interesting is for inference, that's when you want to make a prediction, you use Azure Kubernetes Service or Azure Container Instance.

1102
01:30:36,560 --> 01:30:40,080
I didn't see it show up under here, so I'm kind of confused whether that's where it appears.

1103
01:30:40,640 --> 01:30:45,760
Maybe we'll discover as we do the follow-alongs that they do appear here, but I'm not sure about that one.

1104
01:30:45,760 --> 01:30:47,600
But yeah, those are the four there, okay?

1105
01:30:51,920 --> 01:30:55,440
So within Azure Machine Learning Studio, we can do some data labeling.

1106
01:30:55,440 --> 01:30:59,200
So we create data labeling jobs to prepare your ground truth for supervised learning.

1107
01:30:59,360 --> 01:31:00,160
We have two options.

1108
01:31:00,160 --> 01:31:01,200
Human in the loop labeling.

1109
01:31:01,200 --> 01:31:03,080
You have a team of humans that will apply labeling.

1110
01:31:03,080 --> 01:31:03,760
These are humans.

1111
01:31:03,760 --> 01:31:05,120
You grant access to labeling.

1112
01:31:05,840 --> 01:31:07,600
Machine learning assisted data labeling.

1113
01:31:07,600 --> 01:31:10,160
You will use ML to perform labeling.

1114
01:31:10,560 --> 01:31:14,720
So you can export the labeled data for machine learning experimentation at any time.

1115
01:31:15,280 --> 01:31:20,720
Your users often export multiple times and train different models rather than wait for all the images to be labeled.

1116
01:31:20,960 --> 01:31:23,760
Images labels can be exported in Cocoa format.

1117
01:31:23,760 --> 01:31:29,360
That's why we talked about Cocoa a lot earlier in our data set section, Azure Machine Learning data set.

1118
01:31:29,360 --> 01:31:33,520
And this is the data set format that makes it easy to use for training in Azure Machine Learning.

1119
01:31:33,520 --> 01:31:35,280
So generally you want to use that format.

1120
01:31:35,520 --> 01:31:38,000
The idea is you would choose a labeling task type.

1121
01:31:38,600 --> 01:31:44,240
And that way you would have this UI and then people would go in and just click buttons and do the labeling, okay?

1122
01:31:48,720 --> 01:31:57,400
So Azure ML Data Store securely connects you to storage services on Azure without putting your authentication credentials and the integrity of your original data source at risk.

1123
01:31:57,400 --> 01:32:01,120
So here is the example of data stores that are available to us in the studio.

1124
01:32:01,480 --> 01:32:02,800
And let's just go quickly through them.

1125
01:32:02,800 --> 01:32:04,120
So we have Azure Blob Storage.

1126
01:32:04,120 --> 01:32:07,040
This is data that is stored as objects distributed across many machines.

1127
01:32:07,360 --> 01:32:11,360
Azure File Share, a mountable file share via SMB and NFS protocols.

1128
01:32:11,680 --> 01:32:13,120
Azure Data Lake Storage Gen.

1129
01:32:13,120 --> 01:32:16,880
2, this is Blob Storage designed for vast amounts of big data analytics.

1130
01:32:17,120 --> 01:32:18,600
Azure SQL, this is a fully managed

1131
01:32:18,720 --> 01:32:22,000
SQL relational database, Azure Postgres database.

1132
01:32:22,000 --> 01:32:27,600
This is an open source relational database, often considered an object-related database, preferred by developers.

1133
01:32:27,920 --> 01:32:33,200
Azure MySQL, another open source relational database, the most popular one, and considered a pure relational database.

1134
01:32:33,200 --> 01:32:33,600
Okay.

1135
01:32:38,120 --> 01:32:43,840
So Azure ML datasets makes it easy to register your datasets for use with your ML workload.

1136
01:32:43,840 --> 01:32:48,400
So what you do is you'd add a dataset and you get a bunch of metadata associated with it.

1137
01:32:48,840 --> 01:32:53,320
And you can also upload the dataset again to have multiple versions.

1138
01:32:53,320 --> 01:32:55,840
So you'll have a current version and a latest version.

1139
01:32:56,480 --> 01:33:05,520
It's very easy to get started working with them because they'll have some sample code that's for the Azure ML SDK to import that into your Jupyter Notebooks.

1140
01:33:06,160 --> 01:33:11,040
For data sets, you can generate profiles that will give you summary statistics, distribution of data, and more.

1141
01:33:11,200 --> 01:33:13,680
You will have to use a compute instance to generate that data.

1142
01:33:13,680 --> 01:33:16,200
So you'd press the generate profile, and you'd have that stored.

1143
01:33:16,200 --> 01:33:17,520
I think it's in BLOB storage.

1144
01:33:17,840 --> 01:33:19,120
There are open data sets.

1145
01:33:19,120 --> 01:33:23,760
These are publicly hosted data sets that are commonly used for learning how to build ML models.

1146
01:33:23,920 --> 01:33:26,160
So if you go to open data sets, you just choose one.

1147
01:33:26,160 --> 01:33:30,240
And so this is a curated list of open data sets that you can quickly add to your data store.

1148
01:33:30,400 --> 01:33:35,840
Great for learning how to use AutoML or Azure Machine Learning Designer or any kind of ML

1149
01:33:36,400 --> 01:33:37,760
workload if you're new to it.

1150
01:33:37,840 --> 01:33:42,800
That's why we covered MNIST and Cocoa earlier, just because those are some common data sets there.

1151
01:33:43,200 --> 01:33:43,840
But there you go.

1152
01:33:48,240 --> 01:33:56,240
Taking a look here at Azure ML Experiments, this is a logical grouping of Azure runs, and runs is the act of running an ML task on a virtual machine or container.

1153
01:33:56,400 --> 01:34:00,920
So here's a list of them, and it can run various types of ML tasks.

1154
01:34:00,920 --> 01:34:03,840
So scripts could be pre-processing, auto ML,

1155
01:34:04,520 --> 01:34:15,600
A training pipeline, but what it's not going to include is inference, and what I mean is, once you've deployed your model or pipeline and you make predictions via requests, it's just not going to show up under here, okay?

1156
01:34:20,520 --> 01:34:25,560
Okay, so we have Azure ML Pipelines, which is an executable workflow of a complete machine learning task.

1157
01:34:25,560 --> 01:34:31,280
Not to be confused with Azure Pipelines, which is part of Azure DevOps, or Data Factory, which has its own pipelines.

1158
01:34:31,280 --> 01:34:33,360
It's a totally separate thing here.

1159
01:34:33,600 --> 01:34:37,040
So subtasks are encapsulated as a series of steps within the pipeline.

1160
01:34:37,040 --> 01:34:43,600
Independent steps allow multiple data scientists to work on the same pipeline at the same time without overtaxing compute resources.

1161
01:34:43,840 --> 01:34:47,840
Separate steps also make it easy to use different compute type sizes for each step.

1162
01:34:48,080 --> 01:34:50,440
When you rerun a pipeline, the run jumps to

1163
01:34:50,520 --> 01:34:53,920
the steps that need to be rerun, such as the updated training script.

1164
01:34:53,920 --> 01:34:56,480
Steps do not need to be rerun, and they will be skipped.

1165
01:34:56,880 --> 01:35:03,840
After a pipeline has been published, you can configure a REST endpoint, which allows you to rerun the pipeline from any platform or stack.

1166
01:35:04,000 --> 01:35:06,160
There's two ways to build pipelines.

1167
01:35:06,160 --> 01:35:12,080
You can use the Azure ML Designer or programmatically using Azure Machine Learning Python SDK.

1168
01:35:12,080 --> 01:35:14,080
So here is an example of some code.

1169
01:35:14,320 --> 01:35:15,520
Just make a note here.

1170
01:35:15,520 --> 01:35:18,560
I mean, it's not that important, but notice you create steps.

1171
01:35:18,960 --> 01:35:22,160
Okay, and then you assemble all the steps into a pipeline here.

1172
01:35:22,160 --> 01:35:22,560
All right.

1173
01:35:27,840 --> 01:35:33,440
So Azure Machine Learning Designer lets you quickly build Azure ML pipelines without having to write any code.

1174
01:35:33,440 --> 01:35:35,200
So here is what it looks like.

1175
01:35:35,440 --> 01:35:38,240
And over there you can see our pipeline is quite visual.

1176
01:35:38,480 --> 01:35:42,720
And on the left-hand side you have a bunch of assets you can drag out that are pre-built there.

1177
01:35:42,720 --> 01:35:45,600
So it's a really fast way for building a pipeline.

1178
01:35:45,600 --> 01:35:48,840
So you do have to have a good understanding of ML pipelines and

1179
01:35:48,960 --> 01:35:50,480
to end to make good use of it.

1180
01:35:51,040 --> 01:35:54,160
Once you've trained your pipeline, you can create an inference pipeline.

1181
01:35:54,160 --> 01:35:57,280
So you drop down and you'd say whether you want it to be real or batch.

1182
01:35:58,000 --> 01:36:00,240
You can toggle between them later.

1183
01:36:00,240 --> 01:36:06,560
So I mean, there's a lot to this service, but for the AI 900, we don't have to go diving too deep, okay?

1184
01:36:11,080 --> 01:36:18,560
So, Azure ML models, or the Model Registry, allows you to create, manage, and track your registered models as incremental versions under the same name.

1185
01:36:18,880 --> 01:36:24,240
So, each time you register a model with the same name as an existing one, the registry assures that it's a new version.

1186
01:36:24,560 --> 01:36:28,560
Additionally, you can provide metadata tags and use tags when you search for models.

1187
01:36:28,720 --> 01:36:33,280
So, yeah, it's just a really easy way to share and deploy or download your models, okay?

1188
01:36:38,040 --> 01:36:41,640
Azure ML endpoints allow you to deploy machine learning models as a web service.

1189
01:36:41,640 --> 01:36:55,400
So the workflow for deploying models is register the model, prepare an entry script, prepare an inference configuration, deploy the model locally to ensure everything works, choose a compute target, redeploy the model to the cloud, test the resulting web service.

1190
01:36:55,400 --> 01:37:01,680
So we have two options here, real-time endpoints, so an endpoint that provides remote access to invoke the ML model.

1191
01:37:02,320 --> 01:37:08,080
service running on either Azure Kubernetes Service, AKS, or Azure Container Instance, ACI.

1192
01:37:08,320 --> 01:37:13,520
Then we have pipeline endpoints, so an endpoint that provides remote access to invoke an ML pipeline.

1193
01:37:13,680 --> 01:37:19,520
You can parameterize the pipeline endpoint for managed repeatability in batch scoring and retraining scenarios.

1194
01:37:20,480 --> 01:37:27,280
And so you can deploy a model to an endpoint that will either be deployed to AKS or ACI, as we said earlier.

1195
01:37:27,920 --> 01:37:34,720
And the thing is that when you do do that, just understand that that's going to be shown under the AKS or ACI within the Azure portal.

1196
01:37:34,960 --> 01:37:38,080
It's not consolidated under the Azure Machine Learning Studio.

1197
01:37:38,320 --> 01:37:43,000
When you've deployed A real-time endpoint, you can test the endpoint by sending either a single request or a batch request.

1198
01:37:43,000 --> 01:37:48,360
So they have a nice form here where it's single, or it's like here it's a CSV that you can send.

1199
01:37:48,360 --> 01:37:49,040
So there you go.

1200
01:37:53,640 --> 01:37:58,640
So Azure has a built-in Jupyter-like notebook editor, so you can build and train your ML models.

1201
01:37:58,640 --> 01:38:00,560
And so here is an example of it.

1202
01:38:00,560 --> 01:38:05,200
I personally don't like it too much, but that's okay because we have some other options to make it easier.

1203
01:38:05,400 --> 01:38:08,800
What we do is you choose your compute instance to run the notebook.

1204
01:38:08,800 --> 01:38:14,400
You'll choose your kernel, which is a preloaded programming language and programming libraries for different use cases.

1205
01:38:14,640 --> 01:38:17,360
But that's a Jupyter kernel concept there.

1206
01:38:17,840 --> 01:38:23,560
So you can open the notebook in a more familiar ID, such as VS Code, Jupyter Notebook Classic, or Jupyter

1207
01:38:23,840 --> 01:38:28,240
So you go there, drop it down, choose it, and open it up, and now you're in a more familiar territory.

1208
01:38:28,480 --> 01:38:35,360
The VS Code one is exactly the same experience as the one in Azure ML Studio.

1209
01:38:35,360 --> 01:38:36,560
I personally don't like it.

1210
01:38:36,560 --> 01:38:40,320
I think most people are going to be using the notebooks, but it's great that they have all those options.

1211
01:38:45,720 --> 01:38:50,800
So Azure Automated Machine Learning, also known as AutoML, automates the process of creating an ML model.

1212
01:38:50,800 --> 01:38:57,360
So with Azure AutoML, you supply a data set, choose a task type, and then AutoML will train and tune your model.

1213
01:38:57,360 --> 01:38:58,640
So here are our task types.

1214
01:38:58,640 --> 01:38:59,600
Let's quickly go through them.

1215
01:38:59,600 --> 01:39:03,400
So we have classification, when you need to make a prediction based on several classes.

1216
01:39:03,400 --> 01:39:14,000
So binary classification, multi-class classification, regression, when you need to predict a continuous number value, and then time series forecasting, when you need to predict the value based on time.

1217
01:39:14,240 --> 01:39:15,640
So just look at them a little bit

1218
01:39:15,720 --> 01:39:16,320
more in detail.

1219
01:39:16,320 --> 01:39:22,560
So classification is a type of supervised learning in which the model learns using training data and apply those learnings to new data.

1220
01:39:22,560 --> 01:39:26,080
So here is an example, or this is just the option here.

1221
01:39:26,560 --> 01:39:32,240
So the goal of classification is to predict which categories new data will fall into based on learning from its training data.

1222
01:39:32,480 --> 01:39:34,400
So binary classification is a record.

1223
01:39:34,720 --> 01:39:39,360
Is labeled out of two possible labels, so maybe it's true or false, zero or one.

1224
01:39:39,720 --> 01:39:40,720
It's just two values.

1225
01:39:40,720 --> 01:39:48,960
Multi-class classification is a record is labeled out of a range of labels, and so it could be like happy, sad, mad, or rad.

1226
01:39:49,760 --> 01:39:54,240
I can see there's a spelling mistake there, but yeah, there should be an F, so let's just correct that.

1227
01:39:54,640 --> 01:39:55,200
There we go.

1228
01:39:55,920 --> 01:39:57,760
You can also apply deep learning.

1229
01:39:57,760 --> 01:40:08,400
And so if you turn deep learning on, you probably will want to use a GPU compute instance just because, or compute cluster, because deep learning really prefers GPUs.

1230
01:40:08,400 --> 01:40:08,800
Okay.

1231
01:40:10,000 --> 01:40:16,640
Looking at regression, it's also a type of supervised learning where the model learns using training data and applies those learnings to new data.

1232
01:40:16,880 --> 01:40:20,720
But it's a bit different where the goal of regression is to predict a variable in the future.

1233
01:40:21,360 --> 01:40:24,560
Then you have time series forecasting, and this sounds a lot like

1234
01:40:25,840 --> 01:40:27,200
regression because it is.

1235
01:40:27,360 --> 01:40:36,480
So forecast revenue, inventory, sales, or customer demand, an automated time series experiment that is treated as a multivariate regression problem.

1236
01:40:36,720 --> 01:40:42,960
Past time series values are pivoted to become additional dimensions for the regressor together with other predictors.

1237
01:40:43,400 --> 01:40:52,640
Unlike classical time series methods, has an advantage of naturally incorporating multiple contextual variables and their relationship to one another during training.

1238
01:40:52,640 --> 01:40:58,320
So use cases here, or advanced configurations, I should say, holiday detection and futurization time series.

1239
01:40:58,720 --> 01:41:14,400
You've got deep learning neural networks, so you've got auto ARIMA, profit forecast TCN, many model supports through grouping, rolling origin cross-validation, configurable labs, rolling window aggregate features, so there you go.

1240
01:41:19,560 --> 01:41:26,200
So within AutoML, we have data guardrails, and these are run by AutoML when automatic featurization is enabled.

1241
01:41:26,200 --> 01:41:31,200
It's a sequence of checks to ensure high quality input data is being used to train the model.

1242
01:41:31,200 --> 01:41:33,520
So just to show you some information here.

1243
01:41:33,840 --> 01:41:36,560
So the idea is it could apply validation split handling.

1244
01:41:36,560 --> 01:41:40,960
So the input data has been split for validation to improve the performance.

1245
01:41:41,160 --> 01:41:44,320
Then you have missing feature value imputation.

1246
01:41:44,320 --> 01:41:47,440
So no features missing values were detected in training data.

1247
01:41:47,760 --> 01:41:49,480
High cardinality feature detection

1248
01:41:49,560 --> 01:41:52,960
And your inputs were analyzed, and no high cardinality features were detected.

1249
01:41:53,080 --> 01:42:00,960
High cardinality means, like, if you have too many dimensions, it becomes very dense or hard to process the data, so that's something good to check against.

1250
01:42:05,480 --> 01:42:08,720
Let's talk about AutoML's automatic featurization.

1251
01:42:08,720 --> 01:42:14,960
So during model training with AutoML, one of the following scaling or normalization techniques will be applied to each model.

1252
01:42:14,960 --> 01:42:17,160
The first is standard scale wrappers.

1253
01:42:17,160 --> 01:42:20,640
So standardized features by removing the mean and scaling to unit variance.

1254
01:42:20,880 --> 01:42:25,520
Min/Max scalar, transform features by scaling each feature by the columns minimum/maximum.

1255
01:42:25,760 --> 01:42:29,440
Max ABS scalar, scale each feature by its maximum absolute value.

1256
01:42:29,680 --> 01:42:33,120
Robust scalar, scales features by the quantile range.

1257
01:42:33,520 --> 01:42:35,400
PCA, linear dimensionality reduction.

1258
01:42:35,680 --> 01:42:41,760
using single value decomposition of the data to project it to lower dimensional space.

1259
01:42:43,200 --> 01:42:46,480
Dimension reduction is very useful if your data is too complex.

1260
01:42:46,560 --> 01:42:47,680
Let's say you have data.

1261
01:42:48,640 --> 01:42:59,280
you have too many labels, like 20, 30, 40 labels for categories to pick out of, you'll want to reduce the dimensions so that your machine learning model is not overwhelmed.

1262
01:42:59,600 --> 01:43:01,640
So then you have truncated SVD wrappers.

1263
01:43:01,640 --> 01:43:07,920
So the transformer performs linear dimensionality reduction by means of truncated singular value decomposition.

1264
01:43:07,920 --> 01:43:16,640
Contrary to PCA, the estimator does not center the data before computing the singular value decomposition, which means it can work with spicy sparse matrices

1265
01:43:17,120 --> 01:43:35,280
Efficiently sparse normalization each sample that is each row of the data matrix which with at least 10 component is rescaled independently of other samples that is norm so 1L or 2L2 I can't remember it's I2 or L anyway I1 and.

1266
01:43:35,760 --> 01:43:36,880
and I2.

1267
01:43:37,840 --> 01:43:43,600
So the thing is that on the exam, they're probably not going to be asking these questions, but I just like to get you exposure.

1268
01:43:43,600 --> 01:43:46,640
But I just want to show you that AutoML is doing all this.

1269
01:43:46,640 --> 01:43:48,160
is like pre-processing stuff.

1270
01:43:48,320 --> 01:43:50,080
This is stuff that you'd have to do.

1271
01:43:50,400 --> 01:43:52,640
And so it's just taking care of the stuff for you.

1272
01:43:57,440 --> 01:44:01,440
So within Azure AutoML, they have a feature called Model Selection.

1273
01:44:01,440 --> 01:44:05,280
And this is the task of selecting a statistical model from a set of candidate models.

1274
01:44:05,720 --> 01:44:12,040
And Azure AutoML will use different or many different ML algorithms that will recommend the best performing candidates.

1275
01:44:12,040 --> 01:44:16,880
So here is a list, and I want to just point out down below, there's three pages.

1276
01:44:16,880 --> 01:44:18,240
There's 53 models.

1277
01:44:18,240 --> 01:44:19,280
That's a lot of models.

1278
01:44:19,640 --> 01:44:24,000
And so you can see that the one it chose as its top candidate was called Voting Ensemble.

1279
01:44:24,160 --> 01:44:27,040
That's an ensemble algorithm.

1280
01:44:27,040 --> 01:44:32,000
That's where you take two weak ML models, combine them together to make a more stronger one.

1281
01:44:32,480 --> 01:44:37,360
And notice here it will show us the results, and this is what we're looking for, which is the primary metric.

1282
01:44:37,600 --> 01:44:41,280
The highest value should indicate that that's the model we should want to use.

1283
01:44:41,600 --> 01:44:46,160
You can get an explanation of the model called, that's known as explainability.

1284
01:44:47,000 --> 01:44:52,880
And now if you're a data scientist, you might be a bit smarter and say, well, I know this one should be better, so I'll use this and tweak it.

1285
01:44:53,200 --> 01:44:56,080
But you know, if you don't know what you're doing, you just go with the top one, okay?

1286
01:45:01,160 --> 01:45:07,760
So we just saw that we had a top candidate model, and there could be an explanation to understand as to the effectiveness of this.

1287
01:45:07,760 --> 01:45:11,040
is called MXL, so Machine Learning Explainability.

1288
01:45:11,040 --> 01:45:15,480
This is the process of explaining, interpreting ML or deep learning models, MXL.

1289
01:45:15,840 --> 01:45:21,160
MLX can help machine learning developers to better understand and interpret models' behaviors.

1290
01:45:21,160 --> 01:45:32,400
So, after your top candidate model is selected by Azure AutoML, you can get an explanation of internals of various factors, so model performance, dataset explorer, aggregate feature importance, individual feature importance.

1291
01:45:32,920 --> 01:45:35,200
So I mean, this is aggregate.

1292
01:45:35,200 --> 01:45:43,120
So what it's looking at, and it's actually cut off here, but it's saying that these are the most important ones that affect how the model's outcome.

1293
01:45:43,120 --> 01:45:45,200
So I think this is the diabetes data set.

1294
01:45:45,200 --> 01:45:49,680
So BMI would be one that would be a huge influence there.

1295
01:45:49,680 --> 01:45:50,080
Okay.

1296
01:45:55,000 --> 01:46:00,320
So the primary metric is a parameter that determines the metric to be used during the model training for optimization.

1297
01:46:00,320 --> 01:46:04,160
So for classification, we have a few, and regression and time series, we have a few.

1298
01:46:04,480 --> 01:46:10,080
But you'll have these task types, and underneath, you'll choose the additional configuration, and that's where you can override the primary metric.

1299
01:46:10,640 --> 01:46:17,760
It might just auto-detect it for you so you don't have to, because it might sample some of your data set to just kind of guess, but you might have to override it yourself.

1300
01:46:18,160 --> 01:46:19,680
Just going through some scenarios.

1301
01:46:20,360 --> 01:46:21,760
And we'll break it down into two categories.

1302
01:46:21,760 --> 01:46:24,800
So here we have suited for larger data sets that are well-balanced.

1303
01:46:25,040 --> 01:46:27,880
Well-balanced means that your data set is evenly distributed.

1304
01:46:27,880 --> 01:46:34,400
So if you have classifications for A&B, let's say you have 100 and 100, they're well-balanced, right?

1305
01:46:34,640 --> 01:46:39,440
You don't have one data set much, a subset of your data set much larger than the other that's labeled.

1306
01:46:39,840 --> 01:46:43,920
So for accuracy, this is great for image classification, sentiment analysis, churn prediction.

1307
01:46:44,240 --> 01:46:47,120
For average precision score weighted, it's for sentiment analysis.

1308
01:46:47,360 --> 01:46:50,120
Norm macro recall churn prediction for precision score weighted.

1309
01:46:50,800 --> 01:46:53,840
uncertain as to what that would be good for, maybe sentiment analysis.

1310
01:46:54,160 --> 01:47:02,160
Suited for smaller data sets that are inbound, so that's where your data set, like you might have like 10 records for one and 500 for the other on the label.

1311
01:47:02,160 --> 01:47:06,960
So you have AUC weighted, fraud detection, image classification, anomaly detection, spam detection.

1312
01:47:08,240 --> 01:47:12,000
Onto regression scenarios, we'll break it down into ranges.

1313
01:47:12,000 --> 01:47:13,760
So when you have a very wide range,

1314
01:47:14,320 --> 01:47:15,920
Spearman correlation works really well.

1315
01:47:15,920 --> 01:47:21,360
R2 score, this is great for airline delay, salary estimation, bug resolution, time.

1316
01:47:21,600 --> 01:47:23,440
We're looking at smaller ranges.

1317
01:47:23,600 --> 01:47:29,360
We're talking about normalized root square mean to error, so price predictions, review tip score predictions.

1318
01:47:29,680 --> 01:47:33,880
For normalized mean absolute error, it's going to be just another one here.

1319
01:47:33,880 --> 01:47:34,720
They don't give a description.

1320
01:47:34,720 --> 01:47:36,560
For time series, it's the same thing.

1321
01:47:36,560 --> 01:47:41,120
It's just in the context of time series, so forecasting, all right?

1322
01:47:46,480 --> 01:47:50,480
Another option we can change is the validation type when we're setting up our ML model.

1323
01:47:50,560 --> 01:47:54,960
So model validation is when we compare the results of our training data set to our test data set.

1324
01:47:54,960 --> 01:47:57,360
Model validation occurs after we train the model.

1325
01:47:57,680 --> 01:47:59,120
And so you can just drop it down there.

1326
01:47:59,120 --> 01:47:59,800
We have some options.

1327
01:47:59,800 --> 01:48:05,440
So auto, K-fold cross-validation, Monte Carlo cross-validation, train validation, split.

1328
01:48:05,600 --> 01:48:07,920
I'm not going to really get into the details of that.

1329
01:48:07,920 --> 01:48:12,440
I don't think it'll show up on the AI 900 exam, but I just want you to be aware that you do have those options.

1330
01:48:17,760 --> 01:48:29,120
Hey, this is Andrew Brown from Exam Pro, and we are taking a look here at Custom Vision, and this is a fully managed no-code service to quickly build your own classification and object detection ML models.

1331
01:48:29,120 --> 01:48:34,000
The service is hosted on its own isolate domain at www..customvision.ai.

1332
01:48:34,320 --> 01:48:42,440
So the first idea is you upload your images, so bring your own labeled images or Custom Vision to quickly add tags to any unlabeled data images.

1333
01:48:42,720 --> 01:48:56,320
You use the labeled images to teach custom vision the concepts you care about, which is training, and you use a simple REST API that calls to quickly tag images with your new custom computer vision model, so you can evaluate, okay?

1334
01:49:01,320 --> 01:49:04,400
So when we launch Custom Vision, we have to create a project.

1335
01:49:04,400 --> 01:49:06,560
And with that, we need to choose a project type.

1336
01:49:06,560 --> 01:49:09,680
And we have classification and object detection.

1337
01:49:10,000 --> 01:49:13,720
Reviewing classification here, you have the option between multi-labels.

1338
01:49:13,720 --> 01:49:16,160
So when you want to apply many tags to an image.

1339
01:49:16,480 --> 01:49:19,440
So think of an image that contains both a cat and a dog.

1340
01:49:19,440 --> 01:49:20,360
You have multi-class.

1341
01:49:20,360 --> 01:49:25,360
So when you only have one possible tag to apply to an image, so it's either an apple, banana, and orange.

1342
01:49:25,360 --> 01:49:26,080
It's not.

1343
01:49:26,720 --> 01:49:29,280
Multiples of these things, you have object detection.

1344
01:49:29,280 --> 01:49:34,320
This is when we want to detect various objects in an image, and you'll also need to choose a domain.

1345
01:49:34,320 --> 01:49:38,160
A domain is a Microsoft-managed dataset that is used for training the ML model.

1346
01:49:38,400 --> 01:49:43,680
There are different domains that are suited for different use cases, so let's go take a look first at image classification domains.

1347
01:49:43,920 --> 01:49:47,280
So, here is the big list, the domains being over here.

1348
01:49:48,440 --> 01:49:50,400
Okay, and we'll go through these here.

1349
01:49:50,400 --> 01:49:54,160
So general is optimized for a broad range of image classification tasks.

1350
01:49:54,160 --> 01:50:01,520
If none of the other specified domains are appropriate or you're unsure of which domain to choose, select one of the general domains.

1351
01:50:01,520 --> 01:50:11,040
So A1 is optimized for better accuracy with comparable inference time as general domain recommended for larger data sets or more difficult user scenarios.

1352
01:50:11,680 --> 01:50:13,680
This domain requires more training time.

1353
01:50:14,200 --> 01:50:20,560
Then you have A2, optimized for better accuracy with faster adverts times than A1 and general domains.

1354
01:50:20,960 --> 01:50:26,480
Recommended for most data sets, this domain requires less training time than general and A1.

1355
01:50:26,800 --> 01:50:31,680
You have food optimized for photographs or dishes as you would see them on a restaurant menu.

1356
01:50:31,680 --> 01:50:36,720
If you want to classify photographs of individual fruits or vegetables, use food domains.

1357
01:50:37,520 --> 01:50:41,440
So then we have optimized for recognizable landmarks, both natural and artificial.

1358
01:50:41,600 --> 01:50:45,200
This domain works best when landmark is clearly visible in the photograph.

1359
01:50:45,200 --> 01:50:51,120
This domain works even if the landmark is slightly obstructed by people in front of it.

1360
01:50:52,560 --> 01:50:57,280
Then you have retail, so optimize for images that are found in a shopping cart or shopping website.

1361
01:50:57,280 --> 01:51:03,360
If you want a high-precision classifying between dresses, pants, shirts, use this domain.

1362
01:51:03,600 --> 01:51:08,720
Compact domains optimize for the constraints of real-time classification on the edge.

1363
01:51:09,440 --> 01:51:09,680
Okay.

1364
01:51:10,720 --> 01:51:12,840
Then we have object detection domains.

1365
01:51:12,840 --> 01:51:14,080
So this one's a lot shorter.

1366
01:51:14,080 --> 01:51:15,520
So we'll get through a lot quicker.

1367
01:51:15,680 --> 01:51:18,080
So optimize for a broad range of object detection tasks.

1368
01:51:18,080 --> 01:51:23,200
If none of the other domains are appropriate or you're unsure of which domain, choose the general one.

1369
01:51:23,200 --> 01:51:32,560
A1, optimize for better accuracy and comparable inference time than the general domain recommended for most accurate region locations, larger data sets, or more difficult use case scenarios.

1370
01:51:32,560 --> 01:51:35,320
The domain requires more training and results are not deterministic.

1371
01:51:35,320 --> 01:51:35,840
Expect

1372
01:51:36,560 --> 01:51:42,560
plus minus 1% mean average precision, difference with the same training data provided.

1373
01:51:42,560 --> 01:51:51,840
You have logo optimized for finding brands, logos and images, products on shelves, optimized for detecting and classifying products on the shelf.

1374
01:51:51,840 --> 01:51:52,480
So there you go.

1375
01:51:57,040 --> 01:51:59,880
Okay, so let's get some more practical knowledge of the service.

1376
01:51:59,880 --> 01:52:06,000
So for image classification, you're going to upload multiple images and apply a single or multiple labels to the entire image.

1377
01:52:06,400 --> 01:52:10,000
So here I have a bunch of images uploaded, and then I have my tags over here.

1378
01:52:10,360 --> 01:52:12,240
And they could either be multi or singular.

1379
01:52:12,480 --> 01:52:18,240
For object detection, you apply tags to objects in an image for data labeling, and you hover your cursor over the image.

1380
01:52:18,240 --> 01:52:23,360
Custom Vision uses ML to show bounding boxes of possible objects that have not yet been labeled.

1381
01:52:23,360 --> 01:52:28,880
If it does not detect it, you can also just click and drag to draw out whatever square you want.

1382
01:52:29,040 --> 01:52:30,800
So here's one where I tagged it up quite a bit.

1383
01:52:30,960 --> 01:52:34,000
You have to have at least 50 images on every tag to train.

1384
01:52:34,240 --> 01:52:36,200
So just be aware of that when you

1385
01:52:36,280 --> 01:52:37,680
you are tagging your images.

1386
01:52:38,240 --> 01:52:41,440
When you're training, your model is ready and you have two options.

1387
01:52:41,440 --> 01:52:44,880
So you have quick training, this trains quickly but it will be less accurate.

1388
01:52:44,880 --> 01:52:48,320
You have advanced training, this increases compute time to improve your results.

1389
01:52:48,640 --> 01:52:52,400
So for advanced training, basically you just have this thing that you move to the right.

1390
01:52:53,040 --> 01:52:56,680
With each iteration of training, our ML model will improve the evaluation metrics.

1391
01:52:56,680 --> 01:52:59,040
So precision and recall, it's going to vary.

1392
01:52:59,040 --> 01:53:06,880
We're going to talk about the metrics here in a moment, but the probability threshold value determines when to stop training when our evaluation metric meets our desired threshold.

1393
01:53:06,880 --> 01:53:13,280
So these are just additional options where when you're training, you can move this left to right and these left to right.

1394
01:53:13,440 --> 01:53:18,960
And then when we get our results back, we're going to get some metrics here.

1395
01:53:20,120 --> 01:53:21,120
We have evaluation metrics.

1396
01:53:21,120 --> 01:53:30,960
So we have precision, being exact and accurate, selects items that are relevant, recalls that sensitivity or known as true positive rate, how many relevant items returned, average precision.

1397
01:53:30,960 --> 01:53:35,760
It's important that you remember these because they might ask you that on the exam.

1398
01:53:36,240 --> 01:53:45,600
So when we're looking at object detection and we're looking at the evaluation metric outcomes for this one, we have precision, recall, and mean average precision.

1399
01:53:46,160 --> 01:53:51,440
Once we've deployed our pipeline, it makes sense that we should go ahead and give it a quick test to make sure it's working correctly.

1400
01:53:51,600 --> 01:53:56,960
So you press the quick test button, and you can upload your image, and it will tell you, so this one says it's WARF.

1401
01:53:57,760 --> 01:54:06,160
When you're ready to publish, you just hit the publish button, and then you'll get some prediction URL and information, so you can invoke it.

1402
01:54:06,960 --> 01:54:09,680
One other feature that's kind of useful is the smart labeler.

1403
01:54:09,680 --> 01:54:14,640
So once you've loaded some training data within, it can now make suggestions, right?

1404
01:54:14,640 --> 01:54:21,640
So you can't do this right away, but once it has some data, it's like kind of a prediction that is not 100% guaranteed, right?

1405
01:54:21,640 --> 01:54:24,720
And it just helps you build up your training data set a lot faster.

1406
01:54:25,600 --> 01:54:27,760
Very useful if you have a very large data set.

1407
01:54:27,760 --> 01:54:29,920
This is known as ML-assisted labeling.

1408
01:54:30,080 --> 01:54:30,480
Okay?

1409
01:54:35,080 --> 01:54:42,560
Hey, this is Andrew Brown from Exam Pro, and in this section, we'll be covering the newly added section to the AI 900 that focuses on generative AI.

1410
01:54:42,960 --> 01:54:48,880
Generative AI, including technologies like ChatGPT, is becoming more recognized outside of tech circles.

1411
01:54:48,960 --> 01:54:57,680
While it may seem magical in its ability to produce human-like content, it's actually based on advanced mathematical techniques from statistics, data science, and machine learning.

1412
01:54:57,840 --> 01:55:02,720
Understanding these core concepts can help society envision new AI possibilities for the future.

1413
01:55:03,040 --> 01:55:05,000
First, let's compare the differences between

1414
01:55:05,120 --> 01:55:07,040
Regular AI versus generative AI.

1415
01:55:07,680 --> 01:55:13,040
AI refers to the development of computer systems that can perform tasks typically requiring human intelligence.

1416
01:55:13,120 --> 01:55:19,600
These include problem-solving, decision-making, understanding natural language, recognizing speech and images, and more.

1417
01:55:20,000 --> 01:55:28,400
The primary goal of traditional AI is to create systems that can interpret, analyze, and respond to human actions or environmental changes efficiently and accurately.

1418
01:55:28,400 --> 01:55:31,680
It aims to replicate or simulate human intelligence in machines.

1419
01:55:32,240 --> 01:55:39,520
AI applications are vast and include areas like expert systems, natural language processing, speech recognition, and robotics.

1420
01:55:40,000 --> 01:55:48,560
AI is used in various industries for tasks such as customer service, chatbots, recommendation systems in e-commerce, autonomous vehicles, and medical diagnosis.

1421
01:55:49,440 --> 01:55:55,840
On the other hand, generative AI is a subset of AI that focuses on creating new content or data that is novel and realistic.

1422
01:55:56,000 --> 01:55:59,680
It does not just interpret or analyze data, but generates new data itself.

1423
01:55:59,840 --> 01:56:04,400
It includes generating text, images, music, speech, and other forms of media.

1424
01:56:04,960 --> 01:56:14,880
It often involves advanced machine learning techniques, particularly deep learning models like generative adversarial networks, variational autoencoders, and transformer models like GPT.

1425
01:56:15,400 --> 01:56:26,080
Generative AI is used in a range of applications, including creating realistic images and videos, generating human-like text, composing music, creating virtual environments, and even drug discovery.

1426
01:56:26,400 --> 01:56:34,240
Some examples include tools like GPT for text generation, DLL-E for image creation, and various deep learning models that compose music.

1427
01:56:35,120 --> 01:56:43,040
So, let's quickly summarize the differences of regular AI with generative AI across three features, functionality, data handling, and applications.

1428
01:56:43,640 --> 01:56:50,080
Regular AI focuses on understanding and decision-making, whereas generative AI is about creating new, original outputs.

1429
01:56:50,560 --> 01:56:59,520
In terms of data handling, regular AI analyzes and bases decisions on existing data, while generative AI uses the same data to generate new, previously unseen outputs.

1430
01:57:00,160 --> 01:57:06,880
And for applications, regular eyes scope includes data analysis, automation, natural language processing, and healthcare.

1431
01:57:06,960 --> 01:57:15,440
In contrast, generative AI leans towards more creative and innovative applications such as content creation, synthetic data generation, deepfakes, and design.

1432
01:57:20,120 --> 01:57:23,280
The next topic we'll be covering is what is a large language model.

1433
01:57:23,560 --> 01:57:31,280
A large language model, such as GPT, works in a way that's similar to a complex, automatic system that recognizes patterns and makes predictions.

1434
01:57:31,680 --> 01:57:33,280
Training on large datasets.

1435
01:57:33,280 --> 01:57:36,480
Initially, the model is trained on massive amounts of text data.

1436
01:57:36,560 --> 01:57:40,560
This data can include books, articles, websites, and other written material.

1437
01:57:40,880 --> 01:57:47,840
During this training phase, the model learns patterns in language, such as grammar, word usage, sentence structure, and even style and tone.

1438
01:57:48,320 --> 01:57:52,480
Understanding context, the model's design allows it to consider a wide context.

1439
01:57:52,640 --> 01:57:59,040
This means it doesn't just focus on single words, but understands them in relation to the words and sentences that come before and after.

1440
01:57:59,120 --> 01:58:03,280
This context understanding is important for generating coherent and relevant text.

1441
01:58:04,160 --> 01:58:11,520
Predicting the next word, when you give the model a prompt, which is a starting piece of text, it uses what it has learned to predict the next most likely word.

1442
01:58:12,200 --> 01:58:18,240
It then adds this word to the prompt and repeats the process, continually predicting the next word based on the extended sequence.

1443
01:58:18,720 --> 01:58:25,440
Generating text, this process of predicting the next word continues, creating a chain of words that forms a coherent piece of text.

1444
01:58:25,600 --> 01:58:30,800
The length of this generated text can vary based on specific instructions or limitations set for the model.

1445
01:58:31,280 --> 01:58:35,920
Refinement with feedback, the model can be further refined and improved over time with feedback.

1446
01:58:36,080 --> 01:58:41,040
This means it gets better at understanding and generating text as it is exposed to more data and usage.

1447
01:58:41,640 --> 01:58:56,240
In summary, a large language model works by learning from a vast quantity of text data, understanding the context of language, and using this understanding to predict and generate new text that is coherent and contextually appropriate, which can be further refined with feedback, as shown in the workflow image.

1448
01:59:00,960 --> 01:59:03,360
Next, let's talk about transformer models.

1449
01:59:03,600 --> 01:59:09,520
So A transformer model is a type of machine learning model that's especially good at understanding and generating language.

1450
01:59:09,840 --> 01:59:18,800
It's built using a structure called the transformer architecture, which is really effective for tasks involving natural language processing, like translating languages or writing text.

1451
01:59:19,120 --> 01:59:22,800
Transformer model architecture consists of two components, or blocks.

1452
01:59:23,120 --> 01:59:24,480
First, we have the encoder.

1453
01:59:24,480 --> 01:59:26,880
This part reads and understands the input text.

1454
01:59:26,960 --> 01:59:30,840
It's like a smart system that goes through everything it's been taught, which is a lot of text.

1455
01:59:31,160 --> 01:59:34,720
and picks up on the meanings of words and how they're used in different contexts.

1456
01:59:35,040 --> 01:59:36,320
Then we have the decoder.

1457
01:59:36,320 --> 01:59:40,560
So based on what the encoder has learned, this part generates new pieces of text.

1458
01:59:40,640 --> 01:59:44,560
It's like a skilled writer that can make up sentences that flow well and make sense.

1459
01:59:45,040 --> 01:59:48,320
There are different types of transformer models with specific jobs.

1460
01:59:48,400 --> 01:59:51,600
For example, BERT is good at understanding the language.

1461
01:59:51,680 --> 01:59:54,800
It's like a librarian who knows where every book is and what's inside them.

1462
01:59:54,960 --> 01:59:58,160
Google uses it to help its search engine understand what you're looking for.

1463
01:59:58,480 --> 01:59:59,960
GPT is good at creating text.

1464
02:00:00,480 --> 02:00:05,440
It's like a skilled author who can write stories, articles, or conversations based on what it has learned.

1465
02:00:05,760 --> 02:00:08,240
So that's an overview of a transformer model.

1466
02:00:08,240 --> 02:00:11,840
Next, we'll be talking about the main components of a transformer model.

1467
02:00:16,400 --> 02:00:20,720
The next component of a transformer model we'll be covering is the tokenization process.

1468
02:00:21,040 --> 02:00:24,960
Tokenization in a transformer model is like turning a sentence into a puzzle.

1469
02:00:24,960 --> 02:00:28,560
For example, you have the sentence, I heard a dog bark loudly at a cat.

1470
02:00:28,800 --> 02:00:33,040
To help a computer understand it, we chop up the sentence into pieces called tokens.

1471
02:00:33,120 --> 02:00:35,600
Each piece can be a word or even a part of a word.

1472
02:00:35,680 --> 02:00:38,800
So for our sentence, we give each word a number like this.

1473
02:00:39,040 --> 02:00:50,920
I might be 1, herd might be 2, a might be 3, dog might be 4, bark might be 5, loudly might be 6, at might be 7, a is already tokenized as three, cat might be a.

1474
02:00:51,440 --> 02:00:53,920
Now, our sentence becomes a series of numbers.

1475
02:00:53,920 --> 02:00:55,920
This is like giving each word a special code.

1476
02:00:56,080 --> 02:00:59,840
The computer uses these codes to learn about the words and how they fit together.

1477
02:00:59,840 --> 02:01:03,760
If a word repeats, like a, we use its code again instead of making a new one.

1478
02:01:04,080 --> 02:01:08,800
As the computer reads more text, it keeps turning new words into new tokens with new numbers.

1479
02:01:09,200 --> 02:01:13,040
If it learns the word meow, it might call it 9, and skateboard could be 10.

1480
02:01:13,480 --> 02:01:20,480
By doing this with lots and lots of text, the computer builds a big list of these tokens, which it then uses to understand and generate language.

1481
02:01:20,640 --> 02:01:23,920
It's a bit like creating a dictionary where every word has a unique number.

1482
02:01:28,600 --> 02:01:32,000
The next component of a transformer model we'll be covering are embeddings.

1483
02:01:32,400 --> 02:01:39,760
So to help a computer understand language, we turn words into tokens and then give each token a special numeric code called an embedding.

1484
02:01:39,760 --> 02:01:43,040
These embeddings are like a secret code that captures the meaning of the word.

1485
02:01:43,120 --> 02:01:48,080
As a simple example, suppose the embeddings for our tokens consist of vectors with three elements.

1486
02:01:48,080 --> 02:01:55,600
For example, 4 for dog has the embedding vectors 10, 3, 2, 5 for bark has the vectors 10, 2, 2,

1487
02:01:56,120 --> 02:01:58,880
8 for cat, the vectors are 10, 3, 1.

1488
02:01:59,200 --> 02:02:02,000
9 for meow, the vectors are 10, 2, 1.

1489
02:02:02,400 --> 02:02:07,280
And 10 for skateboard, as the vectors 3, 3, 1, which is quite different from the rest.

1490
02:02:07,680 --> 02:02:19,440
Words that have similar meanings or are used in similar ways get codes that look alike, so dog and bark might have similar codes because they are related, but skateboard might be off in a different area because it's not much related to these other words.

1491
02:02:19,960 --> 02:02:24,640
This way, the computer can figure out which words are similar to each other just by looking at their codes.

1492
02:02:24,720 --> 02:02:29,520
It's like giving each word a home on a map, and words that are neighbors on this map have related meanings.

1493
02:02:29,920 --> 02:02:34,240
The image shows a simple example model in which each embedding has only three dimensions.

1494
02:02:34,320 --> 02:02:36,800
Real language models have many more dimensions.

1495
02:02:37,200 --> 02:02:43,840
Tools such as Word2Ovec or the encoding part of a transformer model help AI to figure out where each word dot should go on this big map.

1496
02:02:48,640 --> 02:02:51,680
Let's go over positional encoding from a transformer model.

1497
02:02:52,080 --> 02:02:59,600
Positional encoding is a technique used to ensure that a language model, such as GPT, doesn't lose the order of words when processing natural language.

1498
02:02:59,680 --> 02:03:03,760
This is important because the order in which words appear can change the meaning of a sentence.

1499
02:03:04,160 --> 02:03:08,320
Let's take the sentence, I heard a dog bark loudly at a cat from our previous example.

1500
02:03:08,720 --> 02:03:17,680
Without positional encoding, if we simply tokenize this sentence and convert the tokens into embedding vectors, we might end up with a set of vectors that lose the sequence information.

1501
02:03:18,040 --> 02:03:23,520
Positional encoding adds a positional vector to each word in order to keep track of the positions of the words.

1502
02:03:24,240 --> 02:03:31,200
However, by adding positional encoding vectors to each word's embedding, we ensure that each position in the sentence is uniquely identified.

1503
02:03:31,600 --> 02:03:37,440
The embedding for i would be modified by adding a positional vector corresponding to position 1, labeled i, 1.

1504
02:03:37,760 --> 02:03:42,240
The embedding for herd would be altered by a vector for position 2, labeled herd, 2.

1505
02:03:42,680 --> 02:03:50,240
The embedding for a would be updated with a vector for position 3, labeled a, 3, and reused with the same positional vector for its second occurrence.

1506
02:03:50,640 --> 02:04:00,480
This process continues for each word, token in the sentence with dog, 4, bark, 5, loudly, 6, at, 7, and cat, 8, all receiving their unique positional encodings.

1507
02:04:00,960 --> 02:04:11,440
As a result, the sentence I heard a dog bark loudly at a cat is represented not just by a sequence of vectors for its words, but by a sequence of vectors that are influenced by the position of each word in the sentence.

1508
02:04:12,120 --> 02:04:21,440
This means that even if another sentence had the same words in a different order, its overall representation would be different because the positional encodings would differ, reflecting the different sequence of words.

1509
02:04:21,920 --> 02:04:24,400
So that's an overview of positional encoding.

1510
02:04:29,120 --> 02:04:32,320
The next component of a transformer we'll be covering is attention.

1511
02:04:32,680 --> 02:04:42,480
Attention in AI, especially in transformer models, is a way the model figures out how important each word or token is to the meaning of a sentence, particularly in relation to the other words around it.

1512
02:04:42,640 --> 02:04:46,640
Let's reuse the sentence, I heard a dog bark loudly at a cat to explain this better.

1513
02:04:47,240 --> 02:04:51,440
Self-attention, imagine each word in the sentence shining a flashlight on the other words.

1514
02:04:51,520 --> 02:04:56,480
The brightness of the light shows how much one word should pay attention to the others when understanding the sentence.

1515
02:04:56,640 --> 02:05:00,400
For bark, the light might shine brightest on dog because they're closely related.

1516
02:05:00,800 --> 02:05:07,520
Encoder's role, in the encoder part of a transformer model, attention helps decide how to represent each word as a number or vector.

1517
02:05:07,520 --> 02:05:10,880
It's not just the word itself, but also its context that matters.

1518
02:05:10,960 --> 02:05:17,160
For example, bark and the bark of a tree would have a different representation than bark and I heard a dog bark because the surrounding words

1519
02:05:17,240 --> 02:05:27,680
Are different decoders' role when generating new text, like completing a sentence, the decoder uses attention to figure out which words it already has are most important for deciding what comes next.

1520
02:05:27,840 --> 02:05:34,320
If our sentence is, I heard a dog, the model uses attention to know that herd and dog are key to adding the next word, which might be bark.

1521
02:05:35,040 --> 02:05:40,320
Multi-head attention, this is like having multiple flashlights, each highlighting different aspects of the words.

1522
02:05:40,480 --> 02:05:46,960
Maybe one flashlight looks at the meaning of the word, another looks at its role in the sentence, like subject or object, and so on.

1523
02:05:46,960 --> 02:05:49,840
This helps the model get a richer understanding of the text.

1524
02:05:50,560 --> 02:05:55,360
Building the output, the decoder builds the sentence one word at a time, using attention at each step.

1525
02:05:55,520 --> 02:05:59,920
It looks at the sentence so far, decides what's important, and then predicts the next word.

1526
02:06:00,000 --> 02:06:03,200
It's an ongoing process, with each new word influencing the next.

1527
02:06:04,000 --> 02:06:15,680
So Attention in Transformer Models is like a guide that helps the AI understand and create language by focusing on the most relevant parts of the text, considering both individual word meanings and their relationships within the sentence.

1528
02:06:16,560 --> 02:06:18,640
Let's take a look at the attention process.

1529
02:06:19,120 --> 02:06:24,160
Token embeddings, each word in the sentence is represented as a vector of numbers or its embedding.

1530
02:06:24,560 --> 02:06:29,920
Predicting the next token, the goal is to figure out what the next word should be, also represented as a vector.

1531
02:06:30,560 --> 02:06:36,400
Assigning weights, the attention layer looks at the sentence so far and decides how much influence each word should have on the next one.

1532
02:06:36,960 --> 02:06:43,520
Calculating attention scores, using these weights, a new vector for the next token is calculated, which includes an attention score.

1533
02:06:43,600 --> 02:06:48,000
Multi-head attention does this several times, focusing on different aspects of the words.

1534
02:06:48,640 --> 02:06:56,160
Choosing the most likely word, a neural network takes these vectors with attention scores and picks the word from the vocabulary that most likely comes next.

1535
02:06:56,920 --> 02:07:02,560
Adding to the sequence, the chosen word is added to the existing sequence, and the process repeats for each new word.

1536
02:07:03,440 --> 02:07:09,040
So let's use GPT-4 as an example for how this entire process works explained in a simplified manner.

1537
02:07:09,680 --> 02:07:15,280
A transformer model like GPT-4 works by taking a text input and producing A well-structured output.

1538
02:07:15,440 --> 02:07:21,200
During training, it learns from a vast array of text data, understanding how words are typically arranged in sentences.

1539
02:07:21,960 --> 02:07:26,240
The model knows the correct sequence of words, but hides future words to learn how to predict them.

1540
02:07:26,360 --> 02:07:32,000
When it tries to predict a word, it compares its guess to the actual word, gradually adjusting to reduce errors.

1541
02:07:32,640 --> 02:07:39,280
In practice, the model uses its training to assign importance to each word in a sequence, helping it guess the next word accurately.

1542
02:07:39,280 --> 02:07:43,840
The result is that GPT-4 can create sentences that sound like they were written by a human.

1543
02:07:44,520 --> 02:07:48,400
However, this doesn't mean the model knows things or is intelligent in the human sense.

1544
02:07:48,480 --> 02:07:54,560
It's simply very good at using its large vocabulary and training to generate realistic text based on word relationships.

1545
02:07:55,120 --> 02:07:58,160
So, that's an overview of attention in a transformer model.

1546
02:08:03,000 --> 02:08:08,960
Hey, this is Andrew Brown from Exam Pro, and in this section we'll be going over an introduction to Azure OpenAI Service.

1547
02:08:09,200 --> 02:08:15,200
Azure OpenAI Service is a cloud-based platform designed to deploy and manage advanced language models from OpenAI.

1548
02:08:15,280 --> 02:08:22,080
This service combines OpenAI's latest language model developments with the robust security and scalability of Azure's cloud infrastructure.

1549
02:08:22,320 --> 02:08:26,080
Azure OpenAI offers several types of models for different purposes.

1550
02:08:26,440 --> 02:08:34,160
GPT-4 models, these are the newest in the line of GPT models and can create text and programming code when given a prompt written in natural language.

1551
02:08:34,560 --> 02:08:41,440
GPT-3.5 models, similar to GPT-4, these models also create text and code from natural language prompts.

1552
02:08:41,520 --> 02:08:50,080
The GPT-3.5 Turbo version is specially designed for conversations, making it a great choice for chat applications and other interactive AI tasks.

1553
02:08:50,520 --> 02:08:51,520
Embedding models.

1554
02:08:51,520 --> 02:08:58,960
These models turn written text into numbered sequences, which is helpful for analyzing and comparing different pieces of text to find out how similar they are.

1555
02:08:59,360 --> 02:09:00,400
DALL-E models.

1556
02:09:00,400 --> 02:09:03,280
These models can make images from descriptions given in words.

1557
02:09:03,360 --> 02:09:09,680
The DALL-E models are still being tested and are shown in the Azure OpenAI Studio, so you don't have to set them up for use manually.

1558
02:09:10,400 --> 02:09:18,560
Key concepts in using Azure OpenAI include prompts and completions, tokens, resources, deployments, prompt engineering, and various models.

1559
02:09:19,000 --> 02:09:27,520
Prompts and completions, users interact with the API by providing a text command in English, known as a prompt, and the model generates a text response or completion.

1560
02:09:27,600 --> 02:09:32,160
For example, a prompt to count to 5 in a loop results in the model returning appropriate code.

1561
02:09:32,640 --> 02:09:38,640
Tokens, Azure OpenAI breaks down text into tokens, which are words or character chunks, to process requests.

1562
02:09:38,800 --> 02:09:41,600
The number of tokens affects response latency and throughput.

1563
02:09:41,760 --> 02:09:48,920
For images, token cost varies with image size and detail setting, with low-detail images costing fewer tokens and high-detail images cost.

1564
02:09:49,120 --> 02:09:50,640
more resources.

1565
02:09:50,640 --> 02:09:55,920
Azure OpenAI operates like other Azure products where users create a resource within their Azure subscription.

1566
02:09:56,320 --> 02:10:02,960
Deployments to use the service, users must deploy a model via deployment APIs, choosing the specific model for their needs.

1567
02:10:03,440 --> 02:10:07,360
Prompt engineering, crafting prompts is crucial as they guide the model's output.

1568
02:10:07,440 --> 02:10:12,000
This requires skill as prompt construction is nuanced and impacts the model's response.

1569
02:10:12,760 --> 02:10:13,280
Models.

1570
02:10:13,280 --> 02:10:16,320
Various models offer different capabilities and pricing.

1571
02:10:16,320 --> 02:10:20,800
DALL-E creates images from text, while Whisper transcribes and translates speech to text.

1572
02:10:20,960 --> 02:10:23,440
Each has unique features suitable for different tasks.

1573
02:10:23,840 --> 02:10:26,480
So that's an overview of Azure OpenAI Service.

1574
02:10:31,160 --> 02:10:34,160
The next topic we'll be covering is Azure OpenAI Studio.

1575
02:10:34,480 --> 02:10:44,480
Developers can work with these models in Azure OpenAI Studio, a web-based environment where AI professionals can deploy, test, and manage LLMs that support generative AI app development on Azure.

1576
02:10:44,800 --> 02:10:51,360
Access is currently limited due to the high demand, upcoming product improvements, and Microsoft's commitment to responsible AI.

1577
02:10:51,680 --> 02:11:01,080
Presently, collaborations are being prioritized for those who already have a partnership with Microsoft, are engaged in lower-risk use cases, and are dedicated to including necessary safeguards.

1578
02:11:02,240 --> 02:11:10,240
In Azure OpenAI Studio, you can deploy large language models, provide few-shot examples, and test them in Azure OpenAI Studio's Chat Playground.

1579
02:11:10,720 --> 02:11:16,320
The image shows Azure OpenAI's Chat Playground interface, where users can test and configure an AI chatbot.

1580
02:11:16,800 --> 02:11:21,040
In the middle, there's a chat area to type user messages and see the assistant's replies.

1581
02:11:21,440 --> 02:11:27,360
On the left, there's a menu for navigation and a section to set up the assistant, including a reminder to save changes.

1582
02:11:27,920 --> 02:11:33,600
On the right, adjustable parameters control the eye's response behavior, like length, randomness, and repetition.

1583
02:11:33,600 --> 02:11:38,560
Users input queries, adjust settings, and observe how the AI responds to fine-tune its performance.

1584
02:11:38,960 --> 02:11:41,680
So, that's an overview of Azure OpenAI Studio.

1585
02:11:46,400 --> 02:11:52,240
Let's take a look at the pricing for the models in Azure OpenAI Service, starting off with the language models.

1586
02:11:52,600 --> 02:12:03,600
We have GPT 3.5 turbo with a context of 4K tokens costs $0.0015 for prompts and $0.002 for completions per 1,000 tokens.

1587
02:12:04,040 --> 02:12:16,720
Another version of GPT-3.5 Turbo can handle a larger context of 16K tokens, with prompt and completion costs increased up to $0.003 and $0.004, respectively.

1588
02:12:16,800 --> 02:12:22,560
GPT-3.5 Turbo1106 with a 16K context has no available pricing.

1589
02:12:22,880 --> 02:12:31,280
GPT-4 Turbo and GPT-4 Turbo Vision both have an even larger context size of 128K tokens but also have no listed prices.

1590
02:12:31,720 --> 02:12:45,120
The standard GPT-4 model with an 8K token context costs $0.03 for prompts and $0.06 for completions, and a larger context version of GPT-4 with 32K tokens costs $0.06 for prompts and $0.12 for completions.

1591
02:12:45,920 --> 02:12:54,080
There are other models such as the base models, fine-tuning models, image models, embedding models, and speech models.

1592
02:12:54,600 --> 02:12:58,800
They all have their respective pricing, but we won't be going through each of them in a lot of detail.

1593
02:12:58,920 --> 02:13:01,920
But essentially, they're all on a pay-per-use pricing model.

1594
02:13:01,920 --> 02:13:04,960
It could be pay-per-hour or pay-per-token and so on.

1595
02:13:04,960 --> 02:13:08,160
The higher quality of the model, the more expensive it will likely be.

1596
02:13:08,480 --> 02:13:11,680
So that's an overview of Azure OpenAI service pricing.

1597
02:13:16,280 --> 02:13:20,960
Hey, this is Andrew Brown from ExamPro, and the next topic we'll be going over are Copilots.

1598
02:13:21,280 --> 02:13:28,080
Copilots are a new type of computing tool that integrates with applications to help users with common tasks using generative AI models.

1599
02:13:28,160 --> 02:13:35,360
They are designed using a standard architecture, allowing developers to create custom Copilots tailored to specific business needs and applications.

1600
02:13:35,680 --> 02:13:42,880
Copilots might appear as a chat feature beside your document or file, and they utilize the content within the product to generate specific results.

1601
02:13:43,280 --> 02:13:45,680
Creating A Copilot involves several steps.

1602
02:13:46,200 --> 02:14:11,360
Training a large language model with a vast amount of data, utilizing services like Azure OpenAI Service, which provide pre-trained models that developers can either use as-is or fine-tune with their own data for more specific tasks, deploying the model to make it available for use within applications, building co-pilots that prompt the models to generate usable content, enabling business users to enhance their productivity and creativity through AI-generated assistance.

1603
02:14:11,880 --> 02:14:14,960
Copilots have the potential to revolutionize the way we work.

1604
02:14:15,040 --> 02:14:21,360
These Copilots use generative AI to help with first drafts, information synthesis, strategic planning, and much more.

1605
02:14:22,160 --> 02:14:26,560
Let's take a look at a few examples of Copilot, starting with Microsoft Copilot.

1606
02:14:27,040 --> 02:14:39,280
So Microsoft Copilot is integrated into various applications to assist users in creating documents, spreadsheets, presentations, and more by generating content, summarizing information, and aiding in strategic planning.

1607
02:14:39,880 --> 02:14:44,960
It is used across Microsoft's suite of products and services to enhance user experience and efficiency.

1608
02:14:45,360 --> 02:14:59,600
Next, we have the Microsoft Bing search engine, which has an integrated Copilot to help users when browsing or searching the internet by generating natural language answers to questions by understanding the context of the questions, providing A richer and more intuitive search experience.

1609
02:15:00,240 --> 02:15:08,480
Microsoft 365 Copilot is designed to be a partner in your workflow, integrated with productivity and communication tools like PowerPoint and Outlook.

1610
02:15:09,120 --> 02:15:16,240
It's there to help you craft effective documents, design spreadsheets, put together presentations, manage emails, and streamline other tasks.

1611
02:15:16,800 --> 02:15:22,160
GitHub Copilot is a tool that helps software developers, offering real-time assistance as they write code.

1612
02:15:22,320 --> 02:15:28,560
It offers more than suggesting code snippets it can help in thoroughly documenting the code for better understanding and maintenance.

1613
02:15:29,120 --> 02:15:37,600
Additionally, Copilot contributes to the development process by providing support for testing code, ensuring that developers can work more efficiently and with fewer errors.

1614
02:15:38,160 --> 02:15:40,080
So that's an overview of Copilot.

1615
02:15:44,800 --> 02:15:49,680
Hey, this is Andrew Brown from ExamPro, and the next topic we'll be covering is prompt engineering.

1616
02:15:50,080 --> 02:15:54,720
Prompt engineering is a process that improves the interaction between humans and generative AI.

1617
02:15:54,800 --> 02:16:00,560
It involves refining the prompts or instructions given to an AI application to generate higher quality responses.

1618
02:16:00,640 --> 02:16:06,880
This process is valuable for both the developers who create AI-driven applications and the end users who interact with them.

1619
02:16:07,200 --> 02:16:08,040
For example,

1620
02:16:08,120 --> 02:16:14,160
Developers may build a generative AI application for teachers to create multiple-choice questions related to text students read.

1621
02:16:14,320 --> 02:16:20,080
During the development of the application, developers can add other rules for what the program should do with the prompts it receives.

1622
02:16:20,560 --> 02:16:21,680
System messages.

1623
02:16:21,760 --> 02:16:24,880
Prompt engineering techniques include defining a system message.

1624
02:16:24,960 --> 02:16:29,200
The message sets the context for the model by describing expectations and constraints.

1625
02:16:29,800 --> 02:16:33,920
For example, you're a helpful assistant that responds in a cheerful, friendly manner.

1626
02:16:33,920 --> 02:16:38,000
These system messages determine constraints and styles for the model's responses.

1627
02:16:38,480 --> 02:16:39,520
Writing good prompts.

1628
02:16:39,680 --> 02:16:44,880
To maximize the utility of AI responses, it is essential to be precise and explicit in your prompts.

1629
02:16:45,080 --> 02:16:53,600
A well-structured prompt, such as create a list of 10 things to do in Edinburgh during August, directs the AI to produce a targeted and relevant output, achieving better results.

1630
02:16:54,720 --> 02:17:01,600
Shot learning refers to an AI model's ability to correctly perform a task without any prior examples or training on that specific task.

1631
02:17:02,000 --> 02:17:07,040
One shot learning involves the AI model learning from a single example or instance to perform a task.

1632
02:17:07,440 --> 02:17:11,360
Here is an example of prompt engineering with a user query and system response.

1633
02:17:11,760 --> 02:17:16,960
So the user inputs, can my camera handle the rainy season if I go to the Amazon rainforest next week?

1634
02:17:17,520 --> 02:17:27,760
Some of the prompt engineering components could be the weather resistance feature check, user's equipment database, rainforest climate data, product specifications, travel tips for photographers, etc.

1635
02:17:28,360 --> 02:17:38,960
For the LLM processing, the AI system integrates the user's question with data about the Amazon's climate, specifically during the rainy season, and the product information about the camera's weather resistance features.

1636
02:17:39,120 --> 02:17:47,840
It also references a database of the user's equipment to ensure it's talking about the correct item and may include travel tips that are useful for photographers heading to similar climates.

1637
02:17:48,520 --> 02:17:59,680
And the output results in your current camera model, the ProShot Mark V, is designed with a weather-sealed body suitable for high humidity and rain conditions, which matches the expected weather in the Amazon rainforest for next week.

1638
02:17:59,840 --> 02:18:04,080
However, for added protection during heavy rains, consider using a rain cover.

1639
02:18:04,640 --> 02:18:07,440
Next, let's take a look at the prompt engineering workflow.

1640
02:18:07,840 --> 02:18:12,960
This image describes A simplified step process for working with AI models in prompt engineering.

1641
02:18:13,280 --> 02:18:16,480
While task understanding, know what you want the AI to do.

1642
02:18:16,840 --> 02:18:19,920
Two, crafting prompts, write instructions for the AI.

1643
02:18:20,320 --> 02:18:24,160
Three, prompt alignment, make sure instructions match what the AI can do.

1644
02:18:24,560 --> 02:18:29,040
Four, optimizing prompt, improve the instructions for better AI responses.

1645
02:18:29,440 --> 02:18:33,440
Five, AI model processing, the AI thinks about the instructions.

1646
02:18:33,760 --> 02:18:37,280
Six, generating output, the AI gives an answer or result.

1647
02:18:37,600 --> 02:18:41,040
Seven, output refinement, fix or tweak the AI's answer.

1648
02:18:41,440 --> 02:18:45,200
Eight, iterative improvement, keep improving the instructions and answers.

1649
02:18:45,560 --> 02:18:47,840
So that's an overview of prompt engineering.

1650
02:18:52,400 --> 02:18:54,640
The next topic we'll be covering is grounding.

1651
02:18:55,040 --> 02:19:01,760
Grounding in prompt engineering is a technique used in large language models where you provide specific, relevant context within a prompt.

1652
02:19:01,840 --> 02:19:05,120
This helps the AI to produce a more accurate and related response.

1653
02:19:05,520 --> 02:19:12,160
For example, if you want an LLM to summarize an e-mail, you would include the actual e-mail text in the prompt along with a command to summarize it.

1654
02:19:12,320 --> 02:19:18,480
This approach allows you to leverage the LLM for tasks it wasn't explicitly trained on without the need for retraining the model.

1655
02:19:18,720 --> 02:19:21,920
So what's the difference between prompt engineering and grounding?

1656
02:19:22,320 --> 02:19:28,160
Prompt engineering broadly refers to the art of crafting effective prompts to produce the desired output from an AI model.

1657
02:19:28,480 --> 02:19:34,400
Grounding specifically involves enriching prompts with relevant context to improve the model's understanding and responses.

1658
02:19:35,000 --> 02:19:45,840
Grounding ensures the AI has enough information to process the prompt correctly, whereas prompt engineering could also include techniques like format, style, and the strategic use of examples or questions to guide the AI.

1659
02:19:46,400 --> 02:19:52,160
The image outlines a framework for grounding options in prompt engineering within the context of large language models.

1660
02:19:52,640 --> 02:19:58,400
Grounding options, these are techniques to ensure LLM outputs are accurate and adhere to responsible AI principles.

1661
02:19:58,840 --> 02:20:02,480
Prompt engineering placed at the top, indicating its broad applicability.

1662
02:20:02,480 --> 02:20:20,400
This involves designing prompts to direct the AI toward generating the desired output, fine-tuning a step below in complexity, where LLMs are trained on specific data to improve their task performance, training the most resource-intensive process at the triangle's base, suggesting its use in more extensive customization needs.

1663
02:20:20,920 --> 02:20:22,720
LLM ops and responsible AI.

1664
02:20:22,720 --> 02:20:30,480
These foundational aspects emphasize the importance of operational efficiency and ethical standards across all stages of LLM application development.

1665
02:20:30,880 --> 02:20:32,800
So that's an overview of grounding.

1666
02:20:37,640 --> 02:20:45,280
Hey, this is Andrew Brown from Exampro, and in this demo, we'll be going over a short demo on what you can do with Copilot with GPT-4 on Microsoft Bing.

1667
02:20:45,920 --> 02:20:52,800
So, to get here, you'll need to search for something like Copilot Bing and click on the try Copilot, and you should be able to access this page.

1668
02:20:53,280 --> 02:21:02,560
So, on here, you have some suggested or popular prompts that people commonly use, such as create an image of a concept kitchen, generate ideas for whacking new products.

1669
02:21:03,080 --> 02:21:05,280
How would you explain AI to a 6th grader?

1670
02:21:05,680 --> 02:21:11,120
Write Python code to calculate all the different flavor combinations for my ice cream parlor, and so on.

1671
02:21:11,760 --> 02:21:21,040
You can choose the conversation style ranging from more creative for more original and imaginative ideas, more balanced or more precise for more factual information.

1672
02:21:21,360 --> 02:21:25,280
We'll be going with somewhere in the middle, so more balanced just for this example.

1673
02:21:25,920 --> 02:21:28,480
On the bottom here, you can type in any prompt you want.

1674
02:21:29,200 --> 02:21:37,280
So, for example, we can type something simple, like summarize the main differences between supervised and unsupervised learning for the AI 900 exam.

1675
02:21:37,760 --> 02:21:40,240
You'll see that it will start generating an answer for you.

1676
02:21:40,720 --> 02:21:50,720
So for supervised learning, data labeling, in supervised learning, the training data is pre-labeled with the correct output values, and it provides other objectives and examples as well.

1677
02:21:51,320 --> 02:21:53,600
And for unsupervised learning, no labels.

1678
02:21:53,600 --> 02:21:56,280
Unsupervised learning operates without labeled data.

1679
02:21:56,280 --> 02:22:00,480
It seeks to discover patterns, structures, or relationships within the raw data.

1680
02:22:00,960 --> 02:22:03,120
Notice how it uses sources from the internet.

1681
02:22:03,200 --> 02:22:09,760
And if you want to learn more, you can click on these links that it provides to directly go to the source of the information, which is very convenient.

1682
02:22:10,160 --> 02:22:15,200
So let's quickly check one out, and it seems like the information we got was pretty good and credible.

1683
02:22:17,360 --> 02:22:24,320
And on the bottom, it also provides us some suggestions for follow-up questions you may want to ask in the future that is related to the previous prompt.

1684
02:22:25,840 --> 02:22:31,440
Another cool feature of Copilot is that it's integrated with DALL-E 3, which is an image generation service.

1685
02:22:32,080 --> 02:22:37,760
So, for example, you can say something like, create an image of a cute dog running through a green field on a sunny day.

1686
02:22:39,200 --> 02:22:43,680
So now you'll have to wait a little bit for it to generate the image that you described in your prompt.

1687
02:22:46,520 --> 02:22:47,280
And there we go.

1688
02:22:47,280 --> 02:22:49,840
We have an adorable little puppy running through the fields.

1689
02:22:54,320 --> 02:22:58,400
You also have the power to modify images if you're not satisfied with the result.

1690
02:22:58,480 --> 02:23:00,960
So they've provided a few options for you here.

1691
02:23:01,200 --> 02:23:06,960
So for example, we can add a rainbow in the background, change it into a cat, or make the sky pink and purple.

1692
02:23:07,280 --> 02:23:08,880
Let's try changing it to a cat.

1693
02:23:09,440 --> 02:23:12,480
So it's going to generate and change it from a dog to a cat.

1694
02:23:13,160 --> 02:23:16,160
And there we go, it's now a cute little cat running through the field.

1695
02:23:17,920 --> 02:23:20,080
You could also write code using Copilot.

1696
02:23:21,360 --> 02:23:26,240
So, for example, I can type in, write a Python function to check if a given number is prime.

1697
02:23:27,840 --> 02:23:30,160
It'll start generating a piece of code for me.

1698
02:23:34,080 --> 02:23:37,040
It can write code in multiple languages, not just Python.

1699
02:23:37,040 --> 02:23:39,200
So let's try out something with JavaScript.

1700
02:23:40,920 --> 02:23:43,840
Let's try create a JavaScript function to reverse a string.

1701
02:23:46,720 --> 02:23:49,280
And of course, we'll need to wait for the code to generate.

1702
02:23:52,080 --> 02:23:53,120
So there we go.

1703
02:23:53,120 --> 02:23:56,480
Here's our code for the function to reverse a string, just as we asked for.

1704
02:23:57,200 --> 02:24:01,200
So that's a really quick and general demo for Copilot with GPT-4.

1705
02:24:06,280 --> 02:24:08,640
Hey, this is Andrew Brown from Exam Pro.

1706
02:24:08,640 --> 02:24:16,880
And in this follow along, we're going to set up a studio with an Azure Machine Learning service so that it will be the basis for all the follow alongs here.

1707
02:24:16,880 --> 02:24:21,200
So what I want you to do is go all the way to the top here and type in Azure Machine Learning.

1708
02:24:21,600 --> 02:24:25,680
And you're looking for this one that looks like a science bottle here.

1709
02:24:26,000 --> 02:24:30,000
And we'll go ahead and create ourselves our Machine Learning Studio.

1710
02:24:30,880 --> 02:24:35,040
And so I'll create a new one here and I'll just say my studio.

1711
02:24:37,600 --> 02:24:38,560
And we'll hit OK.

1712
02:24:39,120 --> 02:24:40,120
And we'll name the workspace.

1713
02:24:40,120 --> 02:24:43,280
So we'll say my work workplace.

1714
02:24:49,550 --> 02:24:51,150
We'll maybe say ML workplace here.

1715
02:24:53,310 --> 02:24:54,510
For containers, there are none.

1716
02:24:54,510 --> 02:24:55,830
So it will create all that stuff for us.

1717
02:24:55,830 --> 02:24:58,910
So I'll hit Create and create.

1718
02:25:02,310 --> 02:25:05,470
And so what we're going to do here is just wait for that creation, okay.

1719
02:25:07,160 --> 02:25:09,760
All right, so after a short little wait there, it looks like our studio is set up.

1720
02:25:09,760 --> 02:25:14,400
So we'll go to that resource, launch the studio, and we are now in.

1721
02:25:14,400 --> 02:25:19,760
So there's a lot of stuff in here, but generally the first thing you'll ever want to do is get yourself a notebook going.

1722
02:25:19,760 --> 02:25:22,000
So in the top left corner, I'm going to go to notebooks.

1723
02:25:22,360 --> 02:25:25,200
And what we'll need to do is load some files in here.

1724
02:25:25,200 --> 02:25:30,000
Now they do have some sample files, like how to use Azure ML.

1725
02:25:30,000 --> 02:25:31,840
So if we just quickly go through here,

1726
02:25:33,440 --> 02:25:44,720
maybe we'll want to look at something like MSNIST here, and we'll go ahead and open this one, and we'll just go ahead and clone this, and we'll just clone it over here.

1727
02:25:48,800 --> 02:25:51,640
Okay, and the idea is that we want to get this notebook running.

1728
02:25:51,640 --> 02:25:54,800
And so notebooks have to be backed by some kind of compute.

1729
02:25:55,120 --> 02:25:57,440
So up here, it says no compute found, and etc.

1730
02:25:57,680 --> 02:26:00,400
So what we can do here, I'm just gonna go back to my files.

1731
02:26:00,480 --> 02:26:02,080
Oh, it went back there for me.

1732
02:26:02,400 --> 02:26:04,240
But what I'm gonna do is go all the way down.

1733
02:26:04,240 --> 02:26:07,600
Actually, I'll just expand this up here, makes it a bit easier, close this tab out.

1734
02:26:08,000 --> 02:26:10,000
But what we'll do is go down to compute.

1735
02:26:10,000 --> 02:26:12,000
And here we have our four types of computes.

1736
02:26:12,000 --> 02:26:14,080
So compute instances is when we're running notebooks.

1737
02:26:14,440 --> 02:26:16,560
Compute clusters is when we're doing training.

1738
02:26:16,720 --> 02:26:20,880
Inference clusters is when we have a inference pipeline.

1739
02:26:21,600 --> 02:26:26,240
And then attached compute is bringing things like HDInsights or Databricks into here.

1740
02:26:26,240 --> 02:26:28,240
But for compute instances is what we need.

1741
02:26:28,520 --> 02:26:29,920
We'll get ahead and go new.

1742
02:26:30,240 --> 02:26:32,480
You'll notice we have the option between CPU and GPU.

1743
02:26:32,480 --> 02:26:35,920
GPU is much more expensive, so it's like 90 cents per hour.

1744
02:26:36,240 --> 02:26:39,440
For a notebook, we do not need anything super powerful.

1745
02:26:39,440 --> 02:26:43,120
Notice it'll say here, development on notebooks, IDEs, lightweight testing.

1746
02:26:43,440 --> 02:26:44,360
Here it's this classical

1747
02:26:44,480 --> 02:26:47,120
ML model training, AutoML pipelines, et cetera.

1748
02:26:47,360 --> 02:26:56,160
So I want to make this a bit cheaper for us here because we're going to be using the notebook to run cognitive services and those costs next to nothing.

1749
02:26:56,160 --> 02:26:57,760
Like they don't take much compute power.

1750
02:26:58,360 --> 02:27:01,280
And for some other ones, we might do something a bit larger for this.

1751
02:27:01,280 --> 02:27:01,800
is good enough.

1752
02:27:01,800 --> 02:27:03,000
So I'll go ahead and hit next.

1753
02:27:03,280 --> 02:27:06,960
I'm just going to say my notebook instance here.

1754
02:27:08,400 --> 02:27:09,520
We'll go ahead and hit create.

1755
02:27:11,000 --> 02:27:13,920
And so we're just going to have to wait for that to finish creating and running.

1756
02:27:13,920 --> 02:27:16,000
And when it is, I'll see you back here in a moment.

1757
02:27:16,880 --> 02:27:20,320
All right, so after a short little wait there, it looks like our server is running.

1758
02:27:20,320 --> 02:27:26,800
And you can even see here, it shows you, can launch in Jupyter Labs, Jupyter, VS Code, RStudio, or the terminal.

1759
02:27:26,800 --> 02:27:30,640
But what I'm going to do is go back all the way to our notebooks just so we have some consistency here.

1760
02:27:30,960 --> 02:27:33,280
I want you to notice that it's now running on this compute.

1761
02:27:33,520 --> 02:27:35,280
If it's not, you can go ahead and select it.

1762
02:27:35,760 --> 02:27:39,120
And it also loaded in Python 3.6, there is 3.8.

1763
02:27:39,120 --> 02:27:41,520
Right now, it's not a big deal, which one you use.

1764
02:27:42,320 --> 02:27:44,880
But that is the kernel, like how it will run this stuff.

1765
02:27:45,240 --> 02:27:52,640
Now, this is all interesting, but I don't want to run this right now, what I want to do is get those kind of cognitive services into here.

1766
02:27:52,880 --> 02:27:59,640
So what we can do is just go up here, and we'll choose editors and edit in Jupyter lab.

1767
02:27:59,640 --> 02:28:03,280
And what that should do is open up a new tab here.

1768
02:28:04,960 --> 02:28:05,680
Is it opening?

1769
02:28:07,520 --> 02:28:09,520
If it's not opening, what we can do is go to compute.

1770
02:28:09,520 --> 02:28:11,680
Sometimes it's a bit more responsive if we just click there.

1771
02:28:11,680 --> 02:28:13,280
It's the same way of getting to it.

1772
02:28:14,000 --> 02:28:17,360
I don't know why, but just sometimes that link doesn't work when you're in the notebook.

1773
02:28:17,680 --> 02:28:24,480
And what we can do is, while we're in here now, we can see that this is where this example project is.

1774
02:28:24,720 --> 02:28:25,120
Okay.

1775
02:28:25,960 --> 02:28:28,800
But what we want to do is get those cognitive services in here.

1776
02:28:28,800 --> 02:28:33,360
So I don't know if I showed it to you yet, but I have a repository.

1777
02:28:33,400 --> 02:28:34,560
I just got to go find it.

1778
02:28:34,560 --> 02:28:36,160
It's somewhere on my screen.

1779
02:28:37,760 --> 02:28:38,320
Here it is.

1780
02:28:38,320 --> 02:28:40,400
Okay, so I have a repo called the FreeAZ.

1781
02:28:41,640 --> 02:28:44,600
It should be AI 900.

1782
02:28:44,720 --> 02:28:49,280
I think I'll go ahead and change that, or that is going to get confusing.

1783
02:28:50,720 --> 02:28:54,880
Okay, so what I want you to do here is, we'll get this loaded in.

1784
02:28:54,880 --> 02:29:03,440
So this is a public directory, I'm just thinking there's a couple ways we can do it, we can go and use the terminal to grab it, what I'm going to do is I'm just going to go download the zip.

1785
02:29:07,800 --> 02:29:10,000
And this is just one of the easiest ways to install it.

1786
02:29:10,000 --> 02:29:12,320
And we need to place it somewhere.

1787
02:29:12,320 --> 02:29:13,840
So here are my downloads.

1788
02:29:14,640 --> 02:29:16,880
And I'm just going to drag it out here.

1789
02:29:18,240 --> 02:29:18,720
Okay,

1790
02:29:19,440 --> 02:29:21,520
And what we'll do is upload that there.

1791
02:29:21,520 --> 02:29:29,840
So I can't remember if it lets you upload entire folders, we'll give it a go see if it lets us maybe rename this to the free AZ or AI 900.

1792
02:29:29,840 --> 02:29:31,600
There, we'll say open.

1793
02:29:32,800 --> 02:29:34,400
Yeah, so it's individual file.

1794
02:29:34,400 --> 02:29:35,560
So it's not that big of a deal.

1795
02:29:35,560 --> 02:29:37,600
But we can go ahead and select it like that.

1796
02:29:40,440 --> 02:29:44,480
And maybe we'll just make a new folder in here, we'll say this cognitive services.

1797
02:29:48,720 --> 02:29:49,200
Okay.

1798
02:29:52,880 --> 02:29:55,840
And what we'll do here is just keep on uploading some stuff.

1799
02:29:55,840 --> 02:29:57,520
So we have assets.

1800
02:30:03,840 --> 02:30:05,360
So I have a couple loose files there.

1801
02:30:07,640 --> 02:30:08,960
I know we have crew.

1802
02:30:11,160 --> 02:30:12,720
Oops, we'll have crew.

1803
02:30:14,320 --> 02:30:14,800
Oops.

1804
02:30:16,160 --> 02:30:17,680
Sometimes it's not as responsive.

1805
02:30:19,760 --> 02:30:21,120
We want OCR.

1806
02:30:21,920 --> 02:30:25,360
I believe we have on called movie reviews.

1807
02:30:26,640 --> 02:30:27,200
So

1808
02:30:27,640 --> 02:30:30,720
we'll go into OCR here and upload the files that we have.

1809
02:30:32,480 --> 02:30:34,240
So we have a few files there.

1810
02:30:36,000 --> 02:30:37,520
And we'll go back a directory here.

1811
02:30:38,360 --> 02:30:41,040
And I know movie reviews are just static files.

1812
02:30:46,570 --> 02:30:48,010
And we have an objects folder.

1813
02:30:55,010 --> 02:30:57,010
So we will go back here to objects.

1814
02:31:02,330 --> 02:31:06,130
And then we'll go back and to crew and we need a folder called WARF.

1815
02:31:07,880 --> 02:31:12,000
a folder called Crusher, a folder called Data.

1816
02:31:12,920 --> 02:31:14,960
And so for each of these, we have some images.

1817
02:31:18,320 --> 02:31:19,440
I think we're on WARF, right?

1818
02:31:19,600 --> 02:31:20,160
Yeah, we are.

1819
02:31:20,160 --> 02:31:20,800
Okay, great.

1820
02:31:21,440 --> 02:31:23,920
So we will quickly upload all these.

1821
02:31:27,520 --> 02:31:30,000
Well, technically, we don't really need to upload any of these.

1822
02:31:30,000 --> 02:31:32,720
Well, these images, we don't, but I'm going to put them here anyway.

1823
02:31:33,040 --> 02:31:36,720
I just remembered that these we just upload directly to the service.

1824
02:31:37,440 --> 02:31:41,200
But because I'm already doing I'm just going to put them here even though we're not going to do anything with them.

1825
02:31:48,650 --> 02:31:53,770
Alright, and so now we are all set up to do some cognitive services.

1826
02:31:53,850 --> 02:31:55,050
So I'll see the next video.

1827
02:31:56,090 --> 02:32:05,290
Alright, so now that we have our work environment set up, what we can do is go ahead and get cognitive services hooked up because we need that service in order to interact with it.

1828
02:32:05,530 --> 02:32:10,530
Because if we open up any of these, you're going to notice we have a cognitive key and endpoint that we're going to need.

1829
02:32:11,040 --> 02:32:18,640
So what I want you to do is go back to your Azure portal and at the top here we'll type in cognitive services.

1830
02:32:19,360 --> 02:32:28,080
Now the thing is that all these services are individualized, but at some point they did group them together and you're able to use them through a unified key and API endpoint.

1831
02:32:28,080 --> 02:32:30,080
That's what this is, and that's the way we're going to do it.

1832
02:32:30,480 --> 02:32:31,520
So we'll say add.

1833
02:32:33,120 --> 02:32:34,960
And it brought us to the marketplace.

1834
02:32:34,960 --> 02:32:36,720
So I'm just going to type in cognitive.

1835
02:32:40,880 --> 02:32:48,000
services, and then just click this one here, and we'll hit create.

1836
02:32:49,600 --> 02:32:51,080
And we'll make a new one here.

1837
02:32:51,080 --> 02:32:53,920
I'm just going to call it my cog services.

1838
02:32:54,720 --> 02:32:58,800
Say, okay, I prefer to be in US East.

1839
02:32:58,800 --> 02:32:59,880
I will leave in US West.

1840
02:32:59,880 --> 02:33:00,400
It's fine.

1841
02:33:00,920 --> 02:33:04,720
And so in here, we'll just say my cog services.

1842
02:33:04,720 --> 02:33:08,000
And if it doesn't like that, I'll just put some numbers in.

1843
02:33:08,400 --> 02:33:09,040
There we go.

1844
02:33:09,680 --> 02:33:10,880
We'll do standard SO.

1845
02:33:10,880 --> 02:33:12,360
We will be charged something for that.

1846
02:33:12,360 --> 02:33:14,240
Let's go take a look at the pricing.

1847
02:33:17,200 --> 02:33:24,080
So you can see that the pricing is quite variable here, but it's like you'd have to do 1000 transactions before you are billed.

1848
02:33:24,960 --> 02:33:27,040
So I think we're going to be okay for billing.

1849
02:33:28,080 --> 02:33:29,120
We'll check boxes here.

1850
02:33:29,440 --> 02:33:30,360
We'll go down below.

1851
02:33:30,360 --> 02:33:32,480
It's telling us about responsible AI notice.

1852
02:33:32,640 --> 02:33:36,640
Sometimes services will actually have you checkbox it, but in this case, it just tells us there.

1853
02:33:40,400 --> 02:33:41,600
And we'll go ahead and hit Create.

1854
02:33:48,680 --> 02:33:50,400
And I don't believe this took very long.

1855
02:33:50,400 --> 02:33:51,760
So we'll give it a second here.

1856
02:33:51,760 --> 02:33:52,760
Yep, it's all deployed.

1857
02:33:52,760 --> 02:33:54,240
So we'll go to this resource here.

1858
02:33:54,400 --> 02:33:57,680
And what we're looking for are our keys and endpoints.

1859
02:33:59,480 --> 02:34:02,400
And so we have two keys and two endpoints, we only need a single key.

1860
02:34:02,400 --> 02:34:06,080
So I'm going to copy this endpoint over, we're gonna go over to Jupyter lab.

1861
02:34:06,080 --> 02:34:07,920
And I'm just going to paste this in here.

1862
02:34:08,800 --> 02:34:10,560
I'm just going to put it in all the ones that need it.

1863
02:34:10,560 --> 02:34:12,080
So this one needs one.

1864
02:34:13,440 --> 02:34:14,720
This one needs one.

1865
02:34:16,400 --> 02:34:17,600
This one needs one.

1866
02:34:18,960 --> 02:34:20,240
And this one needs one.

1867
02:34:21,280 --> 02:34:23,280
And we will show the key here.

1868
02:34:24,080 --> 02:34:25,600
I guess isn't show but it copies.

1869
02:34:26,320 --> 02:34:28,640
Of course, I will end up deleting my key before you ever see it.

1870
02:34:28,640 --> 02:34:31,120
But this is something you don't want to share publicly.

1871
02:34:32,200 --> 02:34:36,800
And usually you don't want to embed keys directly into a notebook, but this is the only way to do it.

1872
02:34:36,800 --> 02:34:38,640
So this is how it is with Azure.

1873
02:34:40,480 --> 02:34:42,400
So yeah, all our keys are installed.

1874
02:34:42,800 --> 02:34:48,480
Going back to the cognitive services, nothing super exciting here, but it does tell us what services work with it.

1875
02:34:48,800 --> 02:34:52,480
You'll see there's an asterisk beside custom vision because we're going to access that through another app.

1876
02:34:53,280 --> 02:34:59,360
But yeah, cognitive services is all set up, and so that means we are ready to start doing some of these labs.

1877
02:34:59,360 --> 02:34:59,560
Okay?

1878
02:35:05,000 --> 02:35:07,320
All right, so let's take a look here at computer vision first.

1879
02:35:07,320 --> 02:35:10,240
And computer vision is actually used for a variety of different services.

1880
02:35:10,240 --> 02:35:13,760
As you will see, it's kind of an umbrella for a lot of different things.

1881
02:35:13,760 --> 02:35:18,280
But the one in particular that we're looking at here is the describe image in stream.

1882
02:35:18,280 --> 02:35:25,000
If we go over here to the documentation, this operation generates description of image in a human readable language with complete sentences.

1883
02:35:25,000 --> 02:35:29,760
The description is based on a collection of content tags, which also returned by the operation.

1884
02:35:30,080 --> 02:35:31,720
Okay, so let's go see what that looks like

1885
02:35:31,800 --> 02:35:37,840
In action, so the first thing is that we need to install this Azure Cognitive Services Vision Computer Vision.

1886
02:35:38,160 --> 02:35:47,440
Now, we do have a kernel, and these aren't installed by default they're not part of the machine learning, the Azure Machine Learning.

1887
02:35:48,200 --> 02:35:49,200
SDK for Python.

1888
02:35:49,360 --> 02:35:53,120
I believe that's pre-installed, but these AI services are not.

1889
02:35:53,120 --> 02:35:55,080
So what we'll do is go ahead and run it this way.

1890
02:35:55,080 --> 02:35:58,240
And you'll notice where it says pip install, that's how it knows to install.

1891
02:35:58,560 --> 02:36:01,680
And once that is done, we'll go run our requirements here.

1892
02:36:01,680 --> 02:36:06,960
So we have the OS, which is for usually handling OS layer stuff.

1893
02:36:06,960 --> 02:36:11,760
We have matplotlib, which is to visually plot things.

1894
02:36:11,840 --> 02:36:14,320
And we're going to use that to show images and draw borders.

1895
02:36:15,120 --> 02:36:16,320
We need to handle images.

1896
02:36:16,880 --> 02:36:19,920
I'm not sure if we're using NumPy here, but I have NumPy loaded.

1897
02:36:20,200 --> 02:36:23,840
And then here we have the Azure Cognitive Services Vision Computer Vision.

1898
02:36:24,120 --> 02:36:25,440
We're going to load the client.

1899
02:36:25,680 --> 02:36:27,360
And then we have the credentials.

1900
02:36:27,360 --> 02:36:30,080
And these are generic credentials for the Cognitive Services credentials.

1901
02:36:30,320 --> 02:36:32,560
It's commonly used for most of these services.

1902
02:36:32,560 --> 02:36:37,280
In some exceptions, the APIs do not support them yet, but I imagine they will in the future.

1903
02:36:37,680 --> 02:36:39,920
So just notice that when we run something, it will show a number.

1904
02:36:39,920 --> 02:36:41,760
If there's an asterisk, it means it hasn't ran yet.

1905
02:36:41,760 --> 02:36:43,280
So I'll go ahead and hit play up here.

1906
02:36:43,520 --> 02:36:45,000
So it was an asterisk and we get A2.

1907
02:36:45,400 --> 02:36:47,280
And we'll go ahead and hit play again.

1908
02:36:48,080 --> 02:36:49,520
And now those are loaded in.

1909
02:36:49,520 --> 02:36:50,880
And so we'll go ahead and hit play.

1910
02:36:52,240 --> 02:36:55,440
Okay, so here we have just packaged our credentials together.

1911
02:36:55,440 --> 02:36:56,960
So we passed our key into here.

1912
02:36:57,400 --> 02:37:00,400
And then we'll now load in the client.

1913
02:37:01,080 --> 02:37:02,960
And so we'll pass in our endpoint and our key.

1914
02:37:02,960 --> 02:37:04,080
Okay, so hit play.

1915
02:37:05,160 --> 02:37:06,880
And so now we just want to load our image.

1916
02:37:06,880 --> 02:37:09,920
So here we're loading assets data.jpg.

1917
02:37:10,040 --> 02:37:11,520
Let's just make sure that is there.

1918
02:37:11,520 --> 02:37:13,360
So we go assets and there it is.

1919
02:37:13,960 --> 02:37:16,720
And we're going to load it as a stream because you have to pass streams along.

1920
02:37:16,880 --> 02:37:17,600
So hit play.

1921
02:37:18,720 --> 02:37:20,080
You'll see that it now ran.

1922
02:37:20,480 --> 02:37:22,480
And so now we'll go ahead and make that call.

1923
02:37:24,720 --> 02:37:25,040
Okay, great.

1924
02:37:25,040 --> 02:37:26,480
And so we're getting some data back.

1925
02:37:26,760 --> 02:37:31,120
And notice we have some properties, person, wall, indoor, man, pointing, captions.

1926
02:37:31,520 --> 02:37:33,040
It's not showing all the information.

1927
02:37:33,040 --> 02:37:35,280
Sometimes you have to extract it out, but we'll take a look here.

1928
02:37:35,280 --> 02:37:36,160
So the.

1929
02:37:36,280 --> 02:37:38,720
This is a way of showing matplodlib in line.

1930
02:37:38,720 --> 02:37:41,440
I don't think we have to run it here, but I have it in here anyway.

1931
02:37:41,760 --> 02:37:46,560
And so what it's going to do is it's going to show us the image, right?

1932
02:37:46,560 --> 02:37:52,160
So it's going to print us the image, and it's going to grab whatever caption is returned to see how there's captions.

1933
02:37:52,960 --> 02:37:55,120
So we're going to iterate through the captions.

1934
02:37:55,440 --> 02:37:58,840
That's going to give us a confidence score saying it thinks it's this.

1935
02:37:58,840 --> 02:38:00,560
So let's see what it comes out with.

1936
02:38:02,120 --> 02:38:05,320
Okay, and so here it says Brent Spiner looking at a camera.

1937
02:38:05,320 --> 02:38:12,800
So that is the actor who plays Data on Star Trek as a confidence score of 57.45%, even though it's 100% correct.

1938
02:38:13,280 --> 02:38:22,920
They probably don't know contextual things like in the sense of like pop culture, like they don't know probably Star Trek characters, but they're going to be able to identify celebrities because it's in their database.

1939
02:38:22,920 --> 02:38:27,680
So that is the first introduction to computer

1940
02:38:28,280 --> 02:38:37,680
Computer vision there, but the key things you want to remember here is that we use this describe an image stream and that we get this confidence score and we get this contextual information, okay?

1941
02:38:37,920 --> 02:38:39,360
And so that's the first one.

1942
02:38:39,360 --> 02:38:41,440
We'll move on to maybe custom vision next.

1943
02:38:46,800 --> 02:38:52,400
All right, so let's take a look at custom vision so we can do some classification and object detection.

1944
02:38:52,400 --> 02:38:55,440
So the thing is that...

1945
02:38:55,880 --> 02:39:02,080
It's possible it's possible to launch Custom Vision through the Marketplace, so if we go, we're not going to do it this way.

1946
02:39:02,480 --> 02:39:07,840
If you type in Custom Vision, it never shows up here, but if you go to the Marketplace here and type in Custom Vision...

1947
02:39:09,600 --> 02:39:11,760
And you go here, you can create it this way.

1948
02:39:11,760 --> 02:39:19,360
But the way I like to do it, I think it's a lot easier to do, is we'll go up the top here and type in customvision.ai, and you'll come to this website.

1949
02:39:19,560 --> 02:39:21,360
And what you'll do is go ahead and sign in.

1950
02:39:21,360 --> 02:39:23,040
It's going to connect to your Azure account.

1951
02:39:23,280 --> 02:39:25,880
And once you're in, you can go ahead here and create a new project.

1952
02:39:25,880 --> 02:39:28,520
So the first one here is I'm just going to call this the Star Trek crew.

1953
02:39:28,520 --> 02:39:32,200
We're going to use this to identify different Star Trek members.

1954
02:39:32,200 --> 02:39:33,120
We'll go down here.

1955
02:39:33,520 --> 02:39:36,400
And we haven't yet created a resource, so we'll go create new.

1956
02:39:38,240 --> 02:39:40,080
My custom vision resource.

1957
02:39:42,480 --> 02:39:43,280
We'll drop this down.

1958
02:39:43,280 --> 02:39:45,520
We'll put this in our COG services.

1959
02:39:46,160 --> 02:39:50,720
We'll go stick with US West as much as we can here.

1960
02:39:50,960 --> 02:39:52,400
We have FO and SO.

1961
02:39:52,480 --> 02:39:54,720
FO is blocked out for me, so just choose SO.

1962
02:39:54,720 --> 02:39:56,960
I think FO is the free tier, but I don't get it.

1963
02:39:59,560 --> 02:40:03,520
And once we're back here, we'll go down below and choose our standard.

1964
02:40:03,520 --> 02:40:05,360
And we're going to have a lot of options here.

1965
02:40:05,360 --> 02:40:08,000
So we have between classification and object detection.

1966
02:40:08,000 --> 02:40:13,840
So classification is when you have an image and you just want to say, what is this image, right?

1967
02:40:13,840 --> 02:40:17,640
And so we have two modes where we can say, let's apply multiple labels.

1968
02:40:17,640 --> 02:40:21,680
So let's say there were two people in the photo or whether there was a dog and cat.

1969
02:40:21,680 --> 02:40:23,440
I think that's an example that he's a dog and a cat.

1970
02:40:23,840 --> 02:40:28,000
Or you just have a single class where it's like, what is the one thing that is in this photo?

1971
02:40:28,000 --> 02:40:29,480
It can only be of one of the particular

1972
02:40:29,560 --> 02:40:30,160
categories.

1973
02:40:30,400 --> 02:40:32,480
This is the one we're going to do multiclass.

1974
02:40:32,720 --> 02:40:34,400
We have a bunch of different domains here.

1975
02:40:34,400 --> 02:40:39,080
And if you want to, you can go ahead and read about all the different domains and their best use case.

1976
02:40:39,080 --> 02:40:40,720
But we're going to stick with A2.

1977
02:40:40,960 --> 02:40:43,640
This is optimized for so that it's faster, right?

1978
02:40:43,640 --> 02:40:44,960
And that's really good for our demo.

1979
02:40:45,760 --> 02:40:47,280
So we're going to choose General A2.

1980
02:40:47,280 --> 02:40:49,120
I'm going to go ahead and create this project.

1981
02:40:50,880 --> 02:40:55,680
And so now what we need to do is start labeling our content.

1982
02:40:55,680 --> 02:40:56,840
So we're

1983
02:40:56,840 --> 02:40:59,760
what we'll do is I just want to go ahead and create the tags ahead of time.

1984
02:40:59,760 --> 02:41:05,520
So let's say WARF, we'll have data, and we'll have crusher.

1985
02:41:07,560 --> 02:41:09,760
And now what we'll do is we'll go ahead and upload those images.

1986
02:41:09,760 --> 02:41:13,040
So, you know, we uploaded the Jupyter Notebook, but it was totally not necessary.

1987
02:41:13,040 --> 02:41:16,240
So here is data, because we're going to do it all through here.

1988
02:41:16,240 --> 02:41:19,840
And we'll just apply the data tag to them all at once, which saves us a lot of time.

1989
02:41:19,840 --> 02:41:20,640
I love that.

1990
02:41:21,360 --> 02:41:23,840
We'll upload now WARF.

1991
02:41:25,320 --> 02:41:30,000
And I don't want to upload them all, I have this one quick test image we're going to use to make sure that this works correctly.

1992
02:41:31,440 --> 02:41:32,560
And I'm going to choose wharf.

1993
02:41:35,360 --> 02:41:37,120
And then we'll go ahead and add Beverly.

1994
02:41:40,480 --> 02:41:41,280
There she is.

1995
02:41:43,120 --> 02:41:44,000
Beverly crusher.

1996
02:41:45,200 --> 02:41:47,120
Okay, so we have all our images.

1997
02:41:47,160 --> 02:41:51,120
And I don't know how this one got in here, but it's under warf, it works out totally fine.

1998
02:41:51,360 --> 02:41:53,600
So what I want to do

1999
02:41:54,800 --> 02:42:01,920
is go ahead and train this model, because they're all labeled, so we have a ground truth, and we'll let it go ahead and train.

2000
02:42:01,920 --> 02:42:03,080
So we'll go and press train.

2001
02:42:03,080 --> 02:42:08,640
And we have two options, quick training or advanced training, advanced training, where we can increase the time for better accuracy.

2002
02:42:08,960 --> 02:42:11,480
But honestly, we just want to do quick training.

2003
02:42:11,480 --> 02:42:12,880
So I'll go ahead and do quick training.

2004
02:42:13,600 --> 02:42:15,760
And it's going to start its iterative process.

2005
02:42:15,760 --> 02:42:18,320
Notice on the left-hand side, we have probability threshold.

2006
02:42:18,720 --> 02:42:24,640
the minimum probability score for a prediction to be valid when calculating precision and recall.

2007
02:42:24,640 --> 02:42:29,440
So the thing is that if it doesn't at least meet that requirement, it will quit out.

2008
02:42:29,760 --> 02:42:34,960
And if it gets above that, then it might quit out early just because it's good enough, okay?

2009
02:42:34,960 --> 02:42:36,520
So training doesn't take too long.

2010
02:42:36,520 --> 02:42:37,760
It might take 5 to 10 minutes.

2011
02:42:37,920 --> 02:42:42,400
I can't remember how long it takes, but what I'll do is I'll see you back here in a moment, okay?

2012
02:42:42,960 --> 02:42:47,520
All right, so after waiting a short little while here, it looks like our results are done.

2013
02:42:47,760 --> 02:42:48,280
We get 100%

2014
02:42:48,960 --> 02:42:49,320
match here.

2015
02:42:49,320 --> 02:42:55,840
So these are our evaluation metrics to say whether the model was achieved its actual goal or not.

2016
02:42:56,080 --> 02:43:00,640
So we have precision, recall, and I believe this is average precision.

2017
02:43:01,320 --> 02:43:03,440
And so it says that it did a really good job.

2018
02:43:03,440 --> 02:43:07,120
So that means that it should have no problem matching up an image.

2019
02:43:07,120 --> 02:43:10,200
So in the top right corner, we have this button that's called quick test.

2020
02:43:10,200 --> 02:43:13,440
And this is going to give us the opportunity to quickly test these.

2021
02:43:13,440 --> 02:43:16,720
So what we'll do is browse our files locally here.

2022
02:43:17,840 --> 02:43:23,040
And actually I'm going to go to, we'll go here and we have WARF.

2023
02:43:23,920 --> 02:43:25,360
And so I have this quick image here.

2024
02:43:25,360 --> 02:43:27,640
We'll test and we'll see if it actually matches up to be WARF.

2025
02:43:29,080 --> 02:43:30,840
And it says 98.7% WARF.

2026
02:43:30,840 --> 02:43:31,520
So that's pretty good.

2027
02:43:31,680 --> 02:43:35,760
I also have some additional images here I just put into the repo to test again.

2028
02:43:35,760 --> 02:43:42,960
So we'll see what it matches up because I thought it'd be interesting to do something that is not necessarily them, but it's something pretty close to

2029
02:43:44,160 --> 02:43:46,240
it's pretty close to what those are, okay?

2030
02:43:46,640 --> 02:43:51,280
So we'll go to crew here, and 1st we'll try Hugh, okay?

2031
02:43:51,680 --> 02:43:57,680
And Hugh is a Borg, so he's kind of like an android, and so we can see he mostly matches to data, so that's pretty good.

2032
02:43:58,560 --> 02:43:59,840
We'll give another one go.

2033
02:43:59,840 --> 02:44:02,560
Martok is a Klingon, so he should be matched up to Worf.

2034
02:44:03,520 --> 02:44:04,840
very strong match to work.

2035
02:44:04,840 --> 02:44:05,680
That's pretty good.

2036
02:44:06,080 --> 02:44:11,880
And then Pulaski, she is a doctor and female, so she should get matched up to Beverly crusher.

2037
02:44:11,880 --> 02:44:12,480
And she does.

2038
02:44:12,480 --> 02:44:14,640
So this works out pretty darn well.

2039
02:44:15,360 --> 02:44:16,440
And I hadn't even tried that.

2040
02:44:16,440 --> 02:44:17,200
So it's pretty exciting.

2041
02:44:17,200 --> 02:44:24,720
So now let's say we want to go ahead and well, if we wanted to make predictions, we could do them in bulk here.

2042
02:44:26,080 --> 02:44:27,520
I believe that you could do them in bulk.

2043
02:44:27,760 --> 02:44:28,160
But anyway,

2044
02:44:31,320 --> 02:44:34,080
Yeah, I guess I always thought this was like, I could have swore.

2045
02:44:34,080 --> 02:44:37,080
Yeah, if we didn't have these images before, I think that it actually has an upload option.

2046
02:44:37,080 --> 02:44:38,320
It's probably just a quick test.

2047
02:44:38,560 --> 02:44:39,760
So I'm a bit confused there.

2048
02:44:40,320 --> 02:44:46,480
But anyway, so now that this is ready, what we can do is go ahead and publish it so that it is publicly accessible.

2049
02:44:46,480 --> 02:44:48,480
So we'll just say here, crew model.

2050
02:44:49,800 --> 02:44:51,840
Okay, and we'll drop that down, say publish.

2051
02:44:56,640 --> 02:44:59,440
And once it's published, now we have this public URL.

2052
02:44:59,440 --> 02:45:02,000
So this is an endpoint that we can go hit pragmatically.

2053
02:45:02,480 --> 02:45:03,440
I'm not going to do that.

2054
02:45:03,520 --> 02:45:05,200
I mean, we could use Postman to do that.

2055
02:45:05,840 --> 02:45:10,800
But my point is that we've basically figured it out for classification.

2056
02:45:10,800 --> 02:45:16,720
So now that we've done classification, let's go back here to the vision here.

2057
02:45:16,720 --> 02:45:19,920
And now let's go ahead and do object detection, okay?

2058
02:45:25,120 --> 02:45:28,480
Alright, so we're still in custom vision, let's go ahead and try out object detection.

2059
02:45:28,480 --> 02:45:32,480
So object detection is when you can identify particular items in a scene.

2060
02:45:33,360 --> 02:45:40,400
And so this one's going to be combat, we're going to call it because we're going to try to detect combat, we have more domains here, we're gonna stick with the general a one.

2061
02:45:41,680 --> 02:45:43,840
And we'll go ahead and create this project here.

2062
02:45:45,520 --> 02:45:52,800
And so what we need to do is add a bunch of images, I'm going to go ahead and create our tag, which is going to be called combat, you could

2063
02:45:53,360 --> 02:45:57,200
look for multiple different kinds of labels, but then you need a lot of images.

2064
02:45:57,200 --> 02:45:59,280
So we're just going to keep it simple and have that there.

2065
02:45:59,840 --> 02:46:01,920
I'm going to go ahead and add some images.

2066
02:46:02,000 --> 02:46:05,800
And we're going to go back a couple steps here into our objects.

2067
02:46:05,800 --> 02:46:06,760
And here I have a bunch of photos.

2068
02:46:06,760 --> 02:46:08,400
And we need exactly 15 to train.

2069
02:46:08,400 --> 02:46:14,080
So we've got 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16.

2070
02:46:14,480 --> 02:46:17,040
And so I threw an additional image in here.

2071
02:46:17,040 --> 02:46:17,840
This is the badge test.

2072
02:46:17,840 --> 02:46:18,880
So we'll leave that out.

2073
02:46:19,280 --> 02:46:21,040
And we'll see if that picks up really well.

2074
02:46:22,520 --> 02:46:22,800
And

2075
02:46:23,280 --> 02:46:24,320
Yeah, we got them all here.

2076
02:46:24,320 --> 02:46:26,320
And so we'll go ahead and upload those.

2077
02:46:27,160 --> 02:46:28,480
And we'll hit upload files.

2078
02:46:30,240 --> 02:46:30,440
Okay.

2079
02:46:30,440 --> 02:46:33,840
And we'll say done.

2080
02:46:34,160 --> 02:46:36,880
And we can now begin to label so we'll click into here.

2081
02:46:36,880 --> 02:46:40,080
And what I want to do if you hover over it should start detecting things.

2082
02:46:40,240 --> 02:46:42,560
If it doesn't, you can click and drag, we'll click this one.

2083
02:46:42,560 --> 02:46:43,520
They're all com badges.

2084
02:46:43,520 --> 02:46:45,000
So we're not going to tag anything else here.

2085
02:46:45,000 --> 02:46:45,280
Okay.

2086
02:46:45,760 --> 02:46:48,400
So go here, hover over, is it going to give me the com badge?

2087
02:46:48,400 --> 02:46:50,720
No, so I'm just clicking and dragging to get it.

2088
02:46:51,000 --> 02:46:51,160
Okay.

2089
02:46:52,760 --> 02:46:53,920
Okay, do we get this combat?

2090
02:46:53,920 --> 02:46:54,560
Yes.

2091
02:46:57,280 --> 02:46:58,000
We get this one?

2092
02:46:58,000 --> 02:46:58,400
Yep.

2093
02:47:00,800 --> 02:47:01,920
So as simple as that.

2094
02:47:04,920 --> 02:47:07,600
It doesn't always get it, but most cases it does.

2095
02:47:11,840 --> 02:47:12,800
Okay, didn't get that one.

2096
02:47:12,800 --> 02:47:13,600
So let's drag it out.

2097
02:47:18,920 --> 02:47:19,920
It's not getting that one.

2098
02:47:23,280 --> 02:47:25,120
It's interesting, like that one's pretty clear.

2099
02:47:25,120 --> 02:47:28,800
But it's interesting what it picks out and what does what does not grabbing.

2100
02:47:28,800 --> 02:47:32,000
So it's not getting this one probably because the photo doesn't have enough contrast.

2101
02:47:34,080 --> 02:47:38,480
And this one has a lot, hoping that that gives us more data to work with here.

2102
02:47:39,440 --> 02:47:45,200
Yeah, I think the higher the contrast easier for it to detect those.

2103
02:47:45,760 --> 02:47:47,280
It's not getting that one.

2104
02:47:48,560 --> 02:47:49,680
Not getting that one.

2105
02:47:49,760 --> 02:47:50,480
Okay, there we go.

2106
02:47:58,280 --> 02:47:59,560
Yes, there are a lot.

2107
02:47:59,560 --> 02:48:02,840
I know I have some of these ones that are packed, but there's only like three photos that are like this.

2108
02:48:08,210 --> 02:48:10,290
Yeah, they have badges, but they're slightly different.

2109
02:48:10,290 --> 02:48:11,650
So we're going to leave those out.

2110
02:48:13,250 --> 02:48:15,250
I think I actually had that one, but we'll just tag it anyway.

2111
02:48:27,000 --> 02:48:29,600
And hopefully this will be worth the effort here.

2112
02:48:33,760 --> 02:48:34,320
There we go.

2113
02:48:37,120 --> 02:48:38,640
I think that was the last one.

2114
02:48:39,960 --> 02:48:40,320
Okay, great.

2115
02:48:40,320 --> 02:48:41,840
So we have all of our tagged photos.

2116
02:48:41,840 --> 02:48:44,160
And what we can do is go ahead and train the model.

2117
02:48:44,480 --> 02:48:46,120
Same option, quick training, advanced training.

2118
02:48:46,120 --> 02:48:47,440
We're going to do a quick training here.

2119
02:48:47,640 --> 02:48:49,520
And notice that the options are slightly different.

2120
02:48:49,520 --> 02:48:50,880
We have probably threshold.

2121
02:48:51,200 --> 02:48:52,640
And then we have overlap threshold.

2122
02:48:52,640 --> 02:48:58,640
So the minimum percentage of overlap between predictive bounding boxes and ground truth boxes to be considered for correct prediction.

2123
02:48:59,040 --> 02:49:01,200
So I'll see you back here when it is done.

2124
02:49:02,040 --> 02:49:06,240
All right, so after waiting a little bit of a while here, it looks like it's done, it's trained.

2125
02:49:06,240 --> 02:49:07,440
And so precision's at 75%.

2126
02:49:07,440 --> 02:49:14,160
So precision, the number will tell you if a tag is predicted by your model, how likely that it's likely to be.

2127
02:49:14,160 --> 02:49:16,080
So how likely did it guess right?

2128
02:49:16,080 --> 02:49:17,120
Then you have recall.

2129
02:49:17,120 --> 02:49:23,120
So the number will tell you out of the tags, which should be predicted correctly, what percentage does your model correctly find?

2130
02:49:23,120 --> 02:49:24,160
So we have 100%.

2131
02:49:25,120 --> 02:49:27,360
And then you have mean average precision.

2132
02:49:27,360 --> 02:49:33,200
This number will tell you the overall object detector performance across all the tags.

2133
02:49:33,280 --> 02:49:38,400
Okay, so what we'll do is we'll go ahead and do a quick test on this model.

2134
02:49:39,160 --> 02:49:40,480
And we'll see how it does.

2135
02:49:40,480 --> 02:49:43,360
I can't remember if I actually even ran this, so it'll be curious to see.

2136
02:49:43,600 --> 02:49:46,960
The first one here, it's not as clearly visible.

2137
02:49:46,960 --> 02:49:50,560
It's part of their uniform, so I'm not expecting you to pick it up, but we'll see what it does.

2138
02:49:50,560 --> 02:49:53,040
It picks up pretty much all of them.

2139
02:49:53,880 --> 02:49:57,760
Exception, this one is definitely not a compadge, but that's okay.

2140
02:49:58,560 --> 02:50:01,520
Only show suggested, obviously, the probability is above the selected threshold.

2141
02:50:03,040 --> 02:50:06,880
So if we increase it, let's bring it down a bit.

2142
02:50:06,880 --> 02:50:10,720
So there it kind of improves it if we move it around back and forth.

2143
02:50:10,720 --> 02:50:11,120
Okay.

2144
02:50:12,240 --> 02:50:14,520
So I imagined via the API, we could choose that.

2145
02:50:14,520 --> 02:50:17,520
Let's go look at our other sample image here.

2146
02:50:19,840 --> 02:50:21,920
I'm not seeing it.

2147
02:50:24,280 --> 02:50:25,120
Where did I save it?

2148
02:50:26,160 --> 02:50:29,280
Let me just double check, make sure that it's in the correct directory here.

2149
02:50:29,440 --> 02:50:29,840
Okay.

2150
02:50:31,120 --> 02:50:32,400
Yeah, I saved it to the wrong place.

2151
02:50:32,400 --> 02:50:33,280
Just a moment.

2152
02:50:38,240 --> 02:50:39,920
I will place it.

2153
02:50:39,920 --> 02:50:45,760
I'll just call that vegtest2, one second.

2154
02:50:51,780 --> 02:50:54,020
Okay, and so I'll just browse here again.

2155
02:50:54,020 --> 02:50:56,340
And so here we have another one.

2156
02:50:56,760 --> 02:50:58,000
See if it picks up the badge right here.

2157
02:50:59,040 --> 02:50:59,520
There we go.

2158
02:50:59,520 --> 02:51:00,760
So looks like it works.

2159
02:51:00,760 --> 02:51:06,240
So yeah, I guess custom vision is pretty easy to use and pretty darn good.

2160
02:51:06,240 --> 02:51:16,240
So what we'll do is close this off and make our way back to our Jupyter labs to move on to our next lab here.

2161
02:51:16,240 --> 02:51:16,400
Okay.

2162
02:51:21,400 --> 02:51:23,400
All right, so let's move on to the face service.

2163
02:51:23,400 --> 02:51:25,360
So just go ahead and double click there on the left-hand side.

2164
02:51:25,360 --> 02:51:27,240
And what we'll do is work our way from the top.

2165
02:51:27,240 --> 02:51:31,400
So the first thing we need to do is make sure that we have the computer vision installed.

2166
02:51:31,400 --> 02:51:35,120
So the face service is part of the computer vision API.

2167
02:51:35,760 --> 02:51:39,360
And once that is done, we'll go ahead and do our imports.

2168
02:51:39,600 --> 02:51:42,440
Very similar to the last one, but here we're using the face client.

2169
02:51:42,440 --> 02:51:45,920
We're still using the cognitive service credentials.

2170
02:51:46,160 --> 02:51:47,840
We will populate our keys.

2171
02:51:48,080 --> 02:51:50,240
We'll make the face client and authenticate.

2172
02:51:51,080 --> 02:51:55,880
And we're going to use the same image we used prior with our computer vision.

2173
02:51:55,920 --> 02:51:56,880
So the data went there.

2174
02:51:57,200 --> 02:51:59,520
And we'll go ahead and print out the results.

2175
02:51:59,800 --> 02:52:00,840
And so we get an object back.

2176
02:52:00,840 --> 02:52:08,720
So it's not very clear what it is, but here, if we hit show, okay, here it's data and it's identifying the face IDs of going through this code.

2177
02:52:08,720 --> 02:52:10,480
So we're just saying open the image.

2178
02:52:10,800 --> 02:52:13,280
We're going to set up our figure for plotting.

2179
02:52:13,920 --> 02:52:16,880
It's going to say, well, how many faces did it detect in the photo?

2180
02:52:16,960 --> 02:52:20,400
And so here it says detected one face.

2181
02:52:20,840 --> 02:52:22,080
It will iterate through it.

2182
02:52:22,320 --> 02:52:24,800
And then we will create a bounding box around the images.

2183
02:52:24,800 --> 02:52:27,600
We can do that because it returns back the face rectangle.

2184
02:52:27,600 --> 02:52:30,320
So we got a top, left, right, et cetera.

2185
02:52:30,800 --> 02:52:33,000
And we will draw that wrangle on top.

2186
02:52:33,000 --> 02:52:33,760
So we have magenta.

2187
02:52:33,760 --> 02:52:36,360
I could change it to like 3 if I wanted to.

2188
02:52:36,360 --> 02:52:40,240
I don't know what the other colors are, so I'm not even going to try, but yeah, there it is.

2189
02:52:40,680 --> 02:52:42,240
And then we annotate with the face ID.

2190
02:52:42,240 --> 02:52:44,200
That's the unique identifier for the face.

2191
02:52:44,200 --> 02:52:46,320
And then we show the image, okay?

2192
02:52:47,160 --> 02:52:47,840
So that's one.

2193
02:52:47,840 --> 02:52:56,400
And then if we wanted to get more detailed information like attributes, such as age, emotion, makeup, or gender, this resolution image wasn't large enough.

2194
02:52:56,400 --> 02:52:59,120
So I had to find a different image and do that.

2195
02:52:59,120 --> 02:53:02,880
So that's one thing you need to know, is if it's not large enough, it won't process it.

2196
02:53:02,880 --> 02:53:04,640
So we're just loading data large.

2197
02:53:06,480 --> 02:53:13,200
Very similar process, but it is the same thing, detect with stream, but now we're passing in

2198
02:53:15,360 --> 02:53:16,440
return face attributes.

2199
02:53:16,440 --> 02:53:18,560
And so here we're saying the attributes we want.

2200
02:53:19,480 --> 02:53:21,920
And there's that list, and we went through it in the lecture content.

2201
02:53:21,920 --> 02:53:24,560
And so here, we'll go ahead and run this.

2202
02:53:25,160 --> 02:53:26,640
And so we're getting more information.

2203
02:53:26,640 --> 02:53:28,600
So that magenta line is a bit hard to see.

2204
02:53:28,600 --> 02:53:30,240
I'm just going to increase that to three.

2205
02:53:31,520 --> 02:53:31,920
Okay.

2206
02:53:32,720 --> 02:53:34,160
Still really hard to see, but that's okay.

2207
02:53:34,160 --> 02:53:36,000
So approximate age, 44.

2208
02:53:36,240 --> 02:53:38,160
I think the actor was a bit younger than that.

2209
02:53:39,280 --> 02:53:44,880
Data technically is male presenting, but he's an android, so he doesn't necessarily have a gender, I suppose.

2210
02:53:45,200 --> 02:53:50,640
He actually is wearing a lot of makeup, but all it detects is, I guess it's only particular on the lips and the eyes.

2211
02:53:50,880 --> 02:53:52,000
So it says he doesn't have makeup.

2212
02:53:52,000 --> 02:53:55,520
So maybe there's a color, you know, like eye shadow stuff, maybe it would detect that.

2213
02:53:55,920 --> 02:54:02,640
In terms of personality, I like how he's a 002% sad, but he's neutral, right?

2214
02:54:03,360 --> 02:54:05,120
So just going through the code here very quickly.

2215
02:54:05,120 --> 02:54:06,720
So again, it's the number of faces.

2216
02:54:06,720 --> 02:54:08,160
So it detected one face.

2217
02:54:08,880 --> 02:54:13,280
And then we draw a bounding box around the face for the detected attributes.

2218
02:54:13,280 --> 02:54:16,080
It's returned back in the data here.

2219
02:54:16,080 --> 02:54:24,320
So we just say get the face attributes, turn it into a dictionary, and then we can just get those values and iterate over it.

2220
02:54:24,320 --> 02:54:26,480
So that's as complicated as it is.

2221
02:54:27,240 --> 02:54:27,920
And so there we go.

2222
02:54:33,280 --> 02:54:34,640
All right, so we're on to

2223
02:54:35,200 --> 02:54:36,880
our next cognitive service.

2224
02:54:36,880 --> 02:54:38,640
Let's take a look at Form Recognizer.

2225
02:54:39,280 --> 02:54:39,560
All right.

2226
02:54:39,560 --> 02:54:46,240
And so Form Recognizer, it tries to identify like forms and turns them into readable things.

2227
02:54:46,440 --> 02:54:48,960
And so they have one for receipts in particular.

2228
02:54:48,960 --> 02:54:53,440
So at the top, finally, we're not using computer vision.

2229
02:54:53,440 --> 02:54:54,400
We actually have a different one.

2230
02:54:54,400 --> 02:54:56,640
So this one's Azure AI Form Recognizer.

2231
02:54:56,960 --> 02:54:57,840
So we'll run that there.

2232
02:54:58,080 --> 02:55:04,720
But this one in particular isn't up to date in terms of using it like, notice all the other ones they're using

2233
02:55:05,760 --> 02:55:07,680
the cognitive service credential.

2234
02:55:07,680 --> 02:55:11,960
So for this, we actually had to use the Azure key credential, which was annoying.

2235
02:55:12,000 --> 02:55:16,080
I tried to use the other one to be consistent, but I couldn't use it.

2236
02:55:16,080 --> 02:55:16,320
Okay.

2237
02:55:16,480 --> 02:55:18,800
So what we'll do is run our keys like before.

2238
02:55:18,960 --> 02:55:21,120
We have a client, very similar process.

2239
02:55:22,560 --> 02:55:24,160
And this time we actually have a receipt.

2240
02:55:25,280 --> 02:55:27,720
And so we have begin recognize receipt.

2241
02:55:27,720 --> 02:55:29,760
So it's going to analyze the receipt information.

2242
02:55:30,560 --> 02:55:32,800
And then what it's going to do is show us the image.

2243
02:55:33,480 --> 02:55:35,200
Okay, just so we have a reference to look at.

2244
02:55:35,760 --> 02:55:37,360
Now, the image isn't actually yellow.

2245
02:55:37,360 --> 02:55:38,440
It's a white background.

2246
02:55:38,440 --> 02:55:41,520
I don't know why when it renders out here, it does that, but that's just what happens.

2247
02:55:42,320 --> 02:55:44,880
And it even obscures the server name.

2248
02:55:45,040 --> 02:55:45,760
I don't know why.

2249
02:55:46,720 --> 02:55:52,080
But anyway, if we go down below, this is return results up here, right?

2250
02:55:52,080 --> 02:55:53,440
So we got our results.

2251
02:55:53,840 --> 02:55:58,560
And so if we just print out the results, here we can see we get a recognized form back.

2252
02:55:58,560 --> 02:55:59,680
We get fields.

2253
02:56:00,280 --> 02:56:01,160
and some additional things.

2254
02:56:01,160 --> 02:56:04,880
And if we go into the fields itself, we see there's a lot more information.

2255
02:56:04,880 --> 02:56:12,160
If you can make out like here, it says merchant phone number, form field, label, value, and there's a number 512707.

2256
02:56:12,160 --> 02:56:22,240
So for these things here, like the receipts, if we can just find the API quickly here, it has predefined fields.

2257
02:56:23,320 --> 02:56:26,880
I'm not sure, yeah, business card, et cetera.

2258
02:56:29,600 --> 02:56:35,120
if we just type in merchant, I'm just trying to see if there's a big old list here.

2259
02:56:35,360 --> 02:56:40,400
It's not really showing us a full list, but these are predefined things that are returned, right?

2260
02:56:40,400 --> 02:56:42,240
So they've defined those.

2261
02:56:42,560 --> 02:56:43,360
Maybe it's over here.

2262
02:56:44,720 --> 02:56:45,200
There we go.

2263
02:56:45,200 --> 02:56:47,200
So these are the predefined ones it extracts out.

2264
02:56:47,200 --> 02:56:50,960
So we have receipt type, merchant name, et cetera, et cetera.

2265
02:56:51,320 --> 02:56:54,320
And so if we go back to here, you can see.

2266
02:56:54,880 --> 02:56:56,800
I have a field called Merchant Name.

2267
02:56:57,040 --> 02:56:58,000
So we hit there.

2268
02:56:58,000 --> 02:56:59,600
It says Alamo Draft Out Cinema.

2269
02:56:59,800 --> 02:57:01,400
Let's say we want to try to get that balance.

2270
02:57:01,400 --> 02:57:03,120
Maybe we can try to figure out which one it is.

2271
02:57:03,360 --> 02:57:06,720
I never ran this myself when I made it, so we'll see what it is.

2272
02:57:07,120 --> 02:57:08,840
But here it has total price.

2273
02:57:08,840 --> 02:57:11,600
What's interesting is that these, this is a space.

2274
02:57:12,240 --> 02:57:14,280
So it's kind of unusual.

2275
02:57:14,280 --> 02:57:16,800
You'd think it'd be together, but let's see if that works.

2276
02:57:18,720 --> 02:57:19,840
Okay, it doesn't like that.

2277
02:57:20,800 --> 02:57:22,240
Maybe that's just a typo on their part.

2278
02:57:22,920 --> 02:57:23,920
Okay, so we get none.

2279
02:57:24,240 --> 02:57:25,760
Let's try price.

2280
02:57:27,040 --> 02:57:27,920
See what it picks up.

2281
02:57:29,840 --> 02:57:30,800
Nope, nothing.

2282
02:57:32,640 --> 02:57:35,280
We know that the phone number's there, so we'll give the phone number.

2283
02:57:37,440 --> 02:57:37,840
There we go.

2284
02:57:38,000 --> 02:57:46,720
So, you know, it's an okay service, but, you know, your mileage will vary based on what you do there.

2285
02:57:46,840 --> 02:57:49,680
Maybe we could try total, because that makes more sense, right?

2286
02:57:51,840 --> 02:57:52,320
Yeah, there we go.

2287
02:57:52,320 --> 02:57:52,800
Okay, great.

2288
02:57:52,800 --> 02:57:54,640
So yeah, it is pulling out the information.

2289
02:57:55,160 --> 02:57:58,440
And so that's pretty much all you need to know about that service there, okay?

2290
02:58:04,000 --> 02:58:06,800
Let's take a look at some of our OCR capabilities here.

2291
02:58:06,880 --> 02:58:09,920
And I believe that's in Computer Vision, so we'll go ahead and open that up.

2292
02:58:10,240 --> 02:58:13,280
At the top here, we'll install Computer Vision, as we did before.

2293
02:58:14,240 --> 02:58:18,720
Very similar to the other Computer Vision tasks, but this time we have a couple of ones here.

2294
02:58:19,400 --> 02:58:21,040
Then I'll explain that as we go through here.

2295
02:58:21,040 --> 02:58:25,600
We'll load our keys, we'll do our credentials, we'll load the client.

2296
02:58:26,240 --> 02:58:30,160
Okay, and so we have this function here called printed text.

2297
02:58:30,560 --> 02:58:37,520
So what this function is going to do is it's going to print out the results of whatever text it processes.

2298
02:58:37,520 --> 02:58:41,360
Okay, so the idea is that we're going to feed in an image.

2299
02:58:41,920 --> 02:58:44,400
And it's going to give us back out the text for the image.

2300
02:58:44,400 --> 02:58:46,560
So we'll run this function.

2301
02:58:46,960 --> 02:58:49,920
And I have two different images because I actually ran it on the first one.

2302
02:58:49,920 --> 02:58:51,080
The results were terrible.

2303
02:58:51,080 --> 02:58:54,400
And so I got a second image and it was a bit better.

2304
02:58:54,400 --> 02:58:54,640
Okay.

2305
02:58:54,640 --> 02:58:55,640
So we'll go ahead and run this.

2306
02:58:55,640 --> 02:58:56,880
It's going to show us the image.

2307
02:58:57,760 --> 02:58:58,000
Okay.

2308
02:58:58,040 --> 02:58:59,040
And so this is the photo.

2309
02:58:59,040 --> 02:59:01,200
It was supposed to extract out Star Trek, The Next Generation.

2310
02:59:01,200 --> 02:59:06,000
But because of the artifacts and size of the image, we get back not English.

2311
02:59:06,240 --> 02:59:06,440
Okay.

2312
02:59:07,320 --> 02:59:12,000
And so, maybe a high resolution image, it would have a better time there.

2313
02:59:12,720 --> 02:59:14,720
But that is what we got back, okay?

2314
02:59:14,720 --> 02:59:18,640
So let's go take a look at our second image and see how it did.

2315
02:59:19,120 --> 02:59:22,480
And this one, I'm surprised that it actually extracts out a lot more information.

2316
02:59:22,640 --> 02:59:29,360
You can see, it really has a hard time with the Star Trek font, but we get Deep Space Nine, Nana Visitor, Tells All, Life, Death, some errors here.

2317
02:59:29,360 --> 02:59:30,640
So it's not perfect.

2318
02:59:31,840 --> 02:59:33,920
But you can see that it does something here.

2319
02:59:34,240 --> 02:59:39,080
Now there is the, this is like for OCR where we have like first very simple images and text.

2320
02:59:39,080 --> 02:59:41,760
This is where we use the recognized printed text in stream.

2321
02:59:42,240 --> 02:59:50,920
But if we're doing this for larger amounts of text and we want to do this, want this analyzed asynchronously, then we want to use the read API.

2322
02:59:50,920 --> 02:59:52,240
And it's a little bit more involved.

2323
02:59:52,960 --> 02:59:55,000
So what we'll do here is load a different image.

2324
02:59:55,000 --> 02:59:55,920
And this is a script.

2325
02:59:55,920 --> 02:59:57,280
We'll look at the image here in a moment.

2326
02:59:58,080 --> 02:59:59,920
But here we read in stream.

2327
03:00:00,800 --> 03:00:02,480
And we create these operations.

2328
03:00:03,080 --> 03:00:03,360
Okay.

2329
03:00:03,840 --> 03:00:08,880
And what it will do is it will asynchronously send all the information over.

2330
03:00:08,880 --> 03:00:09,360
Okay.

2331
03:00:09,840 --> 03:00:12,160
So I think this is supposed to be results here.

2332
03:00:13,440 --> 03:00:14,240
Minor typo.

2333
03:00:14,640 --> 03:00:18,160
And we will go ahead and give that a run.

2334
03:00:19,840 --> 03:00:20,160
Okay.

2335
03:00:20,440 --> 03:00:22,400
And so here you can see it's extracting out the image.

2336
03:00:22,400 --> 03:00:24,880
If we want to see this image.

2337
03:00:25,200 --> 03:00:28,760
I thought I showed this image here, but I guess I don't.

2338
03:00:29,480 --> 03:00:36,240
Yeah, it says plot image here to show us the image path.

2339
03:00:36,880 --> 03:00:37,680
It's up here.

2340
03:00:39,960 --> 03:00:41,200
It doesn't want to show us.

2341
03:00:41,400 --> 03:00:43,840
It's funny because this one up here is showing us no problem, right?

2342
03:00:47,520 --> 03:00:48,680
Well, I can just show you the image.

2343
03:00:48,680 --> 03:00:49,680
It's not a big deal.

2344
03:00:51,040 --> 03:00:53,440
But I'm not sure why it's not showing up here today.

2345
03:00:55,360 --> 03:00:57,760
So if we go to our assets here,

2346
03:00:58,760 --> 03:00:59,840
I go to OCR.

2347
03:01:01,840 --> 03:01:02,960
I'm just going to open this up.

2348
03:01:04,440 --> 03:01:05,480
It's opening up in Photoshop.

2349
03:01:05,480 --> 03:01:07,280
And so this is what it's transcribing, okay?

2350
03:01:07,280 --> 03:01:13,680
So this is a thing, this is like a guide to Star Trek where they talk about like, you know, what makes Star Trek Star Trek.

2351
03:01:14,080 --> 03:01:16,720
So just looking here, it's actually pretty darn good, okay?

2352
03:01:16,960 --> 03:01:23,040
But like read API is a lot more efficient because it can work asynchronously.

2353
03:01:23,040 --> 03:01:25,840
And so when you have a lot of text, that's what you want to do, okay?

2354
03:01:27,400 --> 03:01:29,600
And like it's feeding in each individual line, right?

2355
03:01:29,600 --> 03:01:31,440
So that it can be more effective that way.

2356
03:01:32,080 --> 03:01:34,000
So let's go look at some handwritten stuff.

2357
03:01:34,000 --> 03:01:37,040
So just in case the image doesn't pop up, we'll go ahead and open this one.

2358
03:01:37,400 --> 03:01:44,480
And so this is a handwritten note that William Shatner wrote to a fan of Star Trek.

2359
03:01:44,800 --> 03:01:47,160
And it's basically incomprehensible.

2360
03:01:47,160 --> 03:01:49,600
I don't know if you can read that here, but let's see.

2361
03:01:50,480 --> 03:01:57,440
was very something, he was something, hospital and healthy was something, he was something.

2362
03:01:57,520 --> 03:01:58,400
I can't even read it.

2363
03:01:59,040 --> 03:01:59,520
Okay.

2364
03:01:59,760 --> 03:02:02,720
So let's see what the machine thinks here.

2365
03:02:05,400 --> 03:02:08,240
And it says image path.

2366
03:02:08,320 --> 03:02:09,200
Yeah, it's called path.

2367
03:02:09,320 --> 03:02:10,160
Let's just change that out.

2368
03:02:11,200 --> 03:02:12,000
Go ahead and run that.

2369
03:02:13,120 --> 03:02:13,920
And run that there.

2370
03:02:15,440 --> 03:02:16,400
And we'll go ahead and run it.

2371
03:02:17,600 --> 03:02:18,520
And here we get the image.

2372
03:02:18,520 --> 03:02:18,880
So

2373
03:02:20,240 --> 03:02:21,840
Poner, us, very sick.

2374
03:02:21,840 --> 03:02:25,120
He was the hospital, his BD was, et cetera.

2375
03:02:25,520 --> 03:02:28,000
Beat nobody, lost his family, knew Captain Halden.

2376
03:02:28,080 --> 03:02:30,160
So it reads better than how I could read it.

2377
03:02:30,240 --> 03:02:32,440
Honestly, like it is, it's really hard, right?

2378
03:02:32,440 --> 03:02:37,600
Like if you looked at this, like that looks like difficult.

2379
03:02:37,680 --> 03:02:40,400
Was BD healthy?

2380
03:02:40,400 --> 03:02:42,080
I could see why it's guessing like that, right?

2381
03:02:42,080 --> 03:02:42,560
Dying?

2382
03:02:42,880 --> 03:02:44,160
That looks like dying to me.

2383
03:02:45,080 --> 03:02:45,560
You know what I mean?

2384
03:02:45,560 --> 03:02:50,080
So it's just poorly handwritten, but I mean it's pretty good for what it is.

2385
03:02:50,080 --> 03:02:51,200
So yeah, there you go.

2386
03:02:56,560 --> 03:02:58,800
All right, so let's take a look at another cognitive service here.

2387
03:02:58,800 --> 03:03:01,040
And this one is text analysis.

2388
03:03:02,000 --> 03:03:07,120
And so what we'll do is install the Azure Cognitive Services Language Text Analytics here.

2389
03:03:07,600 --> 03:03:09,440
So we'll go ahead and hit run.

2390
03:03:10,320 --> 03:03:10,720
All right.

2391
03:03:11,200 --> 03:03:15,480
And once that's installed, this one actually is using the cognitive services credentials.

2392
03:03:15,480 --> 03:03:18,160
So it's a little bit more standard with our other ones here.

2393
03:03:18,440 --> 03:03:19,680
We'll go ahead and run that there.

2394
03:03:20,560 --> 03:03:23,760
We'll make our credentials, load our clients.

2395
03:03:24,160 --> 03:03:29,920
And this one, what we're going to do is try to determine sentiment and understand why people like a particular movie or not.

2396
03:03:29,920 --> 03:03:32,320
So I've loaded a bunch of reviews.

2397
03:03:32,720 --> 03:03:36,560
They are, again, I can show you the data if it helps.

2398
03:03:38,040 --> 03:03:40,400
And so I'm just trying to find my right folder here.

2399
03:03:40,760 --> 03:03:45,520
And so if we go back, look our movie reviews, here's like a review someone wrote.

2400
03:03:46,480 --> 03:03:47,600
First Contact just works.

2401
03:03:47,600 --> 03:03:49,760
It works as a rousing chapter in the Star Trek.

2402
03:03:49,840 --> 03:03:51,920
To a lesser extent, it works as a mainstream entertainment.

2403
03:03:51,920 --> 03:03:56,800
So different reviews for Star Trek First Contact, which was a very popular movie back in the day.

2404
03:03:57,840 --> 03:03:59,280
So what we'll do.

2405
03:04:00,560 --> 03:04:02,720
is we will load the reviews.

2406
03:04:02,720 --> 03:04:06,000
So it's just iterating through the text files and showing us what the reviews are.

2407
03:04:06,000 --> 03:04:07,920
So here we can see all the written text.

2408
03:04:08,320 --> 03:04:11,360
Had a lot of trouble getting the last one to display, but it does get loaded in.

2409
03:04:12,120 --> 03:04:20,880
And so here we're using the text analysis to show us key phrases, because maybe that would give us an indicator.

2410
03:04:21,320 --> 03:04:26,520
And so that's the object pack, but maybe that would give us an indicator as to like what people are saying as important things.

2411
03:04:26,520 --> 03:04:29,600
So here we see Borg ship, Enterprise, smaller ship escapes.

2412
03:04:29,920 --> 03:04:32,080
Neutral zone, travels, contact damage.

2413
03:04:32,640 --> 03:04:35,360
Co-writer, Beautiful Mind, Sophisticated Science Fiction.

2414
03:04:36,000 --> 03:04:37,840
Best, Wales, Leonard Nimoy.

2415
03:04:38,320 --> 03:04:38,600
Okay.

2416
03:04:40,000 --> 03:04:41,760
Wealth of Unrealized Potential.

2417
03:04:42,400 --> 03:04:43,920
Filmmaker John Franks.

2418
03:04:44,320 --> 03:04:46,080
Okay, so very interesting stuff.

2419
03:04:46,560 --> 03:04:47,560
Here, Borg ship again.

2420
03:04:47,560 --> 03:04:48,880
You've seen Borg ship A lot.

2421
03:04:49,280 --> 03:04:51,160
So that is kind of key phrases.

2422
03:04:51,160 --> 03:04:54,920
Let's go get customer sentiment or how people felt about it.

2423
03:04:54,920 --> 03:04:56,000
Did they like it or not?

2424
03:04:56,440 --> 03:04:58,080
And so here we just call sentiment.

2425
03:04:58,160 --> 03:05:03,760
And what we'll do is if it's above 5, then it's positive and it's below 5, then it's a negative review.

2426
03:05:04,120 --> 03:05:07,200
I think most people thought it was a very good film.

2427
03:05:07,760 --> 03:05:10,240
So this one says it's pretty low, 9.

2428
03:05:10,800 --> 03:05:12,320
So let's go take a look at that one.

2429
03:05:12,520 --> 03:05:16,160
It wasn't actually showing rendered there, so maybe we'll have to open it up manually.

2430
03:05:16,720 --> 03:05:18,080
See if that's actually accurate.

2431
03:05:18,320 --> 03:05:18,880
It's empty.

2432
03:05:18,880 --> 03:05:19,600
So there you go.

2433
03:05:20,320 --> 03:05:22,000
I guess we had a blank one in there.

2434
03:05:22,400 --> 03:05:24,640
I must have forgot to paste it in, but that's okay.

2435
03:05:25,200 --> 03:05:28,360
That's a good indicator that, you know, that's what happens if you don't have it.

2436
03:05:28,360 --> 03:05:32,640
So let's look at #1 then, which is, well, actually, this one is 9.

2437
03:05:32,640 --> 03:05:33,440
This is 04.

2438
03:05:33,600 --> 03:05:35,520
This one here is 8.

2439
03:05:36,080 --> 03:05:37,280
So open up 8.

2440
03:05:37,880 --> 03:05:41,760
When the Borg launched on Earth, the Enterprise is sent to the neutral zone, et cetera, et cetera.

2441
03:05:41,760 --> 03:05:44,800
However, a smaller ship escapes travel, the Enterprise follows back.

2442
03:05:46,640 --> 03:05:47,600
Meanwhile, the survivors.

2443
03:05:47,760 --> 03:05:49,200
So like this is a synopsis.

2444
03:05:49,200 --> 03:05:52,720
It doesn't say whether they like it or they don't, but it was just 04.

2445
03:05:52,800 --> 03:05:53,280
I guess so.

2446
03:05:53,280 --> 03:05:55,200
There's nothing positive about it, right?

2447
03:05:56,080 --> 03:06:00,800
If we look at one that was, this one's pretty low, which is, no, it's not.

2448
03:06:01,440 --> 03:06:02,160
It's 1.

2449
03:06:02,640 --> 03:06:05,280
So it seems like this person probably really liked it.

2450
03:06:06,000 --> 03:06:09,160
Or no, I guess that's actually pretty low because it's one, it's not nine.

2451
03:06:09,160 --> 03:06:10,160
Nine's very high.

2452
03:06:10,600 --> 03:06:11,600
Let's take a look at this one.

2453
03:06:11,600 --> 03:06:12,480
Review #2.

2454
03:06:12,480 --> 03:06:19,840
If we go up here, the dog has improved the story almost turn to show, but there's a wealth of unrealized potential.

2455
03:06:19,840 --> 03:06:22,880
So that's a fair one saying that maybe they don't like it as much.

2456
03:06:23,200 --> 03:06:25,280
I don't know if they give it two stars, right?

2457
03:06:25,280 --> 03:06:30,480
We could probably actually correlate it with the actual results because I did get these off of IMDB and Rotten Tomatoes.

2458
03:06:30,480 --> 03:06:31,960
But yeah, there you go.

2459
03:06:31,960 --> 03:06:33,680
That is text analysis.

2460
03:06:39,440 --> 03:06:41,920
All right, so now we're on to Q&A Maker.

2461
03:06:41,920 --> 03:06:51,920
And so we're not going to need to do anything programmatically because Q&A Maker is all about no code or low code to build out a questions and answers bot service.

2462
03:06:52,080 --> 03:06:59,680
So what we'll do is go all the way up to here and I want you to type in qnmaker.ai because as far as I'm aware of, it's not accessible through the portal.

2463
03:06:59,840 --> 03:07:04,320
Sometimes you can find these things again if we go to the marketplace.

2464
03:07:05,120 --> 03:07:05,760
I'm just curious.

2465
03:07:05,760 --> 03:07:07,360
I'm going to just take a look here really quickly.

2466
03:07:08,520 --> 03:07:10,000
Whenever it decides to log us in here.

2467
03:07:10,000 --> 03:07:10,560
Okay, great.

2468
03:07:10,560 --> 03:07:12,320
So I'll go over to Marketplace.

2469
03:07:13,400 --> 03:07:16,560
And probably if we type in Q&A, maybe we'd do something here.

2470
03:07:16,560 --> 03:07:17,280
Q&A.

2471
03:07:20,640 --> 03:07:21,920
Yeah, so we go here.

2472
03:07:24,400 --> 03:07:25,360
Give it a second here.

2473
03:07:26,960 --> 03:07:29,520
Seems like Azure is a little bit slow right now.

2474
03:07:29,520 --> 03:07:32,640
It's usually

2475
03:07:33,040 --> 03:07:35,840
varies fast, but the service varies.

2476
03:07:37,720 --> 03:07:41,200
it's not loading for me right now, but that's okay because we're not going to do it that way anyway.

2477
03:07:41,920 --> 03:07:44,400
So again, go to qnamaker.ai.

2478
03:07:44,640 --> 03:07:48,880
And what I want you to do is go all the way to the top of the right corner and we'll hit sign in.

2479
03:07:49,360 --> 03:07:53,360
And what we'll be doing is connecting via our single sign-on with our account.

2480
03:07:53,360 --> 03:07:54,960
So it already knows I have an account there.

2481
03:07:55,360 --> 03:07:56,720
I'm going to give it a moment here.

2482
03:07:57,120 --> 03:08:00,320
And I'm going to go ahead and just give it a second.

2483
03:08:15,040 --> 03:08:15,440
There we go.

2484
03:08:15,440 --> 03:08:18,960
So it says I don't have any knowledge base, which is true.

2485
03:08:18,960 --> 03:08:21,200
So let's go ahead and create ourselves a new knowledge base.

2486
03:08:21,760 --> 03:08:24,000
And here we have the option between stable and preview.

2487
03:08:24,000 --> 03:08:26,320
I'm going to stick with stable because I don't know what's in preview.

2488
03:08:26,600 --> 03:08:28,000
I'm pretty happy with that.

2489
03:08:28,280 --> 03:08:33,440
And so we need to connect Q&A service to our knowledge base.

2490
03:08:33,920 --> 03:08:37,160
And so back over here in Azure, actually I guess we do have to make one.

2491
03:08:37,160 --> 03:08:40,080
Now that I remember, we actually have to create a Q&A maker service.

2492
03:08:40,480 --> 03:08:43,120
So I'll go down here and put this under my cog services.

2493
03:08:43,400 --> 03:08:51,920
We'll say my Q and a Q and a service might complain about the name.

2494
03:08:52,320 --> 03:08:52,560
Yep.

2495
03:08:52,560 --> 03:08:54,000
So I'll just put some numbers here.

2496
03:08:55,040 --> 03:08:57,400
We will pick a free tier sounds good.

2497
03:08:57,400 --> 03:08:59,280
So I'll go free when I actually get the option.

2498
03:08:59,280 --> 03:09:00,320
That's what I will choose.

2499
03:09:01,040 --> 03:09:04,240
Down below, we'll choose free again, USE sounds great to me.

2500
03:09:04,880 --> 03:09:05,880
It generates out the name.

2501
03:09:05,880 --> 03:09:07,840
It's the same name as here, so that's fine.

2502
03:09:08,400 --> 03:09:17,760
We don't need App Insights, but I'm going to leave it enabled because I think it changes it to standard or S0 when you do not have it enabled unusually.

2503
03:09:18,760 --> 03:09:21,440
And so we will create our Q&A Maker service.

2504
03:09:21,920 --> 03:09:22,960
Give it a moment here.

2505
03:09:24,160 --> 03:09:29,960
And it says, I remember it will say like, even if you try, it might have to wait 10 minutes for it to create the service.

2506
03:09:29,960 --> 03:09:32,320
So even though, even after it's provisioned,

2507
03:09:32,960 --> 03:09:33,640
It'll take some time.

2508
03:09:33,640 --> 03:09:37,680
So what we should do is prepare our doc because it can take in a variety of different files.

2509
03:09:38,000 --> 03:09:43,120
And I just want to show you here that the Q&A, they have a whole paper here, formatting the guidelines.

2510
03:09:43,600 --> 03:09:48,120
And basically it's pretty smart about knowing where headings and answers is.

2511
03:09:48,120 --> 03:09:50,920
So for unstructured data, we just have a heading and we have some text.

2512
03:09:50,920 --> 03:09:52,960
So let's write some things in here that we can think of.

2513
03:09:53,200 --> 03:09:55,600
Since we're all about certification, we should write some stuff here.

2514
03:09:55,600 --> 03:09:58,720
So how many AWS certifications are there?

2515
03:10:00,880 --> 03:10:05,760
I believe right now there are 11 AWS certifications.

2516
03:10:06,800 --> 03:10:07,200
Okay.

2517
03:10:07,240 --> 03:10:12,400
And maybe if we use our headings here, this would probably be a good idea here.

2518
03:10:12,400 --> 03:10:12,520
Yeah.

2519
03:10:15,920 --> 03:10:16,160
Okay.

2520
03:10:18,160 --> 03:10:29,520
Another one could be how many fundamental Azure certifications are there?

2521
03:10:37,040 --> 03:10:38,800
And we'll give this a heading.

2522
03:10:38,800 --> 03:10:43,560
We'll say there are three Azure.

2523
03:10:43,560 --> 03:10:45,120
I think there's three.

2524
03:10:45,120 --> 03:10:46,240
There's other ones, right?

2525
03:10:46,240 --> 03:10:48,160
Like Power Platform and stuff.

2526
03:10:48,160 --> 03:10:55,280
But just being Azure specific, there are three Azure fundamental certifications.

2527
03:10:55,840 --> 03:10:56,560
Certifications.

2528
03:10:56,560 --> 03:11:01,600
So we have the DP900, the AI900,

2529
03:11:02,480 --> 03:11:05,600
The AZ-900, I guess there's four, there's the SC-900, right?

2530
03:11:05,600 --> 03:11:06,560
So there are four.

2531
03:11:08,400 --> 03:11:19,920
Okay, we'll say which is the hardest Azure Association Certification.

2532
03:11:31,600 --> 03:11:38,080
And what we'll say here is, I think, I mean, it's my opinion is it's the Azure administrator.

2533
03:11:38,640 --> 03:11:40,880
Had some background noise there, that's why I was a bit pausing there.

2534
03:11:40,880 --> 03:11:44,960
But the Azure administer AZ 104, I would say that's the hardest.

2535
03:11:45,640 --> 03:11:48,160
Which is harder?

2536
03:11:51,520 --> 03:11:55,040
The AWS or Azure certifications?

2537
03:11:59,280 --> 03:12:03,360
I'd say Azure certifications are harder.

2538
03:12:05,040 --> 03:12:19,440
Because they check exact steps for implementation, where AWS focuses on concepts.

2539
03:12:20,440 --> 03:12:23,440
Okay, so we have a bit of a knowledge base here.

2540
03:12:23,440 --> 03:12:24,160
So I'll save it.

2541
03:12:24,880 --> 03:12:28,240
And assuming that this is ready, because we need a little bit time to put this together.

2542
03:12:28,960 --> 03:12:30,480
We'll go back to Q&A.

2543
03:12:31,000 --> 03:12:32,480
You can hit a refresh here.

2544
03:12:33,840 --> 03:12:34,640
Give it a moment.

2545
03:12:35,720 --> 03:12:36,640
Drop it down.

2546
03:12:37,360 --> 03:12:38,480
Choose our service.

2547
03:12:43,840 --> 03:12:46,880
And notice here that we have chit-chat extraction and only extraction.

2548
03:12:46,880 --> 03:12:47,920
We're going to do chit-chat.

2549
03:12:48,720 --> 03:12:52,800
I will say my, or this will be the reference may be changing any time.

2550
03:12:52,800 --> 03:12:56,480
This will be like a certification Q&A.

2551
03:12:59,040 --> 03:13:00,240
And so here we want to populate.

2552
03:13:00,240 --> 03:13:01,680
So we'll go to files here.

2553
03:13:01,680 --> 03:13:03,280
I'm going to go to my desktop.

2554
03:13:05,160 --> 03:13:06,080
And here it is.

2555
03:13:06,080 --> 03:13:06,720
I'll open it.

2556
03:13:08,640 --> 03:13:10,240
We will choose professional tone.

2557
03:13:10,720 --> 03:13:11,600
Go ahead and create that.

2558
03:13:11,800 --> 03:13:13,120
And so I'll see you back here in a moment.

2559
03:13:13,920 --> 03:13:17,200
All right, so after waiting a short little time here, it loaded in our data.

2560
03:13:17,200 --> 03:13:20,720
So you can see that it figured out which is the question, which is the answer.

2561
03:13:21,000 --> 03:13:22,600
And it also has a bunch of defaults.

2562
03:13:22,600 --> 03:13:26,040
So here, if somebody was asked something very silly, like, can you cry?

2563
03:13:26,040 --> 03:13:27,360
I'll say, I don't have a body.

2564
03:13:27,720 --> 03:13:30,720
and has a lot of information preloaded for us, which is really nice.

2565
03:13:30,720 --> 03:13:38,160
If we want to go ahead and test this, we could go and say, we'll go here, and then we'll write in, say like, Hello.

2566
03:13:45,210 --> 03:13:46,090
Say boring.

2567
03:13:48,490 --> 03:13:49,250
This is good morning.

2568
03:13:49,450 --> 03:13:55,050
Okay, so we'll say, how many certifications are there?

2569
03:13:56,090 --> 03:13:58,250
We didn't say AWS, but let's just see what happens.

2570
03:14:04,280 --> 03:14:07,520
And so it kind of inferred, even though we didn't say AWS in particular.

2571
03:14:08,000 --> 03:14:10,160
So I noticed that there's AWS and Azure.

2572
03:14:10,160 --> 03:14:12,600
So how many fundamental Azure certifications, things like that.

2573
03:14:12,600 --> 03:14:14,200
And so it chose AWS.

2574
03:14:14,200 --> 03:14:17,280
So it's not like the perfect service, but it's pretty good.

2575
03:14:17,440 --> 03:14:22,880
I wonder what would happen if we placed in one that's like Azure.

2576
03:14:22,880 --> 03:14:24,320
I don't know how many Azure certs there are.

2577
03:14:24,320 --> 03:14:25,480
We'll just say like there's 11, 12.

2578
03:14:25,520 --> 03:14:26,240
I can never remember.

2579
03:14:26,240 --> 03:14:27,200
They're always adding more.

2580
03:14:27,760 --> 03:14:29,800
But I want to close this here.

2581
03:14:29,800 --> 03:14:30,240
There we go.

2582
03:14:30,560 --> 03:14:39,280
So let's just go add a new key pair here and we'll say how many Azure certifications are there?

2583
03:14:39,520 --> 03:14:41,040
I should have said certifications.

2584
03:14:41,040 --> 03:14:42,600
I'll probably just set one moment.

2585
03:14:42,600 --> 03:14:48,880
So there are 12 Azure certifications.

2586
03:14:49,520 --> 03:14:50,280
Who knows how many they have?

2587
03:14:50,280 --> 03:14:51,760
They could have like 14 or something.

2588
03:14:51,760 --> 03:14:54,560
We could say like between 11 and 14.

2589
03:14:56,560 --> 03:14:58,680
They just add, they just update them too frequently.

2590
03:14:58,680 --> 03:14:59,440
I can't keep track.

2591
03:14:59,920 --> 03:15:02,800
So we'll go here and we'll just say certifications.

2592
03:15:03,120 --> 03:15:04,800
And we will save and retrain.

2593
03:15:05,120 --> 03:15:06,640
So we'll just wait here a moment.

2594
03:15:11,680 --> 03:15:12,000
Great.

2595
03:15:12,000 --> 03:15:13,440
And so now we'll go ahead and test this again.

2596
03:15:13,440 --> 03:15:19,600
So we'll say how many certifications are there?

2597
03:15:24,520 --> 03:15:26,000
And see, it's pulling the first answer.

2598
03:15:26,000 --> 03:15:29,760
If I say Azure, let's see if it gets the right one here.

2599
03:15:32,240 --> 03:15:34,720
How many Azure certifications are there?

2600
03:15:38,480 --> 03:15:44,800
Okay, so, you know, maybe you'd have to say you'd have to have a generic one for that match.

2601
03:15:44,800 --> 03:15:52,560
So if we go back here and we say, how many certifications are there?

2602
03:15:53,600 --> 03:16:03,280
Say, you know, like which certification, which cloud service provider.

2603
03:16:06,880 --> 03:16:12,880
Okay, we got AWS, Azure, follow prompt.

2604
03:16:12,880 --> 03:16:17,200
You can use guides through conversational flow prompts are used to link Q&A pairs and can be displayed.

2605
03:16:18,240 --> 03:16:21,360
I haven't used this yet, but I mean, it sounds like something that's pretty good.

2606
03:16:22,120 --> 03:16:23,640
Because there is multi turn in this.

2607
03:16:23,640 --> 03:16:27,360
So the idea is that if you had to go through multiple steps, you could absolutely do that.

2608
03:16:28,160 --> 03:16:29,440
We could try this a little bit here.

2609
03:16:30,000 --> 03:16:36,800
Follow prompt you can use to guide use convert prompts are used to link q&a pairs together, texture button for suggested action.

2610
03:16:36,800 --> 03:16:37,360
Oh, okay.

2611
03:16:37,360 --> 03:16:40,080
So maybe we would just like AWS link to q&a.

2612
03:16:40,080 --> 03:16:43,120
And then so search an existing q&a or create a new one.

2613
03:16:44,000 --> 03:16:46,800
So it's a like, how many AWS?

2614
03:16:47,760 --> 03:16:49,040
Oh, okay, we're typing it in.

2615
03:16:50,960 --> 03:16:54,640
Context only this falls up will not be understood out of the context flow.

2616
03:16:55,360 --> 03:16:55,840
Sure.

2617
03:16:56,840 --> 03:16:58,400
Because it should be within context, right?

2618
03:16:59,520 --> 03:17:04,000
And here we can do another one we say like, Azure.

2619
03:17:06,280 --> 03:17:13,520
We'll say how many Azure context only?

2620
03:17:14,240 --> 03:17:17,360
Oops, that got away from me there.

2621
03:17:23,280 --> 03:17:24,000
We'll save that.

2622
03:17:25,120 --> 03:17:27,360
And what we'll do is save and train.

2623
03:17:35,290 --> 03:17:41,570
So we'll go back here and we'll say, how many certifications are there?

2624
03:17:44,050 --> 03:17:44,530
Enter.

2625
03:17:45,810 --> 03:17:47,570
So we have to choose AWS.

2626
03:17:48,010 --> 03:17:48,610
And so there we go.

2627
03:17:48,610 --> 03:17:50,210
So we got something that works pretty good there.

2628
03:17:50,530 --> 03:17:52,930
Since I'm happy with it, we can go ahead and go and publish that.

2629
03:17:52,930 --> 03:17:53,970
So let's say publish.

2630
03:18:02,760 --> 03:18:06,560
And now that it's published, we could use Postman or Curl to trigger it.

2631
03:18:06,720 --> 03:18:12,840
But what I want to do is create a bot because with Azure Bot Services, then we can actually utilize it with other integrations, right?

2632
03:18:12,840 --> 03:18:17,400
It's a great way to use your bot or to actually host your bot.

2633
03:18:17,400 --> 03:18:18,320
So we'll go over here.

2634
03:18:18,640 --> 03:18:19,680
It'll link it over.

2635
03:18:19,880 --> 03:18:21,600
If you don't click it, it doesn't preload it in.

2636
03:18:21,600 --> 03:18:22,320
So it's kind of a pain.

2637
03:18:22,320 --> 03:18:24,080
If you lose it, you have to go back there and click it again.

2638
03:18:24,080 --> 03:18:28,640
But let's just say certification Q&A.

2639
03:18:30,920 --> 03:18:32,400
And we will look through here.

2640
03:18:32,400 --> 03:18:40,800
So I'm gonna go with free premium messages, 10k 1k premium message units, messages, I'm kind of confused by the pricing, but f zero usually means free.

2641
03:18:40,800 --> 03:18:47,280
So that's what I'm gonna go for that SDK or node js, I'm gonna use node js, not that we're going to do anything there with it, go ahead and create that.

2642
03:18:49,440 --> 03:18:51,680
And I don't think this takes too long.

2643
03:18:52,240 --> 03:18:52,960
We'll see here.

2644
03:19:00,590 --> 03:19:02,110
Just go ahead and click on that there.

2645
03:19:03,840 --> 03:19:04,600
I'll just wait here a bit.

2646
03:19:04,600 --> 03:19:05,600
I'll see you back here in a moment.

2647
03:19:06,080 --> 03:19:11,160
All right, so after waiting, I don't know, about 5 minutes there, it looks like our bot service is deployed.

2648
03:19:11,160 --> 03:19:13,120
We'll go to that resource there.

2649
03:19:13,840 --> 03:19:15,760
You can download the bot source code.

2650
03:19:15,760 --> 03:19:21,600
Actually, I never did this, so I don't know what it looks like, so I'd be curious to see this, just to see what the code is.

2651
03:19:21,600 --> 03:19:27,440
I assume that because we chose Node.js, it would give us that as the default there.

2652
03:19:27,440 --> 03:19:29,520
So download your source code as you bot creating the source zip.

2653
03:19:30,480 --> 03:19:31,520
Not sure how long this takes.

2654
03:19:33,280 --> 03:19:40,800
Might be regretting clicking on that, but what we'll do is we'll go on the left-hand side here to channels, because I just want to show here.

2655
03:19:40,800 --> 03:19:43,080
Yeah, I don't, it didn't download.

2656
03:19:44,240 --> 03:19:48,000
We'll try it here in a second, but what we'll do is we'll go back.

2657
03:19:48,000 --> 03:19:49,040
Oop, bot profile.

2658
03:19:51,360 --> 03:19:52,440
Unspecified bot.

2659
03:19:52,440 --> 03:19:53,200
What are you talking about?

2660
03:19:55,680 --> 03:19:57,520
Yeah, maybe it needs some time.

2661
03:20:04,640 --> 03:20:07,520
So, maybe we'll just give the bot a little bit of time here.

2662
03:20:07,520 --> 03:20:10,760
I'm not sure why it's giving us a hard time because this bot is definitely deployed.

2663
03:20:10,760 --> 03:20:12,640
If we go over to our bots, right?

2664
03:20:13,440 --> 03:20:15,840
Bot services, it is here.

2665
03:20:16,320 --> 03:20:19,520
Sometimes there's like latency, you know, with

2666
03:20:20,720 --> 03:20:21,200
Azure.

2667
03:20:21,520 --> 03:20:22,000
Oh, there we go.

2668
03:20:22,000 --> 03:20:23,200
Okay, see, it works now fine, right.

2669
03:20:23,200 --> 03:20:25,240
And so I want to show you that there's different channels.

2670
03:20:25,240 --> 03:20:28,240
And these are just easy ways to integrate your bot in different services.

2671
03:20:28,240 --> 03:20:38,000
So whether you wanted to use it with Alexa, group me, Skype, telephony, Twilio, Skype, business, apparently, they don't have that anymore.

2672
03:20:38,320 --> 03:20:39,840
Because they got salt teams now, right?

2673
03:20:40,160 --> 03:20:46,160
Keek, which I don't know, people still use that slack, which is that discord, telegram, Facebook e-mail.

2674
03:20:47,120 --> 03:20:47,920
That's kind of cool.

2675
03:20:48,560 --> 03:20:50,160
But Teams, Teams is a really good one.

2676
03:20:50,160 --> 03:20:50,880
I use Teams.

2677
03:20:51,120 --> 03:20:52,280
There's a direct line channel.

2678
03:20:52,280 --> 03:20:53,000
I don't know what that means.

2679
03:20:53,000 --> 03:20:56,240
And there's web chat, which is just having like an embed code.

2680
03:20:56,240 --> 03:20:58,960
So if we go over, we can go and test it over here.

2681
03:20:59,520 --> 03:21:00,800
Just start testing our web chat.

2682
03:21:00,800 --> 03:21:07,840
And so it's the same thing as before, but we could just say things like, how many certifications are there?

2683
03:21:12,160 --> 03:21:14,320
Azure and get a clear answer back.

2684
03:21:15,920 --> 03:21:17,520
we'll go back up to our overview.

2685
03:21:17,560 --> 03:21:19,640
Let's try to see if we can download that code.

2686
03:21:19,640 --> 03:21:22,240
Again, I was kind of curious what that looks like.

2687
03:21:27,770 --> 03:21:39,740
If it will download must be a lot of code.

2688
03:21:44,460 --> 03:21:45,100
There we go.

2689
03:21:45,100 --> 03:21:46,220
So now we can hit download.

2690
03:21:46,500 --> 03:21:49,100
And so there is the code, I'm going to go ahead and open that up.

2691
03:21:49,980 --> 03:21:53,180
So yeah, I guess when we chose JavaScript, that made a lot more sense.

2692
03:21:53,640 --> 03:21:59,200
let's give it a little peek here, I'm just going to drop this on my desktop here.

2693
03:22:00,320 --> 03:22:04,320
So let's make a new folder here and call this bot code.

2694
03:22:05,640 --> 03:22:07,440
Okay, I know you can't see what I'm doing here.

2695
03:22:07,440 --> 03:22:13,840
But let's go here and dread, double click into here and then just drag that code on in.

2696
03:22:18,800 --> 03:22:21,680
And then what we can do is open this up in VS Code.

2697
03:22:21,680 --> 03:22:24,160
I should have VS Code running somewhere around here.

2698
03:22:24,160 --> 03:22:25,920
I'm just going to go ahead and open that.

2699
03:22:26,720 --> 03:22:27,440
I'm off screen here.

2700
03:22:27,440 --> 03:22:29,360
I'll just show you my screen in a moment.

2701
03:22:30,080 --> 03:22:31,920
Say show code, oops.

2702
03:22:33,280 --> 03:22:37,840
File, open folder, bot code, okay.

2703
03:22:39,520 --> 03:22:41,160
And we'll come all the way back here.

2704
03:22:41,160 --> 03:22:42,400
And so we've got a lot of code here.

2705
03:22:42,560 --> 03:22:47,920
Never looked at this before, but you know, I'm a pretty good programmer, so it's not too hard for me to understand.

2706
03:22:50,480 --> 03:22:52,800
So looks like you got an API request, things like that.

2707
03:22:52,880 --> 03:22:57,440
I guess it would just be like if you needed to integrate into your application, then it kind of shows you all the code there.

2708
03:22:58,320 --> 03:23:00,400
I'm just trying to see our dialogue choices.

2709
03:23:01,920 --> 03:23:03,840
Nothing super exciting.

2710
03:23:06,480 --> 03:23:06,960
Okay.

2711
03:23:08,080 --> 03:23:18,640
when I go and make the, was it the AI or the AI 100, whatever the data scientist course is, I'm sure I'll be a lot more thorough here, but I was just curious as to what that looks like.

2712
03:23:18,960 --> 03:23:23,720
Now, if we wanted to have an easy integration, we can get an embed code for this.

2713
03:23:23,720 --> 03:23:31,600
So if we go back to our channels, I believe we can go and edit.

2714
03:23:32,840 --> 03:23:33,080
Ah, yes.

2715
03:23:33,080 --> 03:23:34,280
So here we have a code.

2716
03:23:34,280 --> 03:23:40,400
So what I'll do is go back to Jupyter Labs, I'm just going to go make a new empty notebook.

2717
03:23:40,400 --> 03:23:42,320
So let's just go up here and say notebook.

2718
03:23:43,800 --> 03:23:45,200
And this can be for our q&a.

2719
03:23:46,320 --> 03:23:47,600
Doesn't really matter what kernel.

2720
03:23:49,040 --> 03:23:51,440
Let's say Q and a maker.

2721
03:23:52,320 --> 03:23:58,680
Just show like if you wanted a very, very simple way of integrating your bot, we would go back over to

2722
03:24:01,240 --> 03:24:04,960
wherever it is here, here we are, I'm gonna go ahead and copy this iframe.

2723
03:24:05,920 --> 03:24:08,640
I think it's percentage percentage HTML.

2724
03:24:09,200 --> 03:24:11,600
So it treats this cell as HTML.

2725
03:24:12,480 --> 03:24:14,480
And I don't have any HTML to render.

2726
03:24:14,480 --> 03:24:16,440
So we will place that in there.

2727
03:24:16,440 --> 03:24:18,480
And notice we have to replace our secret key.

2728
03:24:18,960 --> 03:24:22,480
So I will go back here and I will show my key and we will copy that.

2729
03:24:24,400 --> 03:24:26,200
And we'll paste that key in here.

2730
03:24:26,200 --> 03:24:28,400
And then we'll run this.

2731
03:24:30,080 --> 03:24:31,360
I can type in here.

2732
03:24:33,400 --> 03:24:35,920
Where am I silly things?

2733
03:24:40,640 --> 03:24:41,200
Who are you?

2734
03:24:43,840 --> 03:24:45,840
How many Azure certifications?

2735
03:24:46,880 --> 03:24:47,360
Are there?

2736
03:24:47,920 --> 03:24:49,520
Well, I wonder if I just leave the are there off?

2737
03:24:49,520 --> 03:24:50,880
Let's see if it's figures it out.

2738
03:24:50,880 --> 03:24:51,440
Okay, cool.

2739
03:24:51,520 --> 03:24:55,840
So yeah, I mean, that's pretty much it with q&a maker.

2740
03:24:57,120 --> 03:24:58,720
So yeah, that's great.

2741
03:24:58,720 --> 03:25:07,840
So I think we're done here and we can move on to checking out LUIS or LUIS learning understanding to make a more robust bot.

2742
03:25:07,840 --> 03:25:08,160
Okay.

2743
03:25:13,760 --> 03:25:21,120
All right, so we are on to our last cognitive service, and this one is going to be LUIS or Luis, depending on how you like to say it.

2744
03:25:21,120 --> 03:25:23,600
It's L-U-I-S, which is Language Understanding.

2745
03:25:23,840 --> 03:25:29,760
So you type in L-U-I-S.ai, and that's going to bring us up to this external website.

2746
03:25:29,760 --> 03:25:33,040
It's still part of Azure, it just has its own domain.

2747
03:25:33,440 --> 03:25:40,720
And so here we'll choose our subscription, and we have no authoring source, so I guess we'll have to go ahead and create one ourselves.

2748
03:25:41,160 --> 03:26:02,800
We'll go down here and we'll choose my cognitive services Azure resource name, so my auth service or my cognitive service create new cognitive service account, but we already have one, so I don't want to make another one, right?

2749
03:26:02,800 --> 03:26:04,000
It should show up here, right?

2750
03:26:06,480 --> 03:26:08,720
are valid in the authoring region.

2751
03:26:08,720 --> 03:26:11,760
So it's possible that we're just in the incorrect region.

2752
03:26:11,760 --> 03:26:13,360
So we might end up creating two of these.

2753
03:26:13,560 --> 03:26:14,640
And that's totally fine.

2754
03:26:14,640 --> 03:26:15,280
I don't care.

2755
03:26:15,560 --> 03:26:18,800
As long as we get this work in here, because we're going to delete everything at the end anyway.

2756
03:26:18,800 --> 03:26:22,000
And so I'll just say my cog service 2.

2757
03:26:23,640 --> 03:26:28,560
And we'll say West US, because I think that maybe we didn't choose one of these regions.

2758
03:26:28,560 --> 03:26:29,760
Let's go double check.

2759
03:26:30,360 --> 03:26:32,000
If we go back to our portal.

2760
03:26:33,840 --> 03:26:35,760
just the limitations of the service, right?

2761
03:26:35,760 --> 03:26:38,720
So we'll go to my cog services here.

2762
03:26:39,120 --> 03:26:42,960
I just want to go cognitive services.

2763
03:26:44,160 --> 03:26:46,080
So I just want to see where this is deployed.

2764
03:26:46,560 --> 03:26:50,400
And this is in West US.

2765
03:26:51,200 --> 03:26:53,360
Yes, I don't know why it's not showing up there, but whatever.

2766
03:26:54,080 --> 03:26:56,160
If that's what it wants, we'll give it what it wants, okay?

2767
03:26:59,440 --> 03:27:01,920
Shouldn't give us that much trouble, but hey, that's how it goes.

2768
03:27:04,240 --> 03:27:06,720
And so we have an authoring service.

2769
03:27:06,720 --> 03:27:08,960
I'm going to refresh here and see if it added a second one.

2770
03:27:08,960 --> 03:27:09,920
It didn't.

2771
03:27:10,000 --> 03:27:10,800
So all right.

2772
03:27:12,240 --> 03:27:12,720
That's fine.

2773
03:27:12,720 --> 03:27:15,600
So we'll just say my sample bot.

2774
03:27:17,360 --> 03:27:18,960
We'll use English as our culture.

2775
03:27:19,040 --> 03:27:21,040
If nothing shows up here, don't worry.

2776
03:27:21,200 --> 03:27:22,440
You can choose it later on.

2777
03:27:22,440 --> 03:27:24,160
I remember the first time I did this, it didn't show up.

2778
03:27:24,600 --> 03:27:27,440
And so now we have my cog service, my custom vision service.

2779
03:27:27,440 --> 03:27:28,720
We want cog service.

2780
03:27:29,600 --> 03:27:30,080
So

2781
03:27:32,880 --> 03:27:40,000
Anyway, it tells you about schema, like how you make a schema that animates talking about like bot action, intent, and example utterance.

2782
03:27:40,000 --> 03:27:41,800
But we're just going to set up something very simple here.

2783
03:27:41,800 --> 03:27:43,320
So we're going to create our intent.

2784
03:27:43,320 --> 03:27:47,120
The one that we always see is a flight booking.

2785
03:27:47,680 --> 03:27:48,960
So I'll go here and do that.

2786
03:27:50,640 --> 03:27:57,040
And what we want to do is write an under and so like book me a flight to Toronto.

2787
03:27:58,160 --> 03:27:58,640
Okay.

2788
03:27:59,720 --> 03:28:07,920
And so if someone were to type that in, then the idea is it would return back the intent, this value and metadata around it, and we could pragmatically provide code, right?

2789
03:28:07,920 --> 03:28:13,200
So what we need is identities, and we can actually just click here and make one here.

2790
03:28:13,200 --> 03:28:16,560
So enter a name, identity, and we'll just call this location.

2791
03:28:17,680 --> 03:28:17,800
Okay.

2792
03:28:17,800 --> 03:28:21,680
Here we have option machine learned and list if you flip between it.

2793
03:28:22,000 --> 03:28:26,320
This is like, imagine you have a ticket order and you have these values that can change.

2794
03:28:26,880 --> 03:28:29,440
Or you just have a value that always stays the same, like list.

2795
03:28:29,440 --> 03:28:30,640
So that's our airport.

2796
03:28:31,600 --> 03:28:32,320
That makes sense.

2797
03:28:32,320 --> 03:28:32,960
We'll do that.

2798
03:28:35,440 --> 03:28:37,680
If we go over to entities, we can see it here.

2799
03:28:40,080 --> 03:28:40,560
All right.

2800
03:28:40,560 --> 03:28:42,480
So nothing super exciting there.

2801
03:28:42,480 --> 03:28:49,600
But what I want to show you is if we go ahead and we should probably add flight booking.

2802
03:28:50,400 --> 03:28:52,800
Should be, how about book flight?

2803
03:28:55,000 --> 03:28:55,840
Flight booking.

2804
03:28:56,480 --> 03:28:57,120
Flight booking.

2805
03:28:57,120 --> 03:29:00,080
Okay, so we'll go ahead, and I know there's only one, but we'll go ahead and train our model.

2806
03:29:05,440 --> 03:29:08,080
Because we don't need to know tons, right?

2807
03:29:08,080 --> 03:29:09,760
We cover a lot in the lecture content.

2808
03:29:10,000 --> 03:29:14,000
To build a complex bot is more for the associate level.

2809
03:29:14,560 --> 03:29:20,960
But now what we can do is go ahead and test this, and we'll say, book me a flight to Seattle.

2810
03:29:23,440 --> 03:29:25,440
Okay, and notice here it says book flight.

2811
03:29:25,440 --> 03:29:28,160
We can go inspect it, and we get some additional data.

2812
03:29:28,560 --> 03:29:31,600
So top scoring, so it says how likely that was the intent.

2813
03:29:34,680 --> 03:29:36,560
Okay, so you get kind of an idea there.

2814
03:29:36,880 --> 03:29:38,280
There's additional things here.

2815
03:29:38,280 --> 03:29:39,280
It doesn't really matter.

2816
03:29:39,920 --> 03:29:42,960
We'll go back here and we will go ahead and publish our model.

2817
03:29:43,840 --> 03:29:45,880
So we can put it into a production slot.

2818
03:29:45,880 --> 03:29:48,160
You can see we have sentiment analysis, speech priming.

2819
03:29:48,160 --> 03:29:49,760
We don't care about either of those things.

2820
03:29:50,920 --> 03:29:52,960
We can go and see where our endpoint is.

2821
03:29:53,560 --> 03:29:56,720
And so now we have an endpoint that we can work with.

2822
03:29:57,840 --> 03:29:59,840
So, I mean, that's pretty much all you...

2823
03:30:00,160 --> 03:30:01,760
really need to learn about LUIS.

2824
03:30:02,560 --> 03:30:05,120
But I think we're all done for cognitive services.

2825
03:30:05,120 --> 03:30:11,440
So we're going to keep around our notebook because we're going to still use our Jupyter notebook for some other things.

2826
03:30:11,440 --> 03:30:18,240
But what I want you to do is make your way over to your resource groups.

2827
03:30:18,560 --> 03:30:20,880
Because if you've been pretty clean, it's all within here.

2828
03:30:20,880 --> 03:30:21,680
We'll just take a look here.

2829
03:30:21,680 --> 03:30:25,080
So we have our Q&A, all of our stuff here.

2830
03:30:25,080 --> 03:30:26,280
I'm just making sure it's all there.

2831
03:30:26,280 --> 03:30:28,000
And so I'm just going to go ahead and

2832
03:30:28,400 --> 03:30:34,720
delete this resource group, and that should wipe away everything, okay, for the cognitive services part.

2833
03:30:37,120 --> 03:30:52,880
All right, so we're all good here, and I'm just going to go off, and I'll leave this open because it's always a pain to get back to it and reopen it, but let's make our way back to the home here in the Azure Machine Learning Studio, and now we can actually explore building out machine learning pipelines.

2834
03:30:58,320 --> 03:31:02,640
Okay, so we are on to the ML follow alongs here.

2835
03:31:02,640 --> 03:31:04,320
So we're going to learn how to build some pipelines.

2836
03:31:04,320 --> 03:31:09,040
So first I think is the easiest would be auto automated ML or also known as auto ML.

2837
03:31:09,360 --> 03:31:13,080
The idea here is it's going to just build out the entire pipeline for us.

2838
03:31:13,080 --> 03:31:14,240
So we don't have to do any thinking.

2839
03:31:14,240 --> 03:31:18,960
We just say what kind of model we want to run and have it to make a prediction.

2840
03:31:18,960 --> 03:31:22,560
So what we'll do is say new automated ML and we're going to need a data set.

2841
03:31:22,560 --> 03:31:25,840
So I don't have one, but the nicest thing is they have these open data sets.

2842
03:31:26,160 --> 03:31:27,120
So if you click here,

2843
03:31:28,000 --> 03:31:29,440
You'll see there is a bunch here.

2844
03:31:29,760 --> 03:31:35,280
And a lot of these you'll come across quite often, not just on Azure, but other places like this diabetes one.

2845
03:31:35,520 --> 03:31:37,280
I've seen it like everywhere.

2846
03:31:37,280 --> 03:31:37,920
Okay.

2847
03:31:38,720 --> 03:31:41,760
And so if we just go click here, maybe we can read a bit more here.

2848
03:31:41,760 --> 03:31:48,080
So diabetes data set, 422 samples with 10 features, ideal for getting started with machine learning algorithms.

2849
03:31:48,080 --> 03:31:51,200
It's one of the popular scikit-learn toy data sets.

2850
03:31:51,280 --> 03:31:54,320
It's probably where I've seen it before, though it's not showing up there.

2851
03:31:54,880 --> 03:31:57,040
You scroll on down, you can see the data.

2852
03:31:57,600 --> 03:32:00,880
You notice that it's available in Azure Notebooks, Databricks, and Azure Synapse.

2853
03:32:01,600 --> 03:32:07,560
The thing is, we have these values, so age, sex, BMI, BP, and then Y is trying to make a prediction.

2854
03:32:07,560 --> 03:32:13,880
It's trying to say what's the likelihood of you having diabetes or not, and so it's not a Boolean value, so it's not a binary classifier.

2855
03:32:13,880 --> 03:32:16,160
It's kind of on a, well, I guess you...

2856
03:32:16,720 --> 03:32:20,800
would you be doing binary classification to say, do you have diabetes?

2857
03:32:20,800 --> 03:32:26,320
Or you can make a prediction to say, what's the likelihood or this value if you gave another value in there.

2858
03:32:26,720 --> 03:32:30,320
But anyway, this is the predicting value.

2859
03:32:30,320 --> 03:32:36,000
A lot of times this is X, so everything here is X, and this is considered Y, the actual prediction.

2860
03:32:36,720 --> 03:32:41,840
So sometimes it's Y, and sometimes it's actually named what it is, but that's just what it is here.

2861
03:32:41,840 --> 03:32:42,880
So we'll close that off.

2862
03:32:43,200 --> 03:32:45,200
And so we'll choose the diabetes set.

2863
03:32:45,920 --> 03:32:48,240
And it will be data set one.

2864
03:32:49,360 --> 03:32:52,000
And so we'll worry about feedback later.

2865
03:32:52,000 --> 03:32:53,840
So we'll click on sample diabetes.

2866
03:32:53,840 --> 03:32:54,560
We'll hit next.

2867
03:32:54,840 --> 03:32:58,720
And here it's going to try to figure out what kind of model that we want.

2868
03:32:58,720 --> 03:32:59,840
We have to create a new experiment.

2869
03:32:59,840 --> 03:33:01,520
It's a container to run the model in.

2870
03:33:01,520 --> 03:33:03,360
So we'll just say diabetes.

2871
03:33:05,080 --> 03:33:05,880
It's my diabetes.

2872
03:33:05,880 --> 03:33:07,360
It sounds a bit odd, but that's what it is.

2873
03:33:07,360 --> 03:33:12,640
The target column we want to predict is seeing the train to predict is the Y.

2874
03:33:12,720 --> 03:33:13,840
It's usually the Y.

2875
03:33:14,960 --> 03:33:18,480
We don't have a compute cluster, so I'll go ahead and create a new compute.

2876
03:33:19,360 --> 03:33:21,120
We have dedicated or low priority.

2877
03:33:21,600 --> 03:33:26,400
Technically, it is low priority, but I just want this done.

2878
03:33:26,400 --> 03:33:28,560
Low priority cheaper, but don't get it to your compute nodes.

2879
03:33:29,520 --> 03:33:30,960
Your job may be preemptied.

2880
03:33:31,920 --> 03:33:33,480
I'm going to stick with dedicated for the time being.

2881
03:33:33,480 --> 03:33:34,800
We're going to stick with CPU.

2882
03:33:35,920 --> 03:33:39,120
If we go with this,

2883
03:33:39,840 --> 03:33:42,000
It does take about an hour to run.

2884
03:33:42,000 --> 03:33:43,840
So I ran this took about an hour.

2885
03:33:43,840 --> 03:33:46,480
So if you don't mind, it's only going to cost you 15 cents.

2886
03:33:46,880 --> 03:33:51,680
But if you want this done a lot sooner, I'm going to try to do something a little bit more powerful.

2887
03:33:52,400 --> 03:33:59,760
So I'm just trying to decide here, because if it only takes an hour, I might run it on something more powerful.

2888
03:33:59,760 --> 03:34:00,880
That's 90 cents.

2889
03:34:01,360 --> 03:34:04,080
That might be overkill, because it's not really deep learning.

2890
03:34:05,160 --> 03:34:07,680
It's just statistical stuff.

2891
03:34:07,680 --> 03:34:08,240
So

2892
03:34:08,760 --> 03:34:10,000
Train large data set.

2893
03:34:10,000 --> 03:34:13,920
I wouldn't say it's large, real time inference, other latency sensitive ones.

2894
03:34:19,120 --> 03:34:20,480
How about...

2895
03:34:24,240 --> 03:34:25,280
Why is this one?

2896
03:34:25,360 --> 03:34:27,040
I'm just looking here because this one's 29 cents.

2897
03:34:27,040 --> 03:34:28,240
This one's more expensive.

2898
03:34:28,800 --> 03:34:30,640
But it has 32 gigabytes of RAM.

2899
03:34:30,640 --> 03:34:31,760
This one's 28.

2900
03:34:31,920 --> 03:34:33,120
Oh, 14 gigabytes of RAM.

2901
03:34:33,200 --> 03:34:34,000
Oh, it's storage.

2902
03:34:34,000 --> 03:34:34,400
So

2903
03:34:34,960 --> 03:34:36,640
This one's our highest in the tier.

2904
03:34:36,720 --> 03:34:40,160
Again, you can choose this one, you just have to wait a lot longer.

2905
03:34:40,160 --> 03:34:44,080
I just want to see if it finishes a lot faster, okay, without having to go to the GPU level.

2906
03:34:44,640 --> 03:34:46,720
So I don't think GPU is going to help too much here.

2907
03:34:47,320 --> 03:34:50,080
The computer name is my diabetes machine.

2908
03:34:55,800 --> 03:35:02,640
Minimum number nodes, you want to provision if you want dedicated nodes to set the count here, maximum,

2909
03:35:03,680 --> 03:35:05,440
I guess I just want one node, right?

2910
03:35:06,960 --> 03:35:11,600
We will go ahead and oops, complete name must be to 16 characters long.

2911
03:35:15,800 --> 03:35:17,040
What doesn't is it too long?

2912
03:35:17,360 --> 03:35:18,240
Okay, there we go.

2913
03:35:25,350 --> 03:35:26,310
We'll give it a moment here.

2914
03:35:29,750 --> 03:35:31,110
Yeah, it's going to spin up the cluster.

2915
03:35:31,110 --> 03:35:32,870
So it does take a little bit time to start this.

2916
03:35:32,870 --> 03:35:34,550
So I'll see you back here when this is done.

2917
03:35:34,550 --> 03:35:34,870
Okay.

2918
03:35:36,160 --> 03:35:39,800
Great, so after a short little wait there, it looks like our cluster is running.

2919
03:35:39,800 --> 03:35:41,760
If we double check here, we can go to compute.

2920
03:35:41,760 --> 03:35:45,440
I believe that it shows up under here under the compute cluster.

2921
03:35:45,440 --> 03:35:46,400
So there it is.

2922
03:35:46,640 --> 03:35:47,600
Notice it's slightly different.

2923
03:35:47,600 --> 03:35:50,800
This one shows you applications, and this one is just size and et cetera.

2924
03:35:50,800 --> 03:35:53,280
We can click in here, see nodes and runtimes.

2925
03:35:53,600 --> 03:35:55,200
We'll go make our way back here.

2926
03:35:56,000 --> 03:35:57,600
And we'll go ahead and hit next.

2927
03:35:57,920 --> 03:36:05,520
And notice that I think it actually will select what it generally, because it'll look at your prediction value, maybe sample a bit of it and say, okay, you probably want a regression thing.

2928
03:36:05,520 --> 03:36:07,600
So to predict a continuous numeric values.

2929
03:36:08,160 --> 03:36:19,280
So the thing is that if it was a label like text or if it was just zero and one, it probably would choose classification because it's, you saw our Y value is like a number that was all over the place.

2930
03:36:19,600 --> 03:36:20,640
It thinks it's regression.

2931
03:36:20,640 --> 03:36:23,840
So I think that's a good indicator there.

2932
03:36:23,840 --> 03:36:25,120
So let's go with regression.

2933
03:36:28,880 --> 03:36:32,720
but you might want it as a binary classifier, but it's another story there.

2934
03:36:33,200 --> 03:36:35,720
So it's, as soon as we created it, just started.

2935
03:36:35,720 --> 03:36:38,640
It didn't give us the option to say, hey, I want to start running it.

2936
03:36:39,120 --> 03:36:41,440
Notice on this here, it's going to do featurization.

2937
03:36:41,440 --> 03:36:44,720
So that means it's automatically going to select out features for us, which is what we wanted to do.

2938
03:36:45,040 --> 03:36:46,400
It's set up to do regression.

2939
03:36:46,640 --> 03:36:47,920
We have some configuration here.

2940
03:36:47,920 --> 03:36:49,840
So training time is 3 hours.

2941
03:36:50,000 --> 03:36:53,520
Doesn't mean it's going to train for three hours, but that's, I guess, it's timeout for it.

2942
03:36:54,800 --> 03:36:57,120
You could set a metric score threshold.

2943
03:36:57,120 --> 03:36:59,680
So it has to meet at least this to be successful.

2944
03:36:59,680 --> 03:37:01,920
If it's not going to do it, it probably would quit out early.

2945
03:37:02,480 --> 03:37:04,320
Cross number or cross validations.

2946
03:37:04,320 --> 03:37:05,640
Just make sure the data is good.

2947
03:37:05,640 --> 03:37:06,960
You can see blocked algorithms.

2948
03:37:06,960 --> 03:37:09,720
So TensorFlow DNN, TensorFlow linear regression.

2949
03:37:09,720 --> 03:37:15,280
If it was using DNN, so deep learning neural network, I probably would have chosen the GPU to see if it would go faster.

2950
03:37:16,360 --> 03:37:17,280
Look at the primary metric.

2951
03:37:17,280 --> 03:37:19,520
It's normalized root square.

2952
03:37:20,560 --> 03:37:25,280
square error, sometimes on the exam, they'll actually ask you like, what's the prime metric for this thing?

2953
03:37:25,280 --> 03:37:28,800
So it's good to take a look and see what they actually use for that.

2954
03:37:28,960 --> 03:37:33,120
I'll probably be sure to highlight that stuff in the actual lecture content.

2955
03:37:34,080 --> 03:37:35,920
But this will take some time to run.

2956
03:37:36,880 --> 03:37:40,320
We have data guardrails, it will actually not populate, I guess, until we've ran it.

2957
03:37:40,320 --> 03:37:41,760
So we'll just let it run.

2958
03:37:41,760 --> 03:37:43,240
And I'll see you back here when it's done.

2959
03:37:43,240 --> 03:37:43,600
Okay.

2960
03:37:44,320 --> 03:37:48,000
All right, so after a very, very, very long wait, our AutoML job is done.

2961
03:37:48,000 --> 03:37:52,480
It took 60 minutes, so using a larger instance didn't save me any time.

2962
03:37:52,720 --> 03:37:56,080
I don't know, maybe if I ran a GPU instance, it would be a lot faster.

2963
03:37:56,080 --> 03:38:01,360
I'd be very curious to try that out, but not something for this certification course.

2964
03:38:01,680 --> 03:38:04,800
So we go into here, and the cheaper instance was the same amount of time.

2965
03:38:04,800 --> 03:38:06,400
So it probably just needs GPUs.

2966
03:38:06,400 --> 03:38:08,760
It really depends on the type of models it's running.

2967
03:38:08,760 --> 03:38:10,560
So we have a bunch of different algorithms in here.

2968
03:38:10,800 --> 03:38:14,000
It ran about 42 different models.

2969
03:38:14,240 --> 03:38:19,960
I thought last time I ran it, I saw a lot more, but you can see there's all kinds of models that it's running.

2970
03:38:19,960 --> 03:38:21,920
And then it's going to choose the top candidate.

2971
03:38:21,920 --> 03:38:24,160
So it chose voting Ensemble.

2972
03:38:24,160 --> 03:38:25,600
So Ensemble is

2973
03:38:27,120 --> 03:38:30,080
don't cover really in the course, because it's gets too much into ml.

2974
03:38:30,080 --> 03:38:39,640
But ensemble is when you actually use two different weaker models and combine the results in order to make a more powerful ml model.

2975
03:38:39,640 --> 03:38:40,000
Okay.

2976
03:38:40,880 --> 03:38:43,120
So here, we'll get some explanation.

2977
03:38:43,280 --> 03:38:46,160
I tried this before, and I didn't get really good information.

2978
03:38:46,640 --> 03:38:47,680
So if we go here,

2979
03:38:49,600 --> 03:38:51,560
So like I don't have anything under model performance.

2980
03:38:51,560 --> 03:38:55,920
So this tab requires array of predicted values from the model to be supplied.

2981
03:38:56,160 --> 03:38:59,120
We didn't supply any, so we don't get any data explorer.

2982
03:38:59,120 --> 03:39:03,520
So select a cohort of the data that all the data is with those we have here.

2983
03:39:04,640 --> 03:39:06,560
So like here, we're seeing age.

2984
03:39:07,560 --> 03:39:11,600
And I guess it's just giving us an indicator about the age information.

2985
03:39:12,560 --> 03:39:15,640
Use the slider to show descending feature importance.

2986
03:39:15,640 --> 03:39:19,040
Select up to three cohorts to see the feature importance slide by side.

2987
03:39:20,200 --> 03:39:20,400
OK.

2988
03:39:23,200 --> 03:39:25,800
So I guess S5 and BMI.

2989
03:39:25,840 --> 03:39:26,960
I don't know what S5 is.

2990
03:39:26,960 --> 03:39:28,520
We'd have to look up the data set.

2991
03:39:28,520 --> 03:39:30,360
BMI is your body mass index.

2992
03:39:30,360 --> 03:39:34,880
So that's a clear indicator as to what affects whether you have diabetes or not.

2993
03:39:34,880 --> 03:39:35,760
So that makes sense.

2994
03:39:35,760 --> 03:39:38,800
Age doesn't seem to be a huge factor, which is kind of interesting.

2995
03:39:40,320 --> 03:39:45,760
Individual feature importance, we can go here and just kind of like narrow in and say, okay, well, why is this outlier over here?

2996
03:39:45,760 --> 03:39:47,840
And they're like age 79, right?

2997
03:39:47,840 --> 03:39:50,880
So it's kind of interesting to see that information.

2998
03:39:50,880 --> 03:39:56,960
So it does give you some explanation as to, you know, why things are, why they are.

2999
03:39:58,480 --> 03:40:00,800
Over here, we have a little bit more different data.

3000
03:40:00,800 --> 03:40:02,880
This is kind of interesting model performance.

3001
03:40:04,000 --> 03:40:06,720
I don't know what I'm looking at, but like here, it's over mean squared.

3002
03:40:06,720 --> 03:40:09,440
So it's that mean squared calculation there again.

3003
03:40:12,960 --> 03:40:13,160
Okay.

3004
03:40:19,450 --> 03:40:20,730
So yeah, it's something right.

3005
03:40:21,450 --> 03:40:24,690
But anyway, the point is, is that, you know, that we finally get metrics.

3006
03:40:24,690 --> 03:40:28,170
So I guess we always had to click there, because that makes more sense.

3007
03:40:29,450 --> 03:40:30,970
So yeah, there's more values here.

3008
03:40:31,530 --> 03:40:31,850
Sure.

3009
03:40:32,970 --> 03:40:34,330
Data transformation.

3010
03:40:35,680 --> 03:40:40,160
So it's the data processing, feature engineering, scaling techniques, the machine learning algorithm, AutoML.

3011
03:40:40,160 --> 03:40:43,840
So, you know, if you were a real data scientist, all this stuff would make sense to you.

3012
03:40:44,720 --> 03:40:46,880
I think just with time, it'll make sense.

3013
03:40:46,880 --> 03:40:48,880
But even at this point, I'm not sure.

3014
03:40:49,040 --> 03:40:50,400
And I don't care about the model, right?

3015
03:40:50,400 --> 03:40:55,440
If you're building something for real, I'm sure the information becomes a lot more valuable.

3016
03:40:55,680 --> 03:40:58,000
So this model is done.

3017
03:40:58,320 --> 03:41:04,800
And the idea is that we can deploy, oops, if we go back to the actual models,

3018
03:41:05,680 --> 03:41:07,200
because we actually went into the name.

3019
03:41:07,200 --> 03:41:11,200
So we go back to the AutoML here.

3020
03:41:12,560 --> 03:41:15,120
I think you can deploy any model that you like.

3021
03:41:15,920 --> 03:41:17,360
So then you go here and deploy this.

3022
03:41:17,360 --> 03:41:19,600
Like if you prefer a different model, you could deploy it.

3023
03:41:20,960 --> 03:41:23,200
If we go into data guardrails, we kind of skipped over that.

3024
03:41:23,200 --> 03:41:26,400
This is a way it does automatic featurization.

3025
03:41:26,400 --> 03:41:27,680
So it's extracting out the feature.

3026
03:41:27,680 --> 03:41:29,680
So how it handles the splitting.

3027
03:41:30,520 --> 03:41:34,440
how it handles missing features, high cardinality.

3028
03:41:34,440 --> 03:41:39,520
It's like if you have too much data, it might have to do dimensionality reduction.

3029
03:41:40,000 --> 03:41:47,520
So that's just saying like, hey, if this is a problem, maybe we would do some pre-processing or stuff to make it easier to work with the data.

3030
03:41:48,160 --> 03:41:50,240
So if we're happy with this, we can go ahead and deploy it.

3031
03:41:51,280 --> 03:41:57,440
So let's say deploy, just say infer my diabetes.

3032
03:41:59,280 --> 03:42:09,280
we have AKS and each Azure container instance, let's do Azure Kubernetes, Kubernetes services, because we did the other one here.

3033
03:42:10,080 --> 03:42:19,120
Say, diabetes, prod, maybe AKS diabetes.

3034
03:42:22,960 --> 03:42:24,240
Oh, compute name, sorry.

3035
03:42:27,000 --> 03:42:28,320
One of the inference ones.

3036
03:42:28,320 --> 03:42:32,960
Okay, so in order to deploy this, we would have to create our pipeline.

3037
03:42:33,280 --> 03:42:36,640
I'm not sure if I have enough in my quota here, but let's go give it a go.

3038
03:42:37,120 --> 03:42:39,120
So I think what it's wanting is one of these here.

3039
03:42:42,160 --> 03:42:45,200
I think we'd want this wherever we are, right?

3040
03:42:46,280 --> 03:42:53,280
I'm not sure where we are, if this is US East or West here.

3041
03:42:53,680 --> 03:42:56,560
Let's go check Studio.

3042
03:43:00,240 --> 03:43:06,480
Azure Machine Learning East US.

3043
03:43:08,960 --> 03:43:14,960
No, I never did this when I was, I just use usually Azure Container Instance, but I'm just curious here.

3044
03:43:16,400 --> 03:43:17,200
Say next.

3045
03:43:18,800 --> 03:43:23,600
My diabetes prod.

3046
03:43:25,760 --> 03:43:29,440
We will need to choose some nodes.

3047
03:43:32,880 --> 03:43:37,120
The number of nodes multiplied by the virtual machine's number of cores must be greater or equal to 12.

3048
03:43:37,120 --> 03:43:37,520
Okay.

3049
03:43:39,920 --> 03:43:43,840
Now, again, if you're not confident, like if you're concerned about cost, you can just, again, watch.

3050
03:43:43,840 --> 03:43:45,120
You don't have to do, right?

3051
03:43:46,240 --> 03:43:49,480
This is, again, a fundamental certification.

3052
03:43:49,480 --> 03:43:53,040
It's not super important to get all the hands-on experience yourself.

3053
03:43:54,160 --> 03:43:56,720
But I'm just trying to explore this so we can see, right?

3054
03:43:56,720 --> 03:43:58,240
Because I don't care about cost.

3055
03:43:58,240 --> 03:44:00,880
It's not a big deal to me on my machine here.

3056
03:44:01,200 --> 03:44:02,960
So probably I don't have...

3057
03:44:06,240 --> 03:44:10,520
Simple must use a VM SKU with more than two cores and four gigabytes.

3058
03:44:10,520 --> 03:44:11,600
Well, what did I choose?

3059
03:44:12,720 --> 03:44:13,920
Did I not choose the right one?

3060
03:44:17,520 --> 03:44:18,480
We'll try this again.

3061
03:44:22,720 --> 03:44:23,920
Oh, I chose three.

3062
03:44:25,040 --> 03:44:25,840
Yeah, that's fair.

3063
03:44:34,310 --> 03:44:35,030
What did it want?

3064
03:44:35,030 --> 03:44:37,070
12 cores set before, I think.

3065
03:44:41,950 --> 03:44:44,670
Invalid parameters, more details.

3066
03:44:47,710 --> 03:44:50,350
Because it already exists based on that name, eh, too?

3067
03:44:51,910 --> 03:44:53,470
It's giving us all this trouble, A.

3068
03:44:54,400 --> 03:44:57,280
This one will go ahead and delete you think like it wouldn't matter.

3069
03:44:57,280 --> 03:44:58,560
Like I wouldn't have to delete it out.

3070
03:44:58,560 --> 03:44:59,440
But that's fine.

3071
03:45:02,000 --> 03:45:02,840
This one failed.

3072
03:45:02,840 --> 03:45:03,680
Now what's the problem?

3073
03:45:05,600 --> 03:45:06,400
Quote exceeded.

3074
03:45:06,400 --> 03:45:10,160
So I can't do it because I don't, I'd have to go make a support request, increase it.

3075
03:45:10,560 --> 03:45:12,400
So it's not a real big deal.

3076
03:45:13,120 --> 03:45:22,800
I guess what we could do is instead of doing it on AKS, we just deployed to container instance, if it'll let us notice, I don't have to fill anything additional and it'll just

3077
03:45:23,480 --> 03:45:24,320
Deploy, I think.

3078
03:45:27,680 --> 03:45:28,000
Great.

3079
03:45:29,160 --> 03:45:32,840
And so I guess we'll let that deploy, and I'll see you back here in a bit, okay?

3080
03:45:33,920 --> 03:45:38,840
All right, so I'm back here checking out on my-- or checking up on my AutoML here.

3081
03:45:38,840 --> 03:45:42,160
So if we go over to compute, we go to inference clusters.

3082
03:45:42,160 --> 03:45:43,680
We don't have anything under there.

3083
03:45:43,680 --> 03:45:49,680
If we go over to our experiments, under our diabetes here,

3084
03:45:51,640 --> 03:45:54,480
Because we did choose to deploy the model.

3085
03:45:57,360 --> 03:45:58,880
Right, we clicked deploy.

3086
03:46:04,510 --> 03:46:07,950
So it should have created an ACI instance, let's make our way over to the portal.

3087
03:46:08,350 --> 03:46:12,030
The reason why it might not be showing up is because I'm just running out of compute.

3088
03:46:12,350 --> 03:46:14,270
Because again, it's a quota thing.

3089
03:46:15,630 --> 03:46:17,430
It's not a big deal for us to get a deploy.

3090
03:46:17,430 --> 03:46:18,710
It's not like we're gonna do anything with it.

3091
03:46:18,710 --> 03:46:23,550
But yeah, so we can see that we have a container over here, and it's running.

3092
03:46:24,320 --> 03:46:28,400
So we must be able to see if we go to endpoints here.

3093
03:46:28,960 --> 03:46:29,760
Ah, here it is, right.

3094
03:46:29,760 --> 03:46:30,720
I was under models.

3095
03:46:30,720 --> 03:46:31,360
That's my problem.

3096
03:46:32,000 --> 03:46:37,920
So pipeline endpoints, that would be something I think that if we had deployed our designer, I thought we would have saw it under there.

3097
03:46:37,920 --> 03:46:41,760
But here we have our binary pipeline or our diabetes prod pipeline.

3098
03:46:41,760 --> 03:46:45,760
So if we wanted to like test data, you know, we could pass stuff in here.

3099
03:46:46,880 --> 03:46:50,080
I think if we wanted to kind of just like see this in action,

3100
03:46:50,720 --> 03:46:52,560
I'm not sure if it's going to work, but we'll give it a go.

3101
03:46:52,560 --> 03:47:01,040
So if we go into our sample diabetes data set, and we just explore some of the data, we should be able to kind of select out some values, because I don't know what these values mean.

3102
03:47:01,040 --> 03:47:03,520
So let's just say like 36.

3103
03:47:04,560 --> 03:47:05,920
Oops, 36.

3104
03:47:05,920 --> 03:47:08,560
But we already know that BMI is the major factor here.

3105
03:47:09,280 --> 03:47:11,520
Sex is either one or two, so we'll say two.

3106
03:47:12,240 --> 03:47:15,280
BMI, we'll say 25.3.

3107
03:47:15,920 --> 03:47:18,000
The BP will be 83.

3108
03:47:19,200 --> 03:47:22,240
or whatever, oops, 83 here.

3109
03:47:26,080 --> 03:47:27,560
S1, 160.

3110
03:47:32,800 --> 03:47:35,920
S2 can be 99.6.

3111
03:47:39,200 --> 03:47:47,200
S3, 40, 5, 40, 5, and 5.1.

3112
03:47:49,120 --> 03:47:50,880
Oh, we're running out of metrics here.

3113
03:47:52,080 --> 03:47:52,640
82.

3114
03:47:54,520 --> 03:47:55,760
What do I doesn't give us all of them?

3115
03:47:57,040 --> 03:47:57,760
Oh, I guess it does.

3116
03:47:57,760 --> 03:47:58,560
It's up to six.

3117
03:47:59,760 --> 03:48:01,800
Okay, so let's go ahead and test that, see what we get.

3118
03:48:01,800 --> 03:48:02,720
And we got a result back.

3119
03:48:02,720 --> 03:48:03,360
168.

3120
03:48:03,360 --> 03:48:07,480
So that is AutoML all complete there for you.

3121
03:48:09,200 --> 03:48:10,080
Yeah, so there you go.

3122
03:48:15,360 --> 03:48:29,480
All right, so let's take a look here at the visual designer because it's a great way to get started very easily with, if you don't know what you're doing and you want something a little bit more advanced than AutoML and have some customization, it's great to start with one of these samples.

3123
03:48:29,480 --> 03:48:31,760
Let's go ahead and expand it and see what we have here.

3124
03:48:32,000 --> 03:48:41,920
We have binary classification with custom Python script, tune parameters for binary classification, multi-class classification, so letter recognition,

3125
03:48:42,320 --> 03:48:44,440
text classification, all sorts of things.

3126
03:48:44,440 --> 03:48:47,600
Usually binary classification is pretty easy.

3127
03:48:47,880 --> 03:48:50,000
I'm looking for one that is pretty darn simple.

3128
03:48:50,560 --> 03:48:51,520
Let's go take a look here.

3129
03:48:51,520 --> 03:48:56,000
So this says, the sample shows how to filter base feature selection to selection features.

3130
03:48:57,520 --> 03:49:06,000
Binary classification, so how do predictors related to custom relationships using binary classes, how to handle imbalanced datasets using SMOTE and modules.

3131
03:49:06,000 --> 03:49:10,560
I'm not really worried about balancing customized Python script to perform cost-sensitive

3132
03:49:11,120 --> 03:49:14,000
binary classification, tune parameters.

3133
03:49:14,000 --> 03:49:18,240
So tune model parameters, best models during the training process.

3134
03:49:18,240 --> 03:49:19,120
Let's go with this one.

3135
03:49:19,120 --> 03:49:20,240
This one seems okay to me.

3136
03:49:21,600 --> 03:49:25,520
And so what you can see here is that it's using a sample data set, I believe.

3137
03:49:25,520 --> 03:49:26,640
I think this is a sample.

3138
03:49:27,120 --> 03:49:31,760
And if you wanted to see all of them, you could literally drag them out here and do things with them.

3139
03:49:32,240 --> 03:49:36,720
I haven't actually built one end-to-end yet for this.

3140
03:49:36,720 --> 03:49:40,480
Again, I don't think it's like super important for this level of exam.

3141
03:49:40,960 --> 03:49:43,200
But this just shows you that there's a pre-built one.

3142
03:49:43,200 --> 03:49:46,320
If you start to get the handle of ML, you know the full pipeline.

3143
03:49:46,560 --> 03:49:47,760
This isn't too confusing.

3144
03:49:47,760 --> 03:49:51,240
So at the beginning here, we have our classification data.

3145
03:49:51,240 --> 03:49:54,640
And then what it's going to do is say select columns in the data set.

3146
03:49:55,200 --> 03:50:00,000
So it says exclude column names, work class, occupation, native country.

3147
03:50:00,000 --> 03:50:02,960
So it's doing some pre-processing there, excluding that data.

3148
03:50:02,960 --> 03:50:05,360
It might be interesting to go look at that data set.

3149
03:50:05,360 --> 03:50:10,160
So if we go over to our data sets tab, it should show up here, I believe.

3150
03:50:11,680 --> 03:50:18,560
Maybe because we haven't committed or submitted this, we can't see that data set yet, but we'll look at it for a moment.

3151
03:50:18,960 --> 03:50:20,320
Then we want to clean our data.

3152
03:50:20,320 --> 03:50:22,600
So here it's saying clean all the columns.

3153
03:50:22,600 --> 03:50:26,080
So custom substitution value.

3154
03:50:27,360 --> 03:50:29,680
See if we can see what it's substituting out.

3155
03:50:34,720 --> 03:50:35,680
It's not saying what.

3156
03:50:35,680 --> 03:50:37,040
So clean missing data.

3157
03:50:39,720 --> 03:50:41,440
So I'm not sure what it's clinging out there, but...

3158
03:50:45,400 --> 03:50:48,160
Because I would suggest that it's using some kind of custom script.

3159
03:50:48,440 --> 03:50:50,320
I'm not sure where it is, but that's okay.

3160
03:50:50,560 --> 03:50:51,440
We have split data.

3161
03:50:51,440 --> 03:50:55,360
Pretty common to split your data, so you would have a training and test data set.

3162
03:50:56,000 --> 03:51:01,200
It's usually really good to randomize it, so you want to randomize it, then split it.

3163
03:51:01,200 --> 03:51:03,200
And that's just so you get better results.

3164
03:51:03,600 --> 03:51:04,160
Then it has...

3165
03:51:04,880 --> 03:51:06,720
model hyperparameter tuning.

3166
03:51:06,720 --> 03:51:12,480
So the idea is that it's going to use ML to figure out the best parameters for tuning.

3167
03:51:12,800 --> 03:51:16,480
Over here we have the two class decision tree where it's going to do some work there.

3168
03:51:16,720 --> 03:51:20,800
It's going to score our model and then it's going to evaluate our model and see if it's successful.

3169
03:51:20,800 --> 03:51:22,720
So this is all set up to go.

3170
03:51:22,720 --> 03:51:24,280
So all we got to do is go to the top here.

3171
03:51:24,280 --> 03:51:25,440
This is setting wheel here.

3172
03:51:25,760 --> 03:51:27,440
And we need to choose some type of compute.

3173
03:51:27,440 --> 03:51:34,760
So I'm going to go here and we have this one here, but I'm going to go create this for my diabetes one, but I'm going to go ahead and make a new

3174
03:51:34,880 --> 03:51:35,120
one.

3175
03:51:35,120 --> 03:51:43,040
And we're going to say we recommend using a predefined configuration to quickly set compute training.

3176
03:51:43,440 --> 03:51:49,760
This one looks okay, I don't know if it needs two nodes.

3177
03:51:49,760 --> 03:51:51,840
But I guess we can do this one.

3178
03:51:51,840 --> 03:51:53,600
So let's just say binary.

3179
03:51:53,960 --> 03:51:55,360
Let's just like binary pipeline.

3180
03:51:57,080 --> 03:51:57,240
Okay.

3181
03:51:59,760 --> 03:52:00,400
Say save.

3182
03:52:01,600 --> 03:52:04,560
Hopefully, it's making a good suggestion, and we'll have to wait for that to spin up.

3183
03:52:04,560 --> 03:52:05,840
It's going to take a little bit of time.

3184
03:52:05,840 --> 03:52:07,960
Okay, so I'll see you back here in a moment.

3185
03:52:08,480 --> 03:52:11,360
All right, so I got a little message saying that is ready.

3186
03:52:11,360 --> 03:52:14,320
So, what we can do, I think it was here, my notebook instance.

3187
03:52:14,320 --> 03:52:17,360
No, that's not it, but I definitely saw a pop-up on my screen.

3188
03:52:18,320 --> 03:52:19,200
You might have saw it too.

3189
03:52:19,200 --> 03:52:22,000
You'd have to be paying close attention for that, but if you go over...

3190
03:52:23,200 --> 03:52:25,200
It says that it's ready to go.

3191
03:52:25,200 --> 03:52:27,680
So what I'm going to do is make my way back over here.

3192
03:52:27,920 --> 03:52:29,280
We're going to select our compute.

3193
03:52:29,600 --> 03:52:31,160
There is our binary pipeline.

3194
03:52:31,160 --> 03:52:32,400
I'm going to select that.

3195
03:52:32,880 --> 03:52:34,560
And there are some other options.

3196
03:52:34,560 --> 03:52:35,680
We're not going to fiddle around with that.

3197
03:52:35,680 --> 03:52:37,120
We're going to go ahead and hit submit.

3198
03:52:37,440 --> 03:52:39,280
So we need a new experiment.

3199
03:52:39,280 --> 03:52:41,680
So I'm going to just say binary pipeline.

3200
03:52:43,040 --> 03:52:43,920
We'll hit submit.

3201
03:52:49,980 --> 03:52:50,380
Okay.

3202
03:52:50,380 --> 03:52:51,740
And so this is now running.

3203
03:52:51,740 --> 03:52:55,020
So after a little while here, we're going to start seeing these go green.

3204
03:52:55,020 --> 03:52:56,300
So this is not started.

3205
03:52:56,680 --> 03:53:00,000
We'll give it a moment here just so we can see some kind of animation.

3206
03:53:00,440 --> 03:53:01,120
And there it goes.

3207
03:53:01,120 --> 03:53:02,160
It's off to the races.

3208
03:53:02,320 --> 03:53:03,680
There's not much to do here.

3209
03:53:03,680 --> 03:53:04,800
This is going to take a while.

3210
03:53:04,800 --> 03:53:05,360
I don't know.

3211
03:53:05,440 --> 03:53:09,600
I have never ran this one in particular, so I don't know if it's an hour or 30 minutes.

3212
03:53:09,920 --> 03:53:11,840
So I'll see you back when it's done running.

3213
03:53:12,400 --> 03:53:14,480
But yeah, it's not that fun to watch.

3214
03:53:14,880 --> 03:53:17,520
But it's cool that you get a visual illustration.

3215
03:53:17,600 --> 03:53:18,560
So I'll see you back in a bit.

3216
03:53:19,440 --> 03:53:22,520
I just wanted to peek in here and take a look at how it's progressing here.

3217
03:53:22,520 --> 03:53:25,480
And you can see it's still going and it's just cleaning the data.

3218
03:53:25,480 --> 03:53:26,320
It's still not done.

3219
03:53:27,160 --> 03:53:28,960
I'm not sure how long this has been running for.

3220
03:53:28,960 --> 03:53:36,000
If we go over to our experiments and we go into our, I think it's binary pipeline and we look at the runtime, we're about 8 minutes in.

3221
03:53:36,560 --> 03:53:38,160
And it hasn't done a whole lot.

3222
03:53:38,160 --> 03:53:39,840
So it's still cleaning the data.

3223
03:53:39,840 --> 03:53:41,920
I would have thought it'd be a little bit faster.

3224
03:53:42,160 --> 03:53:47,600
I'm kind of used to using like AWS and it goes SageMaker's, this doesn't usually take this long.

3225
03:53:48,320 --> 03:53:50,880
But I mean, it's nice that it's going here.

3226
03:53:50,880 --> 03:53:54,080
But yeah, so we're almost out of the pre-processing phase.

3227
03:53:54,480 --> 03:53:57,840
We'll be on to the model tuning, okay?

3228
03:53:57,840 --> 03:54:03,360
All right, so after waiting a little while, it looks like our pipeline is done.

3229
03:54:03,520 --> 03:54:09,040
So if we make our way over to experiments and go to binary pipeline, we can see that it took 14 minutes and 22 seconds.

3230
03:54:09,040 --> 03:54:13,800
We can go here and just see some additional information.

3231
03:54:13,800 --> 03:54:14,960
There's nothing really else to see.

3232
03:54:14,960 --> 03:54:18,000
We saw all the steps already ran, so you can see them all here.

3233
03:54:19,040 --> 03:54:23,040
Okay, and so let's say we wanted to, there's nothing under metrics, but

3234
03:54:24,480 --> 03:54:29,040
Enable metrics, log data points, compare these within across runs, really did a single run.

3235
03:54:29,040 --> 03:54:30,480
So there's nothing to compare.

3236
03:54:30,800 --> 03:54:32,280
So let's say we're happy with this.

3237
03:54:32,280 --> 03:54:33,840
And we want to deploy this model.

3238
03:54:33,840 --> 03:54:37,520
Well, what I'm going to do is go back to the designer, click back here.

3239
03:54:37,920 --> 03:54:42,480
And so now in the top right corner, we can create our inference pipeline.

3240
03:54:42,480 --> 03:54:48,000
So I can't remember if submits going to run it, I don't want to run it again.

3241
03:54:49,280 --> 03:54:54,960
I just want to go ahead and create ourselves a real time or batch pipeline, let's say real time by pipeline here.

3242
03:54:56,240 --> 03:54:59,440
And what this will do is it'll actually create a completely different pipeline.

3243
03:54:59,440 --> 03:55:01,280
So here's a completely new one.

3244
03:55:01,920 --> 03:55:05,480
But it's specifically designed to do deployment.

3245
03:55:05,480 --> 03:55:08,200
Okay, so this is now one was for training the model.

3246
03:55:08,200 --> 03:55:12,880
And this one is actually for taking in data and doing inference.

3247
03:55:12,880 --> 03:55:13,360
Okay.

3248
03:55:13,840 --> 03:55:18,960
So what we can do is we can go ahead and just submit this.

3249
03:55:19,280 --> 03:55:24,320
And so we'll put this under our binary pipeline here, we'll go ahead and hit submit.

3250
03:55:26,880 --> 03:55:29,440
And I believe that we need a different kind of compute here.

3251
03:55:29,480 --> 03:55:30,960
I'm surprised that it's even running.

3252
03:55:32,240 --> 03:55:34,160
No, I guess it has a compute there.

3253
03:55:34,480 --> 03:55:35,360
So it's going to run.

3254
03:55:35,360 --> 03:55:42,080
And once it finishes running, then I believe that we can go ahead and deploy it.

3255
03:55:42,080 --> 03:55:44,000
Okay, so let's just wait for that to finish.

3256
03:55:44,000 --> 03:55:44,320
All right.

3257
03:55:45,440 --> 03:55:53,360
All right, so after a little while there, we've ran our inference pipeline, and so it's definitely something that is ready for use.

3258
03:55:53,360 --> 03:56:01,440
The idea is that what we actually use is it's going to go through this web service input to this web service output, but not so important at this level of certification.

3259
03:56:01,920 --> 03:56:04,000
Let's see what it looks like to go ahead and deploy it.

3260
03:56:04,000 --> 03:56:09,040
So, yep, we have the option between a real-time endpoint and an existing endpoint.

3261
03:56:10,000 --> 03:56:13,200
We don't have an endpoint yet, so we'll just say binary pipeline.

3262
03:56:15,120 --> 03:56:21,440
Okay, and notice we have the option between Oh, it does it wants it lowercase binary pipeline.

3263
03:56:22,640 --> 03:56:26,720
And we have the option between Azure Kubernetes service and Azure container instance.

3264
03:56:27,440 --> 03:56:30,120
It's a lot easier to deploy, I think to container instance.

3265
03:56:30,120 --> 03:56:33,120
So because we'll be waiting forever for Kubernetes to start up.

3266
03:56:33,120 --> 03:56:37,440
So we're going to do container instance, we have some options like SSL and things like that.

3267
03:56:37,760 --> 03:56:38,720
Not too worried about it.

3268
03:56:38,720 --> 03:56:40,400
So we're just going to go ahead and hit deploy.

3269
03:56:42,240 --> 03:56:42,640
Okay.

3270
03:56:44,120 --> 03:56:47,680
And so that is going to go ahead and deploy that.

3271
03:56:48,640 --> 03:56:51,200
So we'll wait for this real-time inference.

3272
03:56:51,200 --> 03:56:55,680
If we go over to our compute, it should spin up.

3273
03:56:56,400 --> 03:56:58,680
So this is for AKS.

3274
03:56:58,680 --> 03:57:00,240
So I don't know if it will show up here.

3275
03:57:00,240 --> 03:57:08,080
I think only I've seen things under here, but I think this will be for Azure Kubernetes Service, and I don't think we're going to see it show up under there.

3276
03:57:08,720 --> 03:57:09,680
However,

3277
03:57:10,240 --> 03:57:12,400
We do not need to be running this anymore.

3278
03:57:12,400 --> 03:57:18,920
So we'll go ahead and delete the binary pipeline because we're not, we don't have it for any use right now.

3279
03:57:18,920 --> 03:57:22,320
And we might need to free it up for something else.

3280
03:57:22,640 --> 03:57:22,960
Okay.

3281
03:57:24,160 --> 03:57:25,920
So go ahead and delete it, we don't need it.

3282
03:57:27,120 --> 03:57:30,240
And coming back to our pipeline.

3283
03:57:31,720 --> 03:57:34,720
Our designer here, I'm just trying to see where we can keep track of it.

3284
03:57:38,720 --> 03:57:40,160
Well, I know it's deploying.

3285
03:57:40,160 --> 03:57:41,960
So waiting for real time endpoint.

3286
03:57:41,960 --> 03:57:43,680
So I'll see you back here when this is done.

3287
03:57:43,680 --> 03:57:45,120
Okay, just takes a little bit time.

3288
03:57:45,600 --> 03:57:47,720
Alright, so I think our pipeline is done.

3289
03:57:47,720 --> 03:57:50,800
If we make our way over to endpoints, there it is the binary pipeline.

3290
03:57:50,800 --> 03:57:52,960
If we wanted to go ahead there, we could test the data.

3291
03:57:55,360 --> 03:57:58,160
And so it actually already has some pre loaded data for us.

3292
03:57:58,560 --> 03:58:02,160
If we hit test, it's nice that it fills it in.

3293
03:58:04,000 --> 03:58:05,120
we get some results back.

3294
03:58:05,120 --> 03:58:05,440
Okay.

3295
03:58:05,440 --> 03:58:10,800
So I mean, and then we see like scored labels and income and score probability.

3296
03:58:10,800 --> 03:58:13,760
So things like that, that is useful.

3297
03:58:14,080 --> 03:58:17,280
So it's getting back all the results, but I don't think it has.

3298
03:58:17,760 --> 03:58:22,480
Yeah, it doesn't have scored labels and scored probabilities, which is the value we want to come back here.

3299
03:58:22,480 --> 03:58:28,640
So there are endpoints and that is the end of our exploration with designer.

3300
03:58:28,640 --> 03:58:28,880
Okay.

3301
03:58:34,160 --> 03:58:39,440
All right, so let's take a look at what it would be to actually train a job programmatically through the notebook.

3302
03:58:39,440 --> 03:58:48,400
So remember we saw these samples over here, and so we saw this image classification, MNIST, and this is a very popular data set for doing computer vision.

3303
03:58:48,720 --> 03:58:49,360
These are really great.

3304
03:58:49,360 --> 03:58:56,080
If you want to really learn, you should really go through these and just read through them, because they're probably very, very useful.

3305
03:58:56,800 --> 03:58:57,920
I've done a lot of this before.

3306
03:58:57,920 --> 03:59:00,160
So for me, it's just it's not too hard to figure out.

3307
03:59:00,160 --> 03:59:01,440
But I've actually never ran this one.

3308
03:59:01,440 --> 03:59:02,720
So let's run it together.

3309
03:59:02,720 --> 03:59:05,360
Again, we want to be in JupyterLab.

3310
03:59:05,360 --> 03:59:08,400
So you can go here and click it there or go to the compute.

3311
03:59:08,800 --> 03:59:12,400
If it's been a bit finicky, and here, we'll get a tab open here.

3312
03:59:13,240 --> 03:59:14,640
And we'll see how this goes.

3313
03:59:14,640 --> 03:59:19,680
So what I want to do is just make sure we're back here, I'm gonna click into this one.

3314
03:59:21,040 --> 03:59:21,680
And

3315
03:59:22,480 --> 03:59:27,360
We have a few, so there's part one, and then we have the deploy stage.

3316
03:59:27,360 --> 03:59:28,560
So let's look at training.

3317
03:59:28,880 --> 03:59:31,680
I don't know if we really need to deploy, but we'll give it a read here.

3318
03:59:31,680 --> 03:59:36,160
So in this tutorial, you train an ML model on our compute resources.

3319
03:59:36,160 --> 03:59:42,080
You'll be training and deployment workflow via the Azure Machine Learning Service in a notebook.

3320
03:59:42,080 --> 03:59:43,200
There's 2 parts to this.

3321
03:59:43,600 --> 03:59:49,440
This is using the MNIST dataset and Scikit-learn and with Azure Machine Learning, probably the SDK.

3322
03:59:49,440 --> 03:59:52,560
It's a popular dataset with 70,000 grayscale images.

3323
03:59:52,720 --> 03:59:58,400
Each image is handwritten digits of 28 times by 28 times pixels, representing numbers from zero to 9.

3324
03:59:58,400 --> 03:59:59,920
The goal is to create multi-class.

3325
04:00:00,040 --> 04:00:03,880
classifier to define the digits in a given image that represents.

3326
04:00:03,880 --> 04:00:06,560
So we're going to learn a few things here, but let's just jump into it.

3327
04:00:07,760 --> 04:00:10,560
So the first thing is that we need to import our packages.

3328
04:00:10,880 --> 04:00:17,040
So here it does that matplotlib inlines, just make sure that when we print things that we visually see them.

3329
04:00:17,320 --> 04:00:22,000
We're going to need NumPy and then matplotlib itself, the Azure ML Core.

3330
04:00:22,520 --> 04:00:25,040
And then we're going to import a workspace since we'll need one there.

3331
04:00:25,520 --> 04:00:29,400
And then I guess it just checks the version, making sure if we have the right version here.

3332
04:00:29,400 --> 04:00:31,000
Okay, so this is 1.28.0.

3333
04:00:31,280 --> 04:00:36,800
It's pretty common, even this in AWS, they'll have like a script in here to update it in case it is out of date.

3334
04:00:37,320 --> 04:00:39,440
I'm surprised it didn't include it in here, but that's okay.

3335
04:00:39,920 --> 04:00:40,680
We'll scroll on down.

3336
04:00:40,680 --> 04:00:43,760
And by the way, we're using Python 3.6 Azure ML.

3337
04:00:44,480 --> 04:00:47,200
If this is the future, they might retire the old one.

3338
04:00:47,200 --> 04:00:51,440
You're using 3.8, but it should generally work if it's in their sample data set.

3339
04:00:51,440 --> 04:00:52,720
I assume they try to maintain that.

3340
04:00:52,720 --> 04:00:53,120
Okay.

3341
04:00:53,440 --> 04:00:54,520
So connect to a workspace.

3342
04:00:54,520 --> 04:00:59,920
So create a workspace object from an existing workspace, reads the file config.json.

3343
04:00:59,920 --> 04:01:01,520
So what we'll do is go run that.

3344
04:01:01,520 --> 04:01:02,800
I assume it's kind of like a session.

3345
04:01:03,520 --> 04:01:06,720
And so here it says it's found our workplace.

3346
04:01:08,000 --> 04:01:10,000
So really, it's just, it's not creating a workspace.

3347
04:01:10,000 --> 04:01:14,000
It's just returning the existing one so that we have it as a variable here.

3348
04:01:14,320 --> 04:01:15,240
Create an experiment.

3349
04:01:15,240 --> 04:01:16,840
So that's pretty clear.

3350
04:01:16,840 --> 04:01:19,120
We saw experiments in the AutoML and the designer.

3351
04:01:19,840 --> 04:01:21,440
So we'll just hit run there.

3352
04:01:23,120 --> 04:01:23,520
Okay.

3353
04:01:24,800 --> 04:01:27,760
So we named it CoreML and we said experiment.

3354
04:01:28,240 --> 04:01:29,600
I wonder if it actually created one yet.

3355
04:01:29,600 --> 04:01:31,360
Let's go over to experiment and see if it's there.

3356
04:01:32,160 --> 04:01:32,800
So it is there.

3357
04:01:32,800 --> 04:01:33,360
Cool.

3358
04:01:33,800 --> 04:01:34,320
That was fast.

3359
04:01:34,320 --> 04:01:36,640
I thought it would like print something out, but it didn't do anything there.

3360
04:01:37,760 --> 04:01:45,440
So create or attach an existing compute resource by using Azure Machine Compute, a managed service, data scientist, et cetera, et cetera, yada, yada, yada.

3361
04:01:45,440 --> 04:01:51,200
So create a compute, creation of a compute takes about 5 minutes.

3362
04:01:51,600 --> 04:01:53,600
So let's see what it's trying to create.

3363
04:01:53,600 --> 04:01:56,880
So we have some environment variables that it wants to load in.

3364
04:01:56,880 --> 04:01:58,960
I'm not sure how these are getting in here.

3365
04:02:00,160 --> 04:02:03,040
I'm not sure where environment variables are set in.

3366
04:02:04,880 --> 04:02:07,840
Jupyter or even how they get feeded in, but apparently they're somewhere.

3367
04:02:08,080 --> 04:02:10,640
But we have, it doesn't matter because these are defaulting.

3368
04:02:10,640 --> 04:02:14,360
So here's a CPU cluster, zero and four.

3369
04:02:14,360 --> 04:02:16,240
It's going to use a standard D2v2.

3370
04:02:16,240 --> 04:02:18,320
That is the cheapest one that we can run.

3371
04:02:19,200 --> 04:02:24,560
I kind of want something a little bit more powerful just for myself, just because I want this to be done a lot sooner.

3372
04:02:24,560 --> 04:02:28,400
But again, you know, if you don't have a lot of money, just stick with what's there, okay?

3373
04:02:28,880 --> 04:02:30,320
So, and this is...

3374
04:02:31,120 --> 04:02:32,320
CPU cluster.

3375
04:02:32,320 --> 04:02:35,120
So if we go here, I just want to see what our options are.

3376
04:02:40,560 --> 04:02:42,560
Not sure why it's not showing us options here.

3377
04:02:47,520 --> 04:02:49,920
You don't have enough quota for the following VM sizes.

3378
04:02:49,920 --> 04:02:53,200
So it probably it's because I'm running more than one VM right now.

3379
04:02:56,000 --> 04:02:57,840
Yes, I've hit my quota.

3380
04:02:58,880 --> 04:03:01,840
Okay, so I probably would have to request for an hour.

3381
04:03:02,480 --> 04:03:07,200
So I think this is the one I'm using.

3382
04:03:09,200 --> 04:03:10,040
What's the difference here?

3383
04:03:10,040 --> 04:03:12,800
This standard DV2 vCPUs.

3384
04:03:12,800 --> 04:03:16,640
It's the same one, right?

3385
04:03:17,120 --> 04:03:18,800
So request quota increase.

3386
04:03:18,880 --> 04:03:20,240
I don't know if this is instant or not.

3387
04:03:20,320 --> 04:03:21,600
I'd have to make a support ticket.

3388
04:03:21,760 --> 04:03:23,120
Oh, that's going to take too long.

3389
04:03:23,360 --> 04:03:35,440
So the thing is that because the reason is that I'm running the AutoML and the design and the designer in the background here trying to create all the workshops or the follow alongs at the same time.

3390
04:03:35,440 --> 04:03:41,600
But what I'll do is I'll just come back and when I'm not running one of those other ones, then I will I'll come back here and continue on.

3391
04:03:41,600 --> 04:03:43,520
But we're just here at the step.

3392
04:03:43,920 --> 04:03:46,560
We want to create a new compute, okay?

3393
04:03:47,200 --> 04:03:50,560
All right, so I'm back, and I freed up one of my compute instances.

3394
04:03:50,560 --> 04:03:56,480
If I go over here, now I just have the one cluster instance for my AutoML.

3395
04:03:56,640 --> 04:03:58,680
But what we'll do here is, again, just read through this.

3396
04:03:58,680 --> 04:04:03,360
So this will create a CPU cluster, 0 to 4 nodes, standard G to V2.

3397
04:04:03,360 --> 04:04:05,120
I guess we'll just stick with what is here.

3398
04:04:06,640 --> 04:04:07,960
Just reading through here.

3399
04:04:07,960 --> 04:04:10,640
It looks like it tries to find the compute target.

3400
04:04:10,640 --> 04:04:11,920
It's going to provision it.

3401
04:04:12,480 --> 04:04:17,760
It will create the cluster, call pool for minimum numbers of nodes for specific times, so wait for completion.

3402
04:04:17,760 --> 04:04:20,400
So we'll go ahead and hit play.

3403
04:04:21,120 --> 04:04:24,240
And so that's going to go and create us a new cluster.

3404
04:04:24,240 --> 04:04:28,880
So we're just going to have to wait a little while here for it to create about 5 minutes, and I'll see you back here in a moment.

3405
04:04:29,600 --> 04:04:31,680
All right, so the cluster started up.

3406
04:04:31,680 --> 04:04:33,920
If we go back over here, we can see that it's confirmed.

3407
04:04:33,920 --> 04:04:37,440
I don't know why it was so quick, but it went pretty quick there.

3408
04:04:37,760 --> 04:04:39,040
So we're on the next section here.

3409
04:04:39,040 --> 04:04:39,760
Explore the data.

3410
04:04:39,760 --> 04:04:43,120
So download the MNIST data set, display some sample images.

3411
04:04:43,440 --> 04:04:46,160
So it's just talking about it being the open data set.

3412
04:04:46,400 --> 04:04:50,000
The code retrieves in the file data set object, which is a subclass of data set.

3413
04:04:50,000 --> 04:04:54,240
File data set references a single or multiple files of any format in your data store.

3414
04:04:54,800 --> 04:05:00,800
The class provides you with the ability to download or amount files to your computer by creating a reference to the data source location.

3415
04:05:00,800 --> 04:05:06,240
Additionally, you register the data set to your workspace for easy retrieval during training.

3416
04:05:06,240 --> 04:05:08,560
There's a bit more how-tos, but we'll give it a good read here.

3417
04:05:08,560 --> 04:05:10,320
So we have the open data set MNIST.

3418
04:05:10,520 --> 04:05:12,400
It's kind of nice that they have that reference there.

3419
04:05:13,440 --> 04:05:22,320
So we have a data folder, we make the directory, we are getting the data set, we download it, and then we are registering it.

3420
04:05:22,320 --> 04:05:24,000
So let's go ahead and run that.

3421
04:05:24,800 --> 04:05:25,920
Not sure how fast that is.

3422
04:05:25,920 --> 04:05:27,200
Shouldn't take too long.

3423
04:05:27,640 --> 04:05:32,960
As it's running, we'll go over here to the left-hand side, refresh, and we'll see if it appears.

3424
04:05:36,320 --> 04:05:37,600
Not as of yet.

3425
04:05:37,600 --> 04:05:38,800
There it is.

3426
04:05:40,320 --> 04:05:41,040
Go into here.

3427
04:05:41,040 --> 04:05:42,320
Maybe we explore the data.

3428
04:05:42,320 --> 04:05:45,520
I'm not sure how it would look like, because these are all images, right?

3429
04:05:46,320 --> 04:05:50,240
Yeah, so they're in ubyte.gz, so they're in compressed files.

3430
04:05:50,240 --> 04:05:53,120
We're not going to be able to see within them, but they're definitely there.

3431
04:05:53,120 --> 04:05:57,360
We know they're there, so that is now registered into our dataset.

3432
04:05:57,920 --> 04:06:04,640
Display some sample images, so load the compressed files into NumPy, then use matplotlib.

3433
04:06:05,200 --> 04:06:07,760
Plot 30 random images from the data set from above.

3434
04:06:07,760 --> 04:06:09,600
Note the step requires load data function.

3435
04:06:09,600 --> 04:06:11,120
It's included in the utils.py.

3436
04:06:11,560 --> 04:06:13,600
This file is included in the sample folder.

3437
04:06:13,600 --> 04:06:14,800
We have it over here.

3438
04:06:14,800 --> 04:06:15,760
We just double click.

3439
04:06:16,120 --> 04:06:17,840
Very simple file to load data.

3440
04:06:18,960 --> 04:06:20,720
And we'll go ahead and run that.

3441
04:06:21,840 --> 04:06:25,440
And it's pretty simple here.

3442
04:06:26,160 --> 04:06:29,120
So load data, X train, X test.

3443
04:06:29,160 --> 04:06:31,360
Are we setting up our training and testing data here?

3444
04:06:31,360 --> 04:06:34,120
It kind of looks like it because it says train and test data.

3445
04:06:34,120 --> 04:06:36,000
That's when we usually see that kind of split.

3446
04:06:37,360 --> 04:06:40,240
And again, it's doing a random split, so that sounds pretty good to me.

3447
04:06:41,440 --> 04:06:43,200
Let's show some randomly chosen images.

3448
04:06:43,200 --> 04:06:46,480
Yeah, so I guess they do set up the training data here.

3449
04:06:47,200 --> 04:06:49,200
And then down below, we're actually showing the images.

3450
04:06:49,200 --> 04:06:50,800
So here's some random images.

3451
04:06:51,040 --> 04:06:52,320
Train on a remote cluster.

3452
04:06:52,320 --> 04:07:03,520
So for this task, you submit the job to run on the remote training cluster to set up earlier, submit your job, create the directory, create a training script, create a script, run configuration, submit the job.

3453
04:07:03,520 --> 04:07:05,760
So first we will create our directory.

3454
04:07:08,760 --> 04:07:10,960
And notice it created this directory over here.

3455
04:07:12,640 --> 04:07:14,520
because I guess it's going to put the training file in there.

3456
04:07:14,520 --> 04:07:16,920
And so this will actually write to a training file.

3457
04:07:16,920 --> 04:07:19,280
This makes quite a bit of sense.

3458
04:07:19,680 --> 04:07:22,000
So if we click into here, it should now have a training file.

3459
04:07:22,720 --> 04:07:25,360
It'll just give it a quick read, see what's going on here.

3460
04:07:25,600 --> 04:07:35,600
So a lot of times when you create these training files, you have to do, and this is the same if you're using AWS, like when you're creating or SageMaker, you create a train file, because it's part of the frameworks.

3461
04:07:35,600 --> 04:07:36,600
It's just how the frameworks work.

3462
04:07:36,600 --> 04:07:38,320
But you'll have these arguments.

3463
04:07:39,040 --> 04:07:42,640
So it could be like parameters to run for training.

3464
04:07:43,120 --> 04:07:47,360
And there could be a whole sorts of ones here.

3465
04:07:48,480 --> 04:07:50,960
they're loading in the training and testing data.

3466
04:07:50,960 --> 04:07:54,560
So it's the same stuff we saw earlier when we were just viewing the data.

3467
04:07:58,640 --> 04:08:00,560
Here it's doing a logistic regression.

3468
04:08:01,200 --> 04:08:04,880
It's using maybe a linear learning model there.

3469
04:08:05,280 --> 04:08:06,480
It's doing multi-class.

3470
04:08:07,240 --> 04:08:08,040
on that there.

3471
04:08:08,040 --> 04:08:09,920
And so what it's going to do is fit.

3472
04:08:09,920 --> 04:08:12,480
So fit is actually performing the training.

3473
04:08:13,120 --> 04:08:15,840
And then what it's going to do is make a prediction on the test set.

3474
04:08:17,520 --> 04:08:19,120
Then we're going to get accuracy.

3475
04:08:19,120 --> 04:08:20,640
So we're getting kind of a score.

3476
04:08:20,640 --> 04:08:27,680
So notice that it's using accuracy as a evaluation metric, I suppose, right?

3477
04:08:28,320 --> 04:08:29,920
And then at the end, we're going to dump the data.

3478
04:08:29,920 --> 04:08:30,960
A lot of times,

3479
04:08:31,240 --> 04:08:32,800
you have to save the model somewhere.

3480
04:08:32,800 --> 04:08:36,880
So they're outputting the actual weights of the neural network and all that other stuff.

3481
04:08:36,880 --> 04:08:38,000
It's a PLK file.

3482
04:08:38,000 --> 04:08:38,960
I don't know what that is.

3483
04:08:39,280 --> 04:08:43,040
But if you're using like TensorFlow, you would use TensorFlow serving at the end of this.

3484
04:08:43,440 --> 04:08:49,600
A lot of times frameworks will like PyTorch or TensorFlow or MXNet, they'll have a serving layer.

3485
04:08:50,480 --> 04:08:54,640
But since we're just using scikit-learn, which is very simple, it's just going to dump out

3486
04:08:55,280 --> 04:08:56,880
that file into our outputs.

3487
04:08:57,120 --> 04:09:03,520
This is going to probably run a container, so this outputs isn't going to necessarily be on the outputs into here.

3488
04:09:03,760 --> 04:09:05,920
It's more like the outputs of the container.

3489
04:09:06,320 --> 04:09:17,120
And a lot of times the container will then place this somewhere, so like it'll be saved on the container, but it'll be passed out to the register or something like that, like model registry.

3490
04:09:17,440 --> 04:09:19,760
So anyway, we ran this, and so that generated the file.

3491
04:09:19,760 --> 04:09:21,640
We don't want to keep on running this multiple times.

3492
04:09:21,640 --> 04:09:23,760
I probably would just overwrite the file, so it's not a big deal.

3493
04:09:24,880 --> 04:09:27,200
Here it says, notice how the script gets saved in the data model.

3494
04:09:27,200 --> 04:09:29,760
So here it's saying the data folder.

3495
04:09:29,760 --> 04:09:30,880
I guess we didn't look at that.

3496
04:09:30,880 --> 04:09:36,360
So if we go top here, I didn't see, this is data folder.

3497
04:09:36,360 --> 04:09:39,520
I wasn't really paying attention to where that was.

3498
04:09:40,480 --> 04:09:43,840
I guess it looks like where more so it's loading the data in.

3499
04:09:44,160 --> 04:09:48,280
So here it saves the data, put anything written to this directory is automatically uploaded to your workspace.

3500
04:09:48,280 --> 04:09:50,400
So I guess that's just how it works.

3501
04:09:50,400 --> 04:09:51,920
So it probably will end up in here then.

3502
04:09:53,120 --> 04:09:58,080
So utilipy reference the training script to load the data set correctly and copy the file over.

3503
04:09:58,080 --> 04:10:03,200
So we will run this to copy the file over.

3504
04:10:04,880 --> 04:10:07,200
So I'm guessing, did it put it into here?

3505
04:10:07,200 --> 04:10:07,800
I'm just wondering.

3506
04:10:07,800 --> 04:10:14,640
Yeah, so it just put it in there because when it actually packages it for the container, it's going to bring that file over because it's a dependency.

3507
04:10:15,520 --> 04:10:16,480
So

3508
04:10:17,640 --> 04:10:18,880
Configure the training job.

3509
04:10:18,880 --> 04:10:26,080
So create a script run config, the directory that contains the script, the compute target, the training script, train file, et cetera.

3510
04:10:26,400 --> 04:10:31,600
Sometimes, like in other frameworks, we'll just call them estimators, but here it's just called a script run config.

3511
04:10:32,160 --> 04:10:36,960
So I'm just trying to see what it's doing.

3512
04:10:37,840 --> 04:10:40,000
So scikit-learn is the dependency.

3513
04:10:40,000 --> 04:10:41,600
Okay, sure, we'll just hit run.

3514
04:10:43,800 --> 04:10:44,160
Okay.

3515
04:10:45,040 --> 04:10:48,080
And then down below here, we have script run config.

3516
04:10:49,680 --> 04:10:52,280
So it looks like we're passing our arguments.

3517
04:10:52,280 --> 04:10:57,040
So we're saying this is our data folder, which is apparently here, we're mounting it.

3518
04:10:57,760 --> 04:11:00,960
And then we're setting regularization to 0.5.

3519
04:11:01,440 --> 04:11:09,680
Sometimes you'll pass in dependencies in here as well, I guess these are technically our parameters that are getting configured up here at the top, right.

3520
04:11:10,720 --> 04:11:15,600
But sometimes you'll have dependencies if you're including other files here.

3521
04:11:17,280 --> 04:11:18,560
And I guess that's up here, right?

3522
04:11:18,560 --> 04:11:19,840
So see where it says environment.

3523
04:11:19,840 --> 04:11:26,200
And then we're saying include the Azure ML defaults and the scikit-learn and stuff like that.

3524
04:11:26,200 --> 04:11:27,760
And so then it gets passed in the ENV.

3525
04:11:28,080 --> 04:11:28,880
So that makes sense to me.

3526
04:11:28,880 --> 04:11:31,760
We haven't ran that yet because we don't see any number here.

3527
04:11:32,800 --> 04:11:34,240
Submit the job to the cluster.

3528
04:11:34,240 --> 04:11:35,520
So let's go ahead and do that.

3529
04:11:38,160 --> 04:11:41,520
It says it returns a preparing or running state as soon as the job is completed.

3530
04:11:41,520 --> 04:11:43,360
So it's in a starting state.

3531
04:11:46,880 --> 04:11:48,240
Monitor remote run.

3532
04:11:48,240 --> 04:11:57,440
So in total, the first run takes 10 minutes, but the second run, as long as the dependencies in the Azure ML department don't change, the same images are reused, and hence the.

3533
04:11:57,540 --> 04:11:59,580
The start time is much faster.

3534
04:12:00,060 --> 04:12:01,740
Here's what's happening while you wait.

3535
04:12:01,740 --> 04:12:07,620
The image creation, a Docker image is created matching the Python environment specified by the Azure ML environment.

3536
04:12:07,900 --> 04:12:13,500
The image is built and stored in the ACR, the Azure Container Registry associated with your workspace.

3537
04:12:13,780 --> 04:12:15,660
Let's go take a look and see if that's the case.

3538
04:12:16,180 --> 04:12:21,100
Because sometimes resources aren't visible to you, so I'm just curious, do we actually see it?

3539
04:12:22,700 --> 04:12:23,180
Okay.

3540
04:12:24,700 --> 04:12:25,900
And yep, there it is.

3541
04:12:25,980 --> 04:12:27,740
Okay, so the did not lie.

3542
04:12:30,460 --> 04:12:34,620
So associated with your workspace image creation uploading takes about 5 minutes.

3543
04:12:34,700 --> 04:12:35,980
This stage happens once.

3544
04:12:36,540 --> 04:12:42,260
For each Python environment, since the container's cached subsequent runs during image creation, logs are stemmed to the run history.

3545
04:12:42,260 --> 04:12:46,940
You can monitor the image creation process using these logs, wherever those are.

3546
04:12:47,260 --> 04:12:53,660
If the remote cluster requires more nodes to execute the run than currently available, additional nodes are added automatically.

3547
04:12:53,660 --> 04:12:56,620
Scaling typically takes about 5 minutes.

3548
04:12:56,900 --> 04:13:02,780
And I've seen this before, where if you're in your compute here, sometimes it'll just say like scaling because it's just not enough.

3549
04:13:04,220 --> 04:13:09,100
So running in the stage, the necessary scripts and files are sent to the compute target.

3550
04:13:09,100 --> 04:13:12,460
Then the data stores are mounted, copied, the entry script is run.

3551
04:13:12,460 --> 04:13:14,860
So the entry script is actually the train.py file.

3552
04:13:15,180 --> 04:13:17,220
While the job is running, St.

3553
04:13:17,220 --> 04:13:21,020
out in the files is in the logs directory are stemmed to the run history.

3554
04:13:21,020 --> 04:13:23,740
You can monitor the run's progress using these logs.

3555
04:13:24,700 --> 04:13:31,180
The.outputs directory of the run is copied over to the run history in your workspace so you can access these results.

3556
04:13:31,660 --> 04:13:33,900
You can check the progress of a running job in multiple ways.

3557
04:13:33,900 --> 04:13:35,660
This tutorial uses the Jupyter widget.

3558
04:13:35,660 --> 04:13:39,660
So it looks like we can run this, watch the progress.

3559
04:13:39,740 --> 04:13:41,180
So maybe we'll run that.

3560
04:13:42,180 --> 04:13:43,540
And so it's actually showing us the progress.

3561
04:13:43,540 --> 04:13:44,260
That's kind of cool.

3562
04:13:44,260 --> 04:13:45,100
I really like that.

3563
04:13:46,620 --> 04:13:49,740
So it's just a little widget showing us all the things that it's doing.

3564
04:13:50,860 --> 04:13:55,420
Let's go take a look and see what we can see under our experiments and our run pipeline.

3565
04:13:55,820 --> 04:13:58,380
He was talking about things like outputs and things like that.

3566
04:13:58,380 --> 04:14:01,660
So over here in the outputs and logs, I'm just curious.

3567
04:14:03,860 --> 04:14:05,420
As if this is the same thing.

3568
04:14:10,650 --> 04:14:13,690
I'm not sure if this is this tails.

3569
04:14:13,690 --> 04:14:15,170
Yeah, it does tail, it just moves.

3570
04:14:15,170 --> 04:14:16,810
So we can actually monitor it from here.

3571
04:14:16,810 --> 04:14:18,250
I guess that's what it was talking about.

3572
04:14:19,740 --> 04:14:24,140
So here we can see that it's setting up Docker, it's actually building a Docker image.

3573
04:14:24,780 --> 04:14:35,500
And then I'm not sure did it send it to I mean, it's on ACR already, I think it looks like it's just still downloading extracting packages.

3574
04:14:35,500 --> 04:14:37,340
So maybe it's actually running on the image now.

3575
04:14:37,340 --> 04:14:38,460
So we'll just wait there.

3576
04:14:38,780 --> 04:14:40,460
We pop back over here.

3577
04:14:41,020 --> 04:14:43,740
You know, we can see probably the same information is identical.

3578
04:14:43,740 --> 04:14:44,540
Yeah, it is.

3579
04:14:46,780 --> 04:14:47,980
So we're 3 minutes in.

3580
04:14:48,260 --> 04:14:52,700
It's probably not that fun to watch it in real time and talk about it.

3581
04:14:52,700 --> 04:14:54,140
So let's just wait until it's done.

3582
04:14:54,140 --> 04:14:55,260
I'll see you back then, okay?

3583
04:14:56,540 --> 04:14:59,020
All right, so I'm about 17 minutes in here.

3584
04:14:59,020 --> 04:15:01,180
I'm not seeing any more movement here.

3585
04:15:01,180 --> 04:15:02,780
So it could be that it is done.

3586
04:15:03,140 --> 04:15:06,220
It does say if you run this next step here, it will wait for completion.

3587
04:15:07,580 --> 04:15:10,300
Specify show output to true for verbose log.

3588
04:15:11,260 --> 04:15:15,260
So here, actually, it did output a moment ago, so maybe it actually was done.

3589
04:15:16,620 --> 04:15:22,140
I just ran it twice, so I'm not sure if that's going to cause me issues there.

3590
04:15:22,940 --> 04:15:26,620
So, because I can't run the next step unless I stop this.

3591
04:15:27,180 --> 04:15:30,060
Can I individually cancel this one here?

3592
04:15:33,700 --> 04:15:34,940
I think I can just hit...

3593
04:15:36,260 --> 04:15:37,020
Interrupt the kernel.

3594
04:15:37,020 --> 04:15:37,420
There we go.

3595
04:15:37,580 --> 04:15:39,260
Okay, so I think that it's done.

3596
04:15:39,580 --> 04:15:43,580
Okay, because it's 18 minutes in, and I don't see any more logging in here.

3597
04:15:43,580 --> 04:15:44,620
It's just not very clear.

3598
04:15:44,860 --> 04:15:48,860
And also, the logs, we just have a lot of stuff going on here.

3599
04:15:48,860 --> 04:15:50,540
Like, it's just so much.

3600
04:15:51,100 --> 04:15:54,540
So, you know, if we were keeping pace, we probably just would have saw all these credit.

3601
04:15:54,540 --> 04:15:57,020
Yeah, so another, we just had a few more outputs there.

3602
04:15:57,580 --> 04:15:59,740
But I think that it's done.

3603
04:16:00,540 --> 04:16:01,020
Okay.

3604
04:16:04,500 --> 04:16:06,860
It's just there's nothing definitively saying like done.

3605
04:16:07,660 --> 04:16:08,380
Do you know what I'm saying?

3606
04:16:08,380 --> 04:16:11,580
And then up here, it doesn't say, oh, oh, I guess it does say that it's done.

3607
04:16:11,580 --> 04:16:12,060
All right.

3608
04:16:12,540 --> 04:16:14,540
So yeah, I just never ran it with this tool.

3609
04:16:14,540 --> 04:16:15,500
So I just don't know.

3610
04:16:16,460 --> 04:16:18,300
So I guess it does definitively say that.

3611
04:16:18,780 --> 04:16:19,540
I already ran this.

3612
04:16:19,540 --> 04:16:21,500
So we don't need to run that again.

3613
04:16:21,500 --> 04:16:23,020
I just feel like we'll get stuck there.

3614
04:16:23,020 --> 04:16:24,300
So let's take a look at the metrics.

3615
04:16:26,300 --> 04:16:29,180
So regularization rate is 0.5 accuracy is.

3616
04:16:30,060 --> 04:16:30,540
Nine.

3617
04:16:30,540 --> 04:16:31,420
So 9 is pretty good.

3618
04:16:31,660 --> 04:16:37,340
The last step is train the script wrote in the output SK learn.

3619
04:16:37,340 --> 04:16:40,620
I want to see if it's actually in our environment here.

3620
04:16:41,780 --> 04:16:42,620
I don't think it is.

3621
04:16:42,620 --> 04:16:43,820
So outputs is somewhere.

3622
04:16:44,220 --> 04:16:46,300
It's in our workspace somewhere, but it's just not.

3623
04:16:47,180 --> 04:16:47,780
We just don't.

3624
04:16:47,780 --> 04:16:48,460
Oh, it's right here.

3625
04:16:48,460 --> 04:16:48,860
Okay.

3626
04:16:49,260 --> 04:16:51,420
So it outputted the actual model right there.

3627
04:16:52,620 --> 04:16:57,380
And so you can see the associated files that are ran.

3628
04:16:57,380 --> 04:16:58,220
Okay, we'll run it.

3629
04:17:00,060 --> 04:17:03,140
Register the work model space so you can work with other collaborators.

3630
04:17:03,140 --> 04:17:03,740
Sure.

3631
04:17:04,220 --> 04:17:10,780
So if I click on that here, and we go back over to our models, it is now registered over here.

3632
04:17:11,020 --> 04:17:11,420
Okay.

3633
04:17:13,140 --> 04:17:15,340
And so we're done part one.

3634
04:17:15,900 --> 04:17:17,740
I don't want to do all these other parts.

3635
04:17:17,980 --> 04:17:19,420
Training is enough as it is.

3636
04:17:19,420 --> 04:17:21,900
But let's just take a look at the deploy stage.

3637
04:17:22,780 --> 04:17:24,540
Okay, so for prerequisites,

3638
04:17:27,260 --> 04:17:28,540
We're setting up a workspace.

3639
04:17:29,180 --> 04:17:31,580
We are loading our registered model.

3640
04:17:33,460 --> 04:17:34,540
Okay, we register it.

3641
04:17:34,540 --> 04:17:36,300
We have to import packages.

3642
04:17:37,180 --> 04:17:41,980
We are going to create scoring script.

3643
04:17:43,460 --> 04:17:45,740
deploy to an ACI model, test the model.

3644
04:17:45,900 --> 04:17:47,980
If you want to do this, you can go through all the steps.

3645
04:17:48,140 --> 04:17:49,740
It does talk about a confusion matrix.

3646
04:17:49,740 --> 04:17:54,020
And that is something that can show up on the exam is actually talking about a confusion matrix.

3647
04:17:54,020 --> 04:17:55,620
But we do cover that in lecture content.

3648
04:17:55,620 --> 04:17:57,820
So you generally understand what that is.

3649
04:17:58,140 --> 04:18:00,060
But, you know, I'm just, I'm too tired.

3650
04:18:00,060 --> 04:18:01,100
I don't want to run through all this.

3651
04:18:01,140 --> 04:18:05,020
And there's not a whole lot of value other than reading through it yourself here.

3652
04:18:05,740 --> 04:18:07,820
So I think we're all done here, okay?

3653
04:18:13,100 --> 04:18:15,660
Okay, one service we forgot to check out was data labeling.

3654
04:18:15,660 --> 04:18:17,420
So let's go over there and give that a go.

3655
04:18:17,420 --> 04:18:19,380
So I'm going to go ahead and create ourselves a new project.

3656
04:18:19,380 --> 04:18:21,420
I'm going to say my labeling project.

3657
04:18:22,260 --> 04:18:25,020
And we can say whether we want to classify images or text.

3658
04:18:25,500 --> 04:18:29,500
We have multi-class, multi-label, bounding box, segmentation.

3659
04:18:29,500 --> 04:18:31,100
Let's go with multi-class.

3660
04:18:32,100 --> 04:18:33,460
I'll go back here for a second.

3661
04:18:33,820 --> 04:18:34,940
Multi-class, whoops.

3662
04:18:36,620 --> 04:18:41,100
I don't know if we create a data set, but we could probably upload some local files.

3663
04:18:42,620 --> 04:18:45,580
Let's say my Star Trek data set.

3664
04:18:49,420 --> 04:18:51,780
It doesn't let us choose the image file type here.

3665
04:18:51,780 --> 04:18:53,260
It'd be nice if these were images.

3666
04:18:56,740 --> 04:18:57,980
It's going to tell us what here.

3667
04:18:59,420 --> 04:19:01,100
It's very finicky, this input here.

3668
04:19:02,220 --> 04:19:07,100
File data set references a single or multiple files in your public data store or private public URL.

3669
04:19:07,100 --> 04:19:08,220
Okay, so we'll go next.

3670
04:19:09,660 --> 04:19:11,420
If we can upload files directly, that'd be nice.

3671
04:19:11,420 --> 04:19:12,660
Oh, upload a folder.

3672
04:19:12,660 --> 04:19:13,340
I like that.

3673
04:19:13,740 --> 04:19:20,620
So what we'll do is we do have some images in the free AI here under cognitive services assets.

3674
04:19:21,820 --> 04:19:30,700
We have, we'll go back here and we'll say, I think objects would be the easiest.

3675
04:19:32,660 --> 04:19:34,140
Oh, but we just want a folder, right?

3676
04:19:34,140 --> 04:19:35,580
So yeah, we'll just take objects.

3677
04:19:37,180 --> 04:19:39,100
Yep, we'll upload the 17 files.

3678
04:19:41,260 --> 04:19:42,860
Yep, we'll just let it stick to that path.

3679
04:19:42,860 --> 04:19:43,820
That seems fine to me.

3680
04:19:43,820 --> 04:19:49,580
We will go ahead and create it.

3681
04:19:51,300 --> 04:19:52,700
And so now we have a data set there.

3682
04:19:52,700 --> 04:19:54,020
We'll go ahead and select that data set.

3683
04:19:54,020 --> 04:19:55,100
We'll say next.

3684
04:19:55,500 --> 04:19:57,540
Your data set is periodically checked for new data points.

3685
04:19:57,540 --> 04:19:59,660
Any data points will be added as tasks.

3686
04:20:00,100 --> 04:20:00,660
It doesn't matter.

3687
04:20:00,660 --> 04:20:01,660
We're only doing this for test.

3688
04:20:02,420 --> 04:20:03,460
Enter the list of labels.

3689
04:20:03,460 --> 04:20:06,220
So we have TNG.

3690
04:20:07,340 --> 04:20:12,940
DS-9, Voyager, Toss.

3691
04:20:13,580 --> 04:20:16,300
That's the types of Star Trek episodes.

3692
04:20:18,940 --> 04:20:29,100
Label which Star Trek series the image is from.

3693
04:20:30,060 --> 04:20:30,860
Say next.

3694
04:20:31,900 --> 04:20:38,060
I don't want enabled, but you can have auto enabled assistant labeler, I'm gonna say no, we'll create the project.

3695
04:20:42,380 --> 04:20:43,820
Okay, I'll just wait for that crate.

3696
04:20:43,820 --> 04:20:45,700
I'll see you back here in a moment.

3697
04:20:45,700 --> 04:20:45,900
Okay.

3698
04:20:46,700 --> 04:20:47,100
All right.

3699
04:20:47,100 --> 04:20:53,260
So I'm back here actually didn't have to wait long, I think it instantly runs, I just assumed like I was waiting for a state that says completed.

3700
04:20:53,580 --> 04:20:54,860
But it's not something we have to do.

3701
04:20:54,860 --> 04:21:00,060
So we have zero out of 17 progress, we're going to go in here, we're going to go label some data.

3702
04:21:00,540 --> 04:21:02,180
We can view the instructions.

3703
04:21:02,180 --> 04:21:03,500
It's not showing up here, but that's fine.

3704
04:21:03,500 --> 04:21:05,500
If we go to tasks, we can start labeling.

3705
04:21:05,500 --> 04:21:07,500
So what season is this from or series?

3706
04:21:07,500 --> 04:21:08,460
This is Voyager.

3707
04:21:08,700 --> 04:21:09,580
We'll hit submit.

3708
04:21:09,820 --> 04:21:10,860
This is Voyager.

3709
04:21:10,860 --> 04:21:11,740
We'll hit submit.

3710
04:21:12,060 --> 04:21:13,020
This is toss.

3711
04:21:13,100 --> 04:21:13,980
We'll hit submit.

3712
04:21:14,300 --> 04:21:15,660
This is TNG.

3713
04:21:16,460 --> 04:21:17,660
This is TNG.

3714
04:21:18,460 --> 04:21:30,140
This is DS9, DS9, Voyager, Voyager, TNG, DS9,

3715
04:21:30,780 --> 04:21:36,060
You get the idea, though, you got some options here, like change the contrast, if someone can't see the photo or rotate it.

3716
04:21:36,460 --> 04:21:47,660
This is Voyager, Voyager, TNG, DS nine, Voyager, Voyager.

3717
04:21:48,940 --> 04:21:49,740
And we're done.

3718
04:21:49,740 --> 04:21:51,820
So we'll go back to our labeling job here.

3719
04:21:52,220 --> 04:21:54,380
We'll see we have the breakdown there.

3720
04:21:54,820 --> 04:21:56,700
And now our data set is labeled.

3721
04:21:57,740 --> 04:22:01,900
We can export our data set, CSV, Cocoa, Azure ML data set.

3722
04:22:02,060 --> 04:22:07,420
I believe that means it'll go back into the data sets over here, which will make our lives a little bit easier.

3723
04:22:08,340 --> 04:22:09,660
Go back to data labeling.

3724
04:22:11,220 --> 04:22:11,340
Okay.

3725
04:22:12,140 --> 04:22:14,100
So you just granted people access to the studio.

3726
04:22:14,100 --> 04:22:17,420
They'd be able to just go in here and jump into that job, okay?

3727
04:22:17,820 --> 04:22:21,660
If we go over to the data set, I believe we should have a labeled version of it now.

3728
04:22:21,660 --> 04:22:23,180
So my labeling project.

3729
04:22:23,900 --> 04:22:27,180
So I believe that is the labeled stuff here, right?

3730
04:22:29,580 --> 04:22:30,660
Yeah, so it's labeled.

3731
04:22:30,940 --> 04:22:31,420
So there you go.

3732
04:22:31,420 --> 04:22:33,660
We're all done Azure Machine Learning.

3733
04:22:33,980 --> 04:22:35,980
And so all that's left is to do some cleanup.

3734
04:22:40,860 --> 04:22:43,260
Okay, so we're all done with Azure Machine Learning.

3735
04:22:43,380 --> 04:22:48,380
If we want to, we can go to our compute and just kill the services we have here.

3736
04:22:48,620 --> 04:22:54,500
Now, if we go to the resource group and delete everything, it'll take all these things down anyway, but I'm just going to go a little bit paranoid.

3737
04:22:54,500 --> 04:22:56,060
So I'm going to just manually do this, okay?

3738
04:22:59,500 --> 04:23:00,300
Hit delete.

3739
04:23:05,100 --> 04:23:08,060
Okay, and so we'll go back to portal.azure.com.

3740
04:23:10,220 --> 04:23:12,860
And I'm going to go to my resource groups.

3741
04:23:13,900 --> 04:23:15,340
And everything is contained.

3742
04:23:15,340 --> 04:23:17,180
It should be all contained within my studio.

3743
04:23:17,180 --> 04:23:19,340
Just be sure to check these other ones for that.

3744
04:23:19,740 --> 04:23:21,580
And we can see all the stuff that we spun up.

3745
04:23:21,980 --> 04:23:23,900
We'll go ahead and hit delete resource group.

3746
04:23:25,100 --> 04:23:29,980
I don't know if it includes like, because I don't see like container registry, right?

3747
04:23:29,980 --> 04:23:31,420
So I know like it puts stuff there.

3748
04:23:33,180 --> 04:23:33,780
I guess it does.

3749
04:23:33,780 --> 04:23:35,020
This is container registry.

3750
04:23:35,020 --> 04:23:36,340
So that's pretty much everything, right?

3751
04:23:36,340 --> 04:23:38,620
And that'll take down everything.

3752
04:23:38,620 --> 04:23:45,900
So, and if you're paranoid, all you can do is go to all resources and double check over here, because if there's anything running, it'll show up here, okay?

3753
04:23:46,860 --> 04:23:47,900
But that's pretty much it.

3754
04:23:48,060 --> 04:23:50,220
And so just delete and we're all done.
