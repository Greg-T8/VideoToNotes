[
  {
    "section_title": "\ud83c\udfa4 [00:00:00] Introduction",
    "chunk_id": 1,
    "timestamp_range": "00:00:00 \u2013 00:00:15",
    "key_concepts": [
      "Foundry IQ, Fabric IQ, and Work IQ form the knowledge foundation for AI apps and agents.",
      "These knowledge layers enable unlocking powerful AI capabilities.",
      "Generative models are trained on large but finite corpora, necessitating additional knowledge layers."
    ],
    "definitions": {
      "Foundry IQ": "A knowledge foundation component designed to enhance AI applications by providing access to additional knowledge beyond the pre-trained model."
    },
    "key_facts": [
      "Generative models have finite training data and cutoff dates, limiting their knowledge scope."
    ],
    "examples": [],
    "exam_tips": [],
    "raw_markdown": "### \ud83c\udfa4 [00:00:00] Introduction  \n**Timestamp**: 00:00:00 \u2013 00:00:15  \n\n**Key Concepts**  \n- Foundry IQ, Fabric IQ, and Work IQ form the knowledge foundation for AI apps and agents.  \n- These knowledge layers enable unlocking powerful AI capabilities.  \n- Generative models are trained on large but finite corpora, necessitating additional knowledge layers.  \n\n**Definitions**  \n- **Foundry IQ**: A knowledge foundation component designed to enhance AI applications by providing access to additional knowledge beyond the pre-trained model.  \n\n**Key Facts**  \n- Generative models have finite training data and cutoff dates, limiting their knowledge scope.  \n\n**Examples**  \n- None in this chunk  \n\n**Key Takeaways \ud83c\udfaf**  \n- Understand the role of Foundry IQ as part of a trio (with Fabric IQ and Work IQ) that supplements generative AI models.  \n- Recognize the limitation of generative models\u2019 training data and the need for external knowledge sources.  \n\n---\n\n"
  },
  {
    "section_title": "\ud83c\udfa4 [00:00:15] AI models and their knowledge",
    "chunk_id": 1,
    "timestamp_range": "00:00:29 \u2013 00:01:59",
    "key_concepts": [
      "Generative AI models are trained on a finite corpus of data from books, websites, transcripts, etc.",
      "Training involves adjusting model weights and biases to predict the next probable token in a sequence.",
      "Models cannot access information outside their training data or after their cutoff date.",
      "To use new or private data, it must be provided as part of the prompt at request time."
    ],
    "definitions": {
      "Generative Model": "AI model trained to predict and generate text based on learned patterns from training data.",
      "Corpus": "The body of text data used to train the model.",
      "Cutoff Date": "The latest date of information included in the training data."
    },
    "key_facts": [
      "Models do not include non-public or post-cutoff data unless explicitly provided."
    ],
    "examples": [],
    "exam_tips": [],
    "raw_markdown": "### \ud83c\udfa4 [00:00:15] AI models and their knowledge  \n**Timestamp**: 00:00:29 \u2013 00:01:59  \n\n**Key Concepts**  \n- Generative AI models are trained on a finite corpus of data from books, websites, transcripts, etc.  \n- Training involves adjusting model weights and biases to predict the next probable token in a sequence.  \n- Models cannot access information outside their training data or after their cutoff date.  \n- To use new or private data, it must be provided as part of the prompt at request time.  \n\n**Definitions**  \n- **Generative Model**: AI model trained to predict and generate text based on learned patterns from training data.  \n- **Corpus**: The body of text data used to train the model.  \n- **Cutoff Date**: The latest date of information included in the training data.  \n\n**Key Facts**  \n- Models do not include non-public or post-cutoff data unless explicitly provided.  \n\n**Examples**  \n- None in this chunk  \n\n**Key Takeaways \ud83c\udfaf**  \n- Know that generative models have inherent knowledge limits and require augmentation with external data for up-to-date or private information.  \n- Understand that additional data must be included in the prompt to influence model output.  \n\n---\n\n"
  },
  {
    "section_title": "\ud83c\udfa4 [00:01:31] RAG to the rescue",
    "chunk_id": 1,
    "timestamp_range": "00:01:24 \u2013 00:02:59",
    "key_concepts": [
      "Retrieval-Augmented Generation (RAG) is the process of retrieving relevant external information to augment generative model responses.",
      "The AI app queries an external knowledge source first, retrieves relevant data, and then includes it in the prompt to the model.",
      "The quality and relevance of retrieved data directly impact the quality of the model\u2019s output (\"Garbage in, garbage out\")."
    ],
    "definitions": {
      "RAG (Retrieval-Augmented Generation)": "Technique combining retrieval of external data with generative AI to improve response accuracy."
    },
    "key_facts": [
      "RAG is a common and essential approach to overcome generative model knowledge limitations."
    ],
    "examples": [
      "Using internal company databases or other knowledge sources to provide context to the AI model."
    ],
    "exam_tips": [],
    "raw_markdown": "### \ud83c\udfa4 [00:01:31] RAG to the rescue  \n**Timestamp**: 00:01:24 \u2013 00:02:59  \n\n**Key Concepts**  \n- Retrieval-Augmented Generation (RAG) is the process of retrieving relevant external information to augment generative model responses.  \n- The AI app queries an external knowledge source first, retrieves relevant data, and then includes it in the prompt to the model.  \n- The quality and relevance of retrieved data directly impact the quality of the model\u2019s output (\"Garbage in, garbage out\").  \n\n**Definitions**  \n- **RAG (Retrieval-Augmented Generation)**: Technique combining retrieval of external data with generative AI to improve response accuracy.  \n\n**Key Facts**  \n- RAG is a common and essential approach to overcome generative model knowledge limitations.  \n\n**Examples**  \n- Using internal company databases or other knowledge sources to provide context to the AI model.  \n\n**Key Takeaways \ud83c\udfaf**  \n- Understand the RAG workflow: query \u2192 retrieve relevant info \u2192 augment prompt \u2192 generate response.  \n- Emphasize the importance of high-quality, relevant data in RAG for effective AI outputs.  \n\n---\n\n"
  },
  {
    "section_title": "\ud83c\udfa4 [00:03:12] Azure AI Search",
    "chunk_id": 1,
    "timestamp_range": "00:03:01 \u2013 00:08:17",
    "key_concepts": [
      "Azure AI Search provides an API endpoint exposing indexes built on various data sources (blobs, databases, etc.).",
      "The app sends queries to Azure AI Search, which returns the best matching data to augment AI prompts.",
      "Azure AI Search supports both lexical (keyword) and semantic (vector-based) search.",
      "Semantic search uses embeddings to represent the meaning of data and queries as high-dimensional vectors.",
      "Reciprocal rank fusion combines lexical and semantic search results for improved relevance.",
      "Semantic re-ranking further refines results based on confidence scores.",
      "Searches are performed against a single index representing a single information source."
    ],
    "definitions": {
      "Lexical Search": "Keyword-based search matching exact terms.",
      "Semantic Search": "Search based on meaning, using vector embeddings to find conceptually similar content.",
      "Embedding Model": "AI model that converts text into high-dimensional vectors representing semantic meaning.",
      "Reciprocal Rank Fusion": "Technique to merge and rank results from multiple search methods."
    },
    "key_facts": [
      "Azure AI Search creates indexes per data source (e.g., blob container, database).",
      "Semantic search addresses natural language challenges like idioms and synonyms.",
      "The search process includes chunking data, embedding creation, and vector similarity matching."
    ],
    "examples": [
      "Searching by SKU or product name using lexical search.",
      "Handling idiomatic phrases like \"raining cats and dogs\" via semantic understanding."
    ],
    "exam_tips": [],
    "raw_markdown": "### \ud83c\udfa4 [00:03:12] Azure AI Search  \n**Timestamp**: 00:03:01 \u2013 00:08:17  \n\n**Key Concepts**  \n- Azure AI Search provides an API endpoint exposing indexes built on various data sources (blobs, databases, etc.).  \n- The app sends queries to Azure AI Search, which returns the best matching data to augment AI prompts.  \n- Azure AI Search supports both lexical (keyword) and semantic (vector-based) search.  \n- Semantic search uses embeddings to represent the meaning of data and queries as high-dimensional vectors.  \n- Reciprocal rank fusion combines lexical and semantic search results for improved relevance.  \n- Semantic re-ranking further refines results based on confidence scores.  \n- Searches are performed against a single index representing a single information source.  \n\n**Definitions**  \n- **Lexical Search**: Keyword-based search matching exact terms.  \n- **Semantic Search**: Search based on meaning, using vector embeddings to find conceptually similar content.  \n- **Embedding Model**: AI model that converts text into high-dimensional vectors representing semantic meaning.  \n- **Reciprocal Rank Fusion**: Technique to merge and rank results from multiple search methods.  \n\n**Key Facts**  \n- Azure AI Search creates indexes per data source (e.g., blob container, database).  \n- Semantic search addresses natural language challenges like idioms and synonyms.  \n- The search process includes chunking data, embedding creation, and vector similarity matching.  \n\n**Examples**  \n- Searching by SKU or product name using lexical search.  \n- Handling idiomatic phrases like \"raining cats and dogs\" via semantic understanding.  \n\n**Key Takeaways \ud83c\udfaf**  \n- Know how Azure AI Search integrates lexical and semantic search to improve retrieval quality.  \n- Understand the importance of embeddings and vector search in handling natural language queries.  \n- Recognize that Azure AI Search indexes are single-source and foundational to RAG 1.0.  \n\n---\n\n"
  },
  {
    "section_title": "\ud83c\udfa4 [00:08:24] Foundry IQ",
    "chunk_id": 1,
    "timestamp_range": "00:08:21 \u2013 00:23:42",
    "key_concepts": [
      "Foundry IQ builds on Azure AI Search to provide a true knowledge layer, not just information retrieval.",
      "Moves from single-shot RAG to agentic RAG with multi-hop, multi-source querying.",
      "Supports searching across multiple knowledge sources grouped into knowledge bases.",
      "Knowledge sources include Azure AI Search indexes, Fabric IQ (enterprise ontology in OneLake), SharePoint sites, web search (Bing), and remote sources like M365 semantic index and MCP (Microsoft Copilot Protocol).",
      "Remote knowledge sources do not create local indexes but query external semantic indexes or APIs.",
      "Knowledge bases are collections of knowledge sources; AI apps query knowledge bases rather than individual sources.",
      "Knowledge sources can be reused across multiple knowledge bases.",
      "Azure AI Search resource must be selected before creating knowledge bases.",
      "SKU limits govern the number of knowledge bases and knowledge sources allowed per Azure AI Search resource.",
      "Reasoning effort settings (minimal, low, medium) control how Foundry IQ plans and executes queries:"
    ],
    "definitions": {
      "Foundry IQ": "Advanced knowledge layer built on Azure AI Search enabling multi-source, agentic retrieval and reasoning.",
      "Agentic RAG": "Retrieval-augmented generation with intelligent planning, multi-hop querying, and selective knowledge source use.",
      "Knowledge Source": "A single indexed or remote data source (e.g., Azure AI Search index, SharePoint site, web).",
      "Knowledge Base": "A collection of knowledge sources grouped logically for AI querying.",
      "Fabric IQ": "Fabric\u2019s enterprise ontology representing entities, relationships, and properties semantically in OneLake.",
      "MCP (Microsoft Copilot Protocol)": "Standard protocol for AI apps to access additional knowledge and tools via reflection of capabilities.",
      "Reasoning Effort": "Level of AI planning and query complexity (minimal, low, medium)."
    },
    "key_facts": [
      "Knowledge bases currently support up to 10 knowledge sources (subject to SKU limits).",
      "Free Azure AI Search SKU supports 3 knowledge bases and 3 knowledge sources; higher SKUs support more.",
      "SharePoint data can be indexed locally or accessed remotely via M365 semantic index.",
      "Web search is powered by Bing and does not create local indexes.",
      "MCP integration is in private preview.",
      "AI apps only need to query knowledge bases, simplifying agent design."
    ],
    "examples": [
      "Knowledge base with two knowledge sources: an Azure AI Search index and web search.",
      "Descriptions like \u201cTranscripts from John Savill\u2019s technical training YouTube channel\u201d help AI select sources.",
      "Retrieval instructions prioritizing YouTube knowledge source for technical queries, falling back to web search if needed."
    ],
    "exam_tips": [],
    "raw_markdown": "### \ud83c\udfa4 [00:08:24] Foundry IQ  \n**Timestamp**: 00:08:21 \u2013 00:23:42  \n\n**Key Concepts**  \n- Foundry IQ builds on Azure AI Search to provide a true knowledge layer, not just information retrieval.  \n- Moves from single-shot RAG to agentic RAG with multi-hop, multi-source querying.  \n- Supports searching across multiple knowledge sources grouped into knowledge bases.  \n- Knowledge sources include Azure AI Search indexes, Fabric IQ (enterprise ontology in OneLake), SharePoint sites, web search (Bing), and remote sources like M365 semantic index and MCP (Microsoft Copilot Protocol).  \n- Remote knowledge sources do not create local indexes but query external semantic indexes or APIs.  \n- Knowledge bases are collections of knowledge sources; AI apps query knowledge bases rather than individual sources.  \n- Knowledge sources can be reused across multiple knowledge bases.  \n- Azure AI Search resource must be selected before creating knowledge bases.  \n- SKU limits govern the number of knowledge bases and knowledge sources allowed per Azure AI Search resource.  \n- Reasoning effort settings (minimal, low, medium) control how Foundry IQ plans and executes queries:  \n  - Minimal: sends the same query to all knowledge sources.  \n  - Low/Medium: plans queries selectively, breaks down complex queries, and chooses relevant knowledge sources based on descriptions and instructions.  \n- Descriptions and retrieval instructions guide the AI\u2019s selection and prioritization of knowledge sources.  \n- Medium reasoning effort adds self-reflection capabilities for improved results.  \n\n**Definitions**  \n- **Foundry IQ**: Advanced knowledge layer built on Azure AI Search enabling multi-source, agentic retrieval and reasoning.  \n- **Agentic RAG**: Retrieval-augmented generation with intelligent planning, multi-hop querying, and selective knowledge source use.  \n- **Knowledge Source**: A single indexed or remote data source (e.g., Azure AI Search index, SharePoint site, web).  \n- **Knowledge Base**: A collection of knowledge sources grouped logically for AI querying.  \n- **Fabric IQ**: Fabric\u2019s enterprise ontology representing entities, relationships, and properties semantically in OneLake.  \n- **MCP (Microsoft Copilot Protocol)**: Standard protocol for AI apps to access additional knowledge and tools via reflection of capabilities.  \n- **Reasoning Effort**: Level of AI planning and query complexity (minimal, low, medium).  \n\n**Key Facts**  \n- Knowledge bases currently support up to 10 knowledge sources (subject to SKU limits).  \n- Free Azure AI Search SKU supports 3 knowledge bases and 3 knowledge sources; higher SKUs support more.  \n- SharePoint data can be indexed locally or accessed remotely via M365 semantic index.  \n- Web search is powered by Bing and does not create local indexes.  \n- MCP integration is in private preview.  \n- AI apps only need to query knowledge bases, simplifying agent design.  \n\n**Examples**  \n- Knowledge base with two knowledge sources: an Azure AI Search index and web search.  \n- Descriptions like \u201cTranscripts from John Savill\u2019s technical training YouTube channel\u201d help AI select sources.  \n- Retrieval instructions prioritizing YouTube knowledge source for technical queries, falling back to web search if needed.  \n\n**Key Takeaways \ud83c\udfaf**  \n- Understand the evolution from single-source RAG to multi-source, agentic RAG with Foundry IQ.  \n- Know the distinction between knowledge sources and knowledge bases and their roles.  \n- Recognize the importance of metadata (descriptions, instructions) in guiding AI reasoning and source selection.  \n- Be aware of SKU limits and how they affect knowledge base and source capacity.  \n- Comprehend how reasoning effort settings influence query planning and execution strategies.  \n- Appreciate the integration of diverse data types and remote sources to enrich AI knowledge access."
  },
  {
    "section_title": "\ud83c\udfa4 [00:22:31] Importance of good descriptions and instructions",
    "chunk_id": 2,
    "timestamp_range": "00:24:03 \u2013 00:24:19",
    "key_concepts": [
      "Foundry IQ performs a plan to query selected knowledge sources and evaluates the results with a medium reasoning effort.",
      "It reflects on whether the problem has been solved and can perform a second follow-up pass if needed to improve output quality."
    ],
    "definitions": {
      "Medium reasoning effort": "A level of processing where the system reviews retrieved data and decides if the query is sufficiently answered, with the option to do additional retrieval if necessary."
    },
    "key_facts": [
      "Additional passes increase token usage, latency, and cost but improve response quality."
    ],
    "examples": [
      "After initial retrieval and reasoning, if the answer is not satisfactory, Foundry IQ can do a second iteration to refine the response."
    ],
    "exam_tips": [],
    "raw_markdown": "### \ud83c\udfa4 [00:22:31] Importance of good descriptions and instructions  \n**Timestamp**: 00:24:03 \u2013 00:24:19\n\n**Key Concepts**  \n- Foundry IQ performs a plan to query selected knowledge sources and evaluates the results with a medium reasoning effort.  \n- It reflects on whether the problem has been solved and can perform a second follow-up pass if needed to improve output quality.  \n\n**Definitions**  \n- **Medium reasoning effort**: A level of processing where the system reviews retrieved data and decides if the query is sufficiently answered, with the option to do additional retrieval if necessary.  \n\n**Key Facts**  \n- Additional passes increase token usage, latency, and cost but improve response quality.  \n\n**Examples**  \n- After initial retrieval and reasoning, if the answer is not satisfactory, Foundry IQ can do a second iteration to refine the response.  \n\n**Key Takeaways \ud83c\udfaf**  \n- Understanding the trade-off between reasoning effort and cost/latency is critical when configuring Foundry IQ.  \n- Medium effort includes reflection and potential additional retrieval to enhance answer quality.  \n\n---\n\n"
  },
  {
    "section_title": "\ud83c\udfa4 [00:23:51] Self-reflection",
    "chunk_id": 2,
    "timestamp_range": "00:24:26 \u2013 00:25:39",
    "key_concepts": [
      "Foundry IQ offers different reasoning effort levels: minimal, low, and medium.",
      "Minimal effort skips source selection and planning, searching all sources indiscriminately.",
      "Low and medium efforts include source selection, query planning, and a reflective retrieval step for richer responses.",
      "Reflective retrieval involves additional classification and retrieval to improve answer quality."
    ],
    "definitions": {
      "Source selection": "The process of choosing the most relevant knowledge sources to query.",
      "Query planning": "Strategizing how to query selected sources effectively.",
      "Reflective retrieval": "An additional retrieval step after initial results to refine answers."
    },
    "key_facts": [
      "Minimal reasoning does not use web as a knowledge source.",
      "Low and medium reasoning enable more advanced capabilities including web usage and answer synthesis."
    ],
    "examples": [
      "Minimal effort mode searches all sources without planning.",
      "Medium effort mode performs planning and reflection to improve answers."
    ],
    "exam_tips": [],
    "raw_markdown": "### \ud83c\udfa4 [00:23:51] Self-reflection  \n**Timestamp**: 00:24:26 \u2013 00:25:39\n\n**Key Concepts**  \n- Foundry IQ offers different reasoning effort levels: minimal, low, and medium.  \n- Minimal effort skips source selection and planning, searching all sources indiscriminately.  \n- Low and medium efforts include source selection, query planning, and a reflective retrieval step for richer responses.  \n- Reflective retrieval involves additional classification and retrieval to improve answer quality.  \n\n**Definitions**  \n- **Source selection**: The process of choosing the most relevant knowledge sources to query.  \n- **Query planning**: Strategizing how to query selected sources effectively.  \n- **Reflective retrieval**: An additional retrieval step after initial results to refine answers.  \n\n**Key Facts**  \n- Minimal reasoning does not use web as a knowledge source.  \n- Low and medium reasoning enable more advanced capabilities including web usage and answer synthesis.  \n\n**Examples**  \n- Minimal effort mode searches all sources without planning.  \n- Medium effort mode performs planning and reflection to improve answers.  \n\n**Key Takeaways \ud83c\udfaf**  \n- Selecting the appropriate reasoning effort level impacts the quality and cost of responses.  \n- Reflective retrieval is a key feature of medium effort that enhances answer accuracy.  \n\n---\n\n"
  },
  {
    "section_title": "\ud83c\udfa4 [00:25:39] Output modes",
    "chunk_id": 2,
    "timestamp_range": "00:25:53 \u2013 00:26:57",
    "key_concepts": [
      "Foundry IQ supports two main output modes when querying knowledge bases: extractive data and answer synthesis.",
      "Extractive data returns raw relevant data chunks from knowledge sources for the AI model to reason over.",
      "Answer synthesis returns a fully generated natural language answer synthesized from the knowledge sources.",
      "Answer synthesis is mandatory when using web as a knowledge source and requires at least low reasoning effort.",
      "Minimal reasoning effort is incompatible with answer synthesis mode."
    ],
    "definitions": {
      "Extractive data": "Returning relevant data snippets without generating a final answer.",
      "Answer synthesis": "Generating a complete, natural language answer based on retrieved knowledge."
    },
    "key_facts": [
      "Answer synthesis mode disables minimal reasoning option.",
      "Extractive data mode is compatible with minimal reasoning."
    ],
    "examples": [
      "When web is included as a knowledge source, answer synthesis is enforced.",
      "Switching between extractive data and answer synthesis changes available reasoning effort options."
    ],
    "exam_tips": [],
    "raw_markdown": "### \ud83c\udfa4 [00:25:39] Output modes  \n**Timestamp**: 00:25:53 \u2013 00:26:57\n\n**Key Concepts**  \n- Foundry IQ supports two main output modes when querying knowledge bases: extractive data and answer synthesis.  \n- Extractive data returns raw relevant data chunks from knowledge sources for the AI model to reason over.  \n- Answer synthesis returns a fully generated natural language answer synthesized from the knowledge sources.  \n- Answer synthesis is mandatory when using web as a knowledge source and requires at least low reasoning effort.  \n- Minimal reasoning effort is incompatible with answer synthesis mode.  \n\n**Definitions**  \n- **Extractive data**: Returning relevant data snippets without generating a final answer.  \n- **Answer synthesis**: Generating a complete, natural language answer based on retrieved knowledge.  \n\n**Key Facts**  \n- Answer synthesis mode disables minimal reasoning option.  \n- Extractive data mode is compatible with minimal reasoning.  \n\n**Examples**  \n- When web is included as a knowledge source, answer synthesis is enforced.  \n- Switching between extractive data and answer synthesis changes available reasoning effort options.  \n\n**Key Takeaways \ud83c\udfaf**  \n- Choose output mode based on application needs: extractive data for rich agent reasoning, answer synthesis for simple chat-like responses.  \n- Web knowledge sources require answer synthesis and higher reasoning effort.  \n\n---\n\n"
  },
  {
    "section_title": "\ud83c\udfa4 [00:28:31] Seeing the output modes in action",
    "chunk_id": 2,
    "timestamp_range": "00:27:00 \u2013 00:32:59",
    "key_concepts": [
      "Demonstration of extractive data mode: Foundry IQ queries a knowledge base and returns multiple document chunks for the model to process.",
      "Demonstration of answer synthesis mode: Foundry IQ generates a complete natural language answer with references to sources used.",
      "Extractive data mode is suited for advanced AI agents that perform their own reasoning on retrieved data.",
      "Answer synthesis mode suits simpler applications that want a ready-made answer without further processing."
    ],
    "definitions": {
      "Knowledge base": "A single queryable entity aggregating multiple knowledge sources."
    },
    "key_facts": [
      "Extractive data mode returns multiple documents (e.g., 11 chunks) without synthesis.",
      "Answer synthesis mode returns a generated answer plus source citations, with longer response time.",
      "Approval prompts can be configured to control query execution."
    ],
    "examples": [
      "Query: \"What is ExpressRoute?\""
    ],
    "exam_tips": [],
    "raw_markdown": "### \ud83c\udfa4 [00:28:31] Seeing the output modes in action  \n**Timestamp**: 00:27:00 \u2013 00:32:59\n\n**Key Concepts**  \n- Demonstration of extractive data mode: Foundry IQ queries a knowledge base and returns multiple document chunks for the model to process.  \n- Demonstration of answer synthesis mode: Foundry IQ generates a complete natural language answer with references to sources used.  \n- Extractive data mode is suited for advanced AI agents that perform their own reasoning on retrieved data.  \n- Answer synthesis mode suits simpler applications that want a ready-made answer without further processing.  \n\n**Definitions**  \n- **Knowledge base**: A single queryable entity aggregating multiple knowledge sources.  \n\n**Key Facts**  \n- Extractive data mode returns multiple documents (e.g., 11 chunks) without synthesis.  \n- Answer synthesis mode returns a generated answer plus source citations, with longer response time.  \n- Approval prompts can be configured to control query execution.  \n\n**Examples**  \n- Query: \"What is ExpressRoute?\"  \n  - Extractive data mode returns raw documents from the knowledge base.  \n  - Answer synthesis mode returns a synthesized answer with references.  \n\n**Key Takeaways \ud83c\udfaf**  \n- Understand the difference between raw data retrieval and synthesized answer generation.  \n- Application design dictates whether to use extractive data or answer synthesis output mode.  \n\n---\n\n"
  },
  {
    "section_title": "\ud83c\udfa4 [00:33:11] Peeking inside its thinking",
    "chunk_id": 2,
    "timestamp_range": "00:33:11 \u2013 00:34:38",
    "key_concepts": [
      "Foundry IQ provides detailed debug information showing internal operations during query processing.",
      "Debug info includes number of iterations, planning cycles, activities, retrieval calls, elapsed time, and token usage.",
      "Query planning steps and additional queries per iteration are visible.",
      "Final answer and references are shown in debug output."
    ],
    "definitions": {
      "Iteration": "A distinct planning and retrieval cycle during query processing.",
      "Activity": "Individual operations or calls made during query processing."
    },
    "key_facts": [
      "Example debug showed 2 iterations, 11 activities, 60 retrieval calls.",
      "Debugging reveals the complexity and depth of Foundry IQ\u2019s reasoning process."
    ],
    "examples": [
      "Viewing debug output for a query shows detailed step-by-step processing and source usage."
    ],
    "exam_tips": [],
    "raw_markdown": "### \ud83c\udfa4 [00:33:11] Peeking inside its thinking  \n**Timestamp**: 00:33:11 \u2013 00:34:38\n\n**Key Concepts**  \n- Foundry IQ provides detailed debug information showing internal operations during query processing.  \n- Debug info includes number of iterations, planning cycles, activities, retrieval calls, elapsed time, and token usage.  \n- Query planning steps and additional queries per iteration are visible.  \n- Final answer and references are shown in debug output.  \n\n**Definitions**  \n- **Iteration**: A distinct planning and retrieval cycle during query processing.  \n- **Activity**: Individual operations or calls made during query processing.  \n\n**Key Facts**  \n- Example debug showed 2 iterations, 11 activities, 60 retrieval calls.  \n- Debugging reveals the complexity and depth of Foundry IQ\u2019s reasoning process.  \n\n**Examples**  \n- Viewing debug output for a query shows detailed step-by-step processing and source usage.  \n\n**Key Takeaways \ud83c\udfaf**  \n- Debugging tools help understand and optimize Foundry IQ query behavior.  \n- Insight into internal processing aids in troubleshooting and improving AI app responses.  \n\n---\n\n"
  },
  {
    "section_title": "\ud83c\udfa4 [00:34:37] Summary",
    "chunk_id": 2,
    "timestamp_range": "00:34:37 \u2013 00:36:25",
    "key_concepts": [
      "Foundry IQ provides a unified knowledge base abstraction that intelligently queries multiple knowledge sources (local, remote, web).",
      "It delivers either relevant data chunks or fully synthesized answers depending on configuration.",
      "The system builds on the data-information-knowledge-wisdom hierarchy:"
    ],
    "definitions": {
      "Knowledge base": "A curated, queryable collection of knowledge sources providing structured knowledge.",
      "Wisdom": "The ability to make sound judgments based on knowledge."
    },
    "key_facts": [
      "Foundry IQ complements other Fabric IQ components like Fabric IQ (OneLake data) and Work IQ (M365 data).",
      "Each IQ focuses on different data domains but collectively provide comprehensive knowledge for AI."
    ],
    "examples": [
      "Foundry IQ handles organizational knowledge.",
      "Fabric IQ manages system operational knowledge.",
      "Work IQ manages user context and memory."
    ],
    "exam_tips": [],
    "raw_markdown": "### \ud83c\udfa4 [00:34:37] Summary  \n**Timestamp**: 00:34:37 \u2013 00:36:25\n\n**Key Concepts**  \n- Foundry IQ provides a unified knowledge base abstraction that intelligently queries multiple knowledge sources (local, remote, web).  \n- It delivers either relevant data chunks or fully synthesized answers depending on configuration.  \n- The system builds on the data-information-knowledge-wisdom hierarchy:  \n  - Raw data is processed into information.  \n  - Information is consolidated and contextualized into knowledge.  \n  - Knowledge enables reasoning and judgment, leading to wisdom.  \n- Foundry IQ focuses on delivering knowledge to AI apps and agents for better inferencing and decision-making.  \n\n**Definitions**  \n- **Knowledge base**: A curated, queryable collection of knowledge sources providing structured knowledge.  \n- **Wisdom**: The ability to make sound judgments based on knowledge.  \n\n**Key Facts**  \n- Foundry IQ complements other Fabric IQ components like Fabric IQ (OneLake data) and Work IQ (M365 data).  \n- Each IQ focuses on different data domains but collectively provide comprehensive knowledge for AI.  \n\n**Examples**  \n- Foundry IQ handles organizational knowledge.  \n- Fabric IQ manages system operational knowledge.  \n- Work IQ manages user context and memory.  \n\n**Key Takeaways \ud83c\udfaf**  \n- Foundry IQ is essential for delivering high-quality knowledge to AI applications.  \n- Understanding the data-to-wisdom progression is key to leveraging Foundry IQ effectively.  \n- Combining multiple IQs enables AI agents to answer complex enterprise questions comprehensively.  \n\n---\n\n"
  },
  {
    "section_title": "\ud83c\udfa4 [00:35:15] How the IQs work together",
    "chunk_id": 2,
    "timestamp_range": "00:36:41 \u2013 00:37:43",
    "key_concepts": [
      "Foundry IQ, Fabric IQ, and Work IQ are complementary systems providing knowledge across different enterprise domains.",
      "Work IQ provides user context and memory from M365 data.",
      "Fabric IQ provides operational knowledge from OneLake data.",
      "Foundry IQ provides organizational knowledge from diverse knowledge sources.",
      "Together, they empower AI apps and agents with comprehensive, contextual knowledge to make informed decisions."
    ],
    "definitions": {
      "IQs": "Intelligent Query systems designed to provide knowledge in specific domains."
    },
    "key_facts": [
      "Integration of IQs allows AI to answer any question by leveraging combined knowledge sources."
    ],
    "examples": [
      "An AI agent can use Work IQ for user context, Fabric IQ for system data, and Foundry IQ for organizational info to generate accurate responses."
    ],
    "exam_tips": [],
    "raw_markdown": "### \ud83c\udfa4 [00:35:15] How the IQs work together  \n**Timestamp**: 00:36:41 \u2013 00:37:43\n\n**Key Concepts**  \n- Foundry IQ, Fabric IQ, and Work IQ are complementary systems providing knowledge across different enterprise domains.  \n- Work IQ provides user context and memory from M365 data.  \n- Fabric IQ provides operational knowledge from OneLake data.  \n- Foundry IQ provides organizational knowledge from diverse knowledge sources.  \n- Together, they empower AI apps and agents with comprehensive, contextual knowledge to make informed decisions.  \n\n**Definitions**  \n- **IQs**: Intelligent Query systems designed to provide knowledge in specific domains.  \n\n**Key Facts**  \n- Integration of IQs allows AI to answer any question by leveraging combined knowledge sources.  \n\n**Examples**  \n- An AI agent can use Work IQ for user context, Fabric IQ for system data, and Foundry IQ for organizational info to generate accurate responses.  \n\n**Key Takeaways \ud83c\udfaf**  \n- Leveraging multiple IQs together enhances AI app capabilities.  \n- Understanding each IQ\u2019s domain helps design better AI solutions.  \n- Foundry IQ is a critical part of the enterprise knowledge ecosystem."
  }
]